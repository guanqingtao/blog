## pg_tiktoken - 标记token数的工具. 防止问答超过AI大模型chatbot token上限, 导致回复截断    
            
### 作者            
digoal            
            
### 日期            
2023-09-22            
            
### 标签            
PostgreSQL , PolarDB , chatbot , token    
            
----            
            
## 背景       
chatbot是大模型应用之一, 在与chatbot沟通时会遇到token上限问题, 例如通义目前是8K, chatgpt是4K. 也就是问题上下文(包含多轮对话的内容)最多8k或4k, 超出就无法处理了.      
    
解释一下token: 对于通义模型来说, 中文字符串的token就是字数(含符号).  英文则可能是词、片段等.    
    
我们的核心目的是通过有限的上下文来拿到结果.     
    
这就需要你的prompt(上下文)足够精确, 防止无效垃圾对话浪费token限额.      
    
上下文的组成:    
1、每一轮对话的提问内容和大模型的回答内容    
2、外脑中的FAQ     
    
参考知识:     
- https://help.aliyun.com/zh/dashscope/developer-reference/api-details    
- https://neon.tech/docs/extensions/pg_tiktoken    
- https://neon.tech/docs/ai/ai-concepts    
- https://github.com/kelvich/pg_tiktoken    
    
## pg_tiktoken 扩展是什么?    
语言模型以称为标记的单位处理文本。标记可以短至单个字符，也可以长至完整的单词，例如“a”或“apple”。在一些语言中，标记可以包括少于单个字符或者甚至超出单个单词。    
    
例如，考虑“Neon 是无服务器 Postgres”这句话。它可以分为七个标记：[“Ne”、“on”、“is”、“server”、“less”、“Post”、“gres”]。    
  
pg_tiktoken 的核心功能是将文本转换为token, 以及统计文本的token数. 不同的大模型切token的方法可能不同, pg_tiktoken 支持多种模型.  
  
pg_tiktoken的2个函数:   
- tiktoken_encode：接受文本输入并返回标记化输出，使您能够无缝标记化文本数据。    
- tiktoken_count：计算给定文本中的标记数量。此功能可帮助您遵守文本长度限制，例如 OpenAI 语言模型设置的长度限制。    
  
## 体验pg_tiktoken  
  
可以使用永久免费的阿里云[云起实验室](https://developer.aliyun.com/adc/scenario/f55dbfac77c0467a9d3cd95ff6697a31)来完成.          
          
如果你本地有docker环境也可以把镜像拉到本地来做实验:          
          
x86_64机器使用以下docker image:          
- [《amd64 image》](../202307/20230710_03.md)          
          
ARM机器使用以下docker image:          
- [《arm64 image》](../202308/20230814_02.md)     
  
```  
CREATE EXTENSION pg_tiktoken;  
```  
  
### 使用tiktoken_encode功能    
  
该tiktoken_encode函数对文本输入进行标记并返回标记化的输出。该函数接受编码名称和 OpenAI 模型名称作为第一个参数，以及要标记化的文本作为第二个参数，如下所示：    
```  
SELECT tiktoken_encode('text-davinci-003', 'The universe is a vast and captivating mystery, waiting to be explored and understood.');    
    
tiktoken_encode     
--------------------------------------------------------------------------------    
 {464,6881,318,257,5909,290,3144,39438,10715,11,4953,284,307,18782,290,7247,13}    
(1 row)    
```  
  
该函数使用字节对编码 (BPE)算法对文本进行标记。    
    
### 使用tiktoken_count功能    
  
该tiktoken_count函数计算文本中标记的数量。该函数接受编码名称和 OpenAI 模型名称作为第一个参数，接受文本作为第二个参数，如下所示：    
```  
neondb=> SELECT tiktoken_count('text-davinci-003', 'The universe is a vast and captivating mystery, waiting to be explored and understood.');    
    
 tiktoken_count     
----------------    
             17    
(1 row)    
```  
  
  
支持以下模型：    
    
Encoding name	| OpenAI models  
---|---  
`cl100k_base`	|ChatGPT models, `text-embedding-ada-002`  
`p50k_base`	|Code models, `text-davinci-002`, `text-davinci-003`  
`p50k_edit`	|Use for edit models like `text-davinci-edit-001`, `code-davinci-edit-001`  
`r50k_base` (or `gpt2`)	|GPT-3 models like `davinci`  
    
  
例如我们可以设计一张表来存储问答的内容:    
```  
CREATE TABLE message (    
  role VARCHAR(50) NOT NULL,      -- equals to 'system', 'user' or 'assistant'    
  content TEXT NOT NULL,      
  created TIMESTAMP NOT NULL DEFAULT NOW(),    
  embedding vector,   -- 向量值   
  n_tokens INTEGER -- number of content tokens    
);    
```  
  
  
`gpt -3.5-turbo`聊天模型需要特定参数：    
```  
{    
  "model": "gpt-3.5-turbo",    
  "messages": [    
        {"role": "system", "content": "You are a helpful assistant."},    
        {"role": "user", "content": "Who won the world series in 2020?"},    
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."}    
    ]    
}    
```  
  
  
该messages参数是一个消息对象数组，每个对象包含两条信息：role消息发送者（system、user或assistant）的 和实际消息content。对话可以很简短，只有一条消息，也可以跨越多个页面，只要组合的消息令牌不超过 4096 个令牌的限制。    
    
要将role、content和标记数量插入数据库，请使用以下查询：    
    
```  
INSERT INTO message (role, content, n_tokens)    
VALUES ('user', 'Hello, how are you?', tiktoken_count('text-davinci-003','Hello, how are you?'));     
```  
  
### 管理文本标记    
    
当对话包含的标记多于模型可以处理的标记（例如，超过 `4096` 个标记`gpt-3.5-turbo`）时，您将需要截断文本以适应模型的限制。    
    
此外，冗长的对话可能会导致回复不完整。例如，如果`gpt-3.5-turbo`对话跨越 `4090` 个令牌，则响应将仅限于 `6` 个令牌。    
    
以下查询将检索消息，直至达到您所需的令牌限制：    
```  
WITH cte AS (    
  SELECT role, content, created, n_tokens,    
         SUM(tokens) OVER (ORDER BY created DESC) AS cumulative_sum    
  FROM message    
)    
    
SELECT role, content, created, n_tokens, cumulative_sum    
FROM cte    
WHERE cumulative_sum <= <MAX_HISTORY_TOKENS>;      
```  
  
`<MAX_HISTORY_TOKENS>`表示您想要保留以完成聊天的对话历史记录，遵循以下公式：    
```  
MAX_HISTORY_TOKENS = MODEL_MAX_TOKENS – NUM_SYSTEM_TOKENS – NUM_COMPLETION_TOKENS    
```  
    
例如，假设所需的完成长度是 90 个标记 ( `NUM_COMPLETION_TOKENS=90` )。    
```  
MAX_HISTORY_TOKENS = 4096 – 6 – 90 = 4000    
```  
  
```  
{    
  "model": "gpt-3.5-turbo", // MODEL_MAX_TOKENS = 4096    
  "messages": [    
         {"role": "system", "content": "You are a helpful assistant."}, // NUM_SYSTEM_TOKENS = 6    
         {"role": "user", "content": "Who won the world series in 2020?"},    
         {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},    
         {"role": ...}  // user 和 assistant 必须交替出现.     
         .    
         .    
         .    
         {"role": "user", "content": "Great! Have a great day."}  // MAX_HISTORY_TOKENS = 4000    
    ]     
}    
```  
  
  
`NUM_COMPLETION_TOKENS` 指留给机器人返回内容的token上限数.      
    
https://zhuanlan.zhihu.com/p/611240015      
    
例如你想让机器人回复1000个token, 那你最多能给他输入3090个token.      
    
甚至在messages中, 可以自己造一些精准的自问自答, 作为提示输入给gpt模型, 最后再追加问一个问题.      
    
- [《沉浸式学习PostgreSQL|PolarDB 9: AI大模型+向量数据库, 提升AI通用机器人在专业领域的精准度, 完美诠释柏拉图提出的“知识是回忆而不是知觉”》](../202308/20230831_01.md)      
- [《标准知识库 + PostgreSQL或PolarDB + 向量插件 + openai(或其他大模型) 提升通用ai机器人在专业领域的精准度》](../202307/20230726_02.md)      
- [《沉浸式学习PostgreSQL|PolarDB 16: 植入通义千问大模型+文本向量化模型, 让数据库具备AI能力》](../202309/20230914_01.md)      
- [《沉浸式学习PostgreSQL|PolarDB 17: 向量数据库, 通义大模型AI的外脑》](../202309/20230922_02.md)      
    
    
例如我想问的是A问题, 根据这个A问题的embedding, 在已有的问答库中搜索最相似的N条问答. 把问答式原文写到messages里面, 作为提示, 最后再附上A问题.    
```  
{    
  "model": "gpt-3.5-turbo", // MODEL_MAX_TOKENS = 4096    
  "messages": [    
         {"role": "system", "content": "You are a helpful assistant."}, // NUM_SYSTEM_TOKENS = 6    
         {"role": "user", "content": "自问1"},    
         {"role": "assistant", "content": "自答1"},    
         {"role": ...}  // user 和 assistant 交替出现.     
         .    
         .    
         .    
         {"role": "user", "content": "追加1个问题"}  // MAX_HISTORY_TOKENS = 4000    
    ]     
}    
```  
  
### 结论    
  
总之，该pg_tiktoken扩展是用于标记文本数据和管理 Postgres 数据库中标记的宝贵工具。通过利用 OpenAI 的 tiktoken 库，它简化了代币化和使用代币限制的过程，使您能够更轻松地与 OpenAI 的语言模型集成。    
    
当您探索 的功能时pg_tiktoken extension，我们鼓励您提供反馈并建议您希望在未来的更新中添加的功能。我们期待看到您使用创建的创新自然语言处理应用程序pg_tiktoken。    
    
  
## 实验  
根据以上知识, 设计一个使用通义千问的PolarDB专属问答机器人.      
  
可以在这个实验中进行体验:  
- [《沉浸式学习PostgreSQL|PolarDB 17: 向量数据库, 通义大模型AI的外脑》](../202309/20230922_02.md)      
    
https://help.aliyun.com/zh/dashscope/developer-reference/api-details    
    
通义千问以用户以文本形式输入的指令（prompt）以及不定轮次的对话历史（history）作为输入，返回模型生成的回复作为输出。在这一过程中，文本将被转换为语言模型可以处理的token序列。Token是模型用来表示自然语言文本的基本单位，可以直观的理解为“字”或“词”。对于中文文本来说，1个token通常对应一个汉字；对于英文文本来说，1个token通常对应3至4个字母或1个单词。例如，中文文本“你好，我是通义千问”会被转换成序列['你', '好', '，', '我', '是', '通', '义', '千', '问']，而英文文本"Nice to meet you."则会被转换成['Nice', ' to', ' meet', ' you', '.']。    
    
通义千问模型支持 8k tokens上下文，为了保障正常使用和正常输出，API限定用户输入为6k Tokens。    
    
    
1、设计faq表    
```  
问题    
回答    
embedding    
tokens  
```  
  
2、输入精准问答材料(问题和答案限制字数, 肯定不能大于6K对吧, 例如强制少于100字.)     
    
3、设计历史问答表    
```  
会话ID    
问题    
回答    
tokens   
准确度评分等级(1,2,3 低中高)    
embedding    
```  
    
4、保存问答历史记录(不含提示的问题+通义的回复)     
    
5、人为修正历史问答准确度     
    
(1,2,3 低中高)    
    
6、根据问题相似度, 从会话历史表 辅以 准确度 提取prompt; 从精准faq表, 辅以 准确度 提取prompt; 最后根据prompt 长度6K限制等条件, 提取问答内容原文; 在提问前, 作为prompt输入.     
    
  
    
## 参考  
https://neon.tech/docs/ai/ai-concepts    
    
https://github.com/neondatabase/yc-idea-matcher    
    
https://github.com/neondatabase/ask-neon    
    
https://neon.tech/docs/extensions/pg_tiktoken    
  
https://github.com/kelvich/pg_tiktoken    
  
[《德说-第257期, 新生产力工具AI推动下一级人类文明跃迁? AI如何倒逼数据库的进化? AI加持后的数据库应用场景有哪些变化?》](../202309/20230921_01.md)      
  
[《沉浸式学习PostgreSQL|PolarDB 16: 植入通义千问大模型+文本向量化模型, 让数据库具备AI能力》](../202309/20230914_01.md)      
    
[《沉浸式学习PostgreSQL|PolarDB 17: 向量数据库, 通义大模型AI的外脑》](../202309/20230922_02.md)      
    
[《PostgreSQL 或PolarDB 使用插件pg_tiktoken - 使用 OpenAI tiktoken库文本向量化(tokenization) - 使用分词算法BPE - NLP 自然语言处理》](../202307/20230706_05.md)      
    
    
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 云原生分布式开源数据库](https://github.com/ApsaraDB "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、内核开发公开课、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  

## DuckDB 发布新版本 0.9.0  
                                                  
### 作者                                                  
digoal                                                  
                                                  
### 日期                                                  
2023-09-27                                                 
                                                  
### 标签                                                  
PostgreSQL , PolarDB , duckdb , 新版本 , 超内存外部哈希计算 , 存储垃圾回收 , 索引空间占用大幅下降 , wasm 动态加载插件 , iceberg格式支持        
                                                  
----                                                  
                                                  
## 背景      
DuckDB 发布新版本 0.9.0  
  
https://duckdb.org/2023/09/26/announcing-duckdb-090.html  
  
https://github.com/duckdb/duckdb/releases/tag/v0.9.0  
  
  
重大改进  
- 支持超出内存的外部哈希聚合  
- 存储改进, 支持vacuum(收缩末尾垃圾空间)  
- 索引支持增了增量写入磁盘, 同时空间占用大幅下降  
- DuckDB-WASM 扩展, wasm版duckdb支持动态加载duckdb插件  
- 扩展自动加载, 支持自动[加载官方extension](https://github.com/duckdb/duckdb/blob/main/scripts/generate_extensions_function.py)  
- 改进的 AWS 支持, 支持LOAD_AWS_CREDENTIALS 使用 AWS Credential Provider Chain自动获取和设置凭证  
- apache Iceberg 格式支持 https://duckdb.org/docs/extensions/iceberg , https://iceberg.apache.org/  
- Azure 支持, 允许 DuckDB 以本机方式读取存储在 Azure 上的数据  
- PySpark 兼容 API  
  
  
  
## 例子  
  
在此版本中，通过对外部哈希聚合的支持进一步扩展了对溢出技术的支持。现在GROUP BY在查询或操作期间构建的哈希表DISTINCT由于存在大量唯一组而无法容纳在内存中，因此会将数据溢出到磁盘，而不是抛出内存不足异常。由于基数分区的巧妙使用，性能下降是逐渐的，并且避免了性能断崖下降。只有不适合内存的表子集才会溢出到磁盘。  
  
我们的哈希聚合的性能总体上也有所提高，特别是当有很多组时。例如，我们使用以下查询计算包含 3000 万行和 15 列的数据集中唯一行的数量：  
  
```  
SELECT COUNT(*) FROM (SELECT DISTINCT * FROM tbl);  
```  
  
  
内存限制	| v0.8.1	| v0.9.0  
---|---|---  
10.0GB	|8.52秒	|2.91秒  
9.0GB	|8.52秒	|3.45秒  
8.0GB	|8.52秒	|3.45秒  
7.0GB	|8.52秒	|3.47秒  
6.0GB	|OOM	|3.41秒  
5.0GB	|OOM	|3.67秒  
4.0GB	|OOM	|3.87秒  
3.0GB	|OOM	|4.20秒  
2.0GB	|OOM	|4.39秒  
1.0GB	|OOM	|4.91秒  
  
  
压缩物化。DuckDB的流式执行引擎内存占用较低，但分组聚合等操作需要更多内存。通过压缩可以减少这些操作的内存占用。DuckDB 已经在其存储格式中使用了许多压缩技术，但其中许多技术在查询执行期间使用成本太高。然而，某些轻量级压缩技术非常便宜，以至于减少内存占用的好处超过了（解）压缩的成本。  
  
```  
┌───────┬─────────┐  
│  id   │  name   │  
│ int32 │ varchar │  
├───────┼─────────┤  
│   300 │ alice   │  
│   301 │ bob     │  
│   302 │ eve     │  
│   303 │ mallory │  
│   304 │ trent   │  
└───────┴─────────┘  
```  
  
该id列使用 32 位整数。从我们的统计数据中我们知道最小值是 300，最大值是 304。我们可以减去 300 并转换为 8 位整数，将宽度从 4 字节减少到 1。  
  
该name列使用我们的内部字符串类型，宽度为 16 个字节。然而，我们的统计告诉我们，这里最长的字符串只有 7 个字节。我们可以将其放入 64 位整数中，如下所示：  
```  
alice   -> alice005  
bob     -> bob00003  
eve     -> eve00003  
mallory -> mallory7  
trent   -> trent005  
```  
  
这将宽度从 16 个字节减少到 8 个字节。为了支持压缩字符串的排序，我们翻转大端机器上的字节，以便我们的比较运算符仍然正确：  
```  
alice005 -> 500ecila  
bob00003 -> 30000bob  
eve00003 -> 30000eve  
mallory7 -> 7yrollam  
trent005 -> 500tnert  
```  
  
通过减少查询中间体的大小，我们可以防止/减少数据溢出到磁盘，减少对昂贵的 I/O 操作的需求，从而提高查询性能。  
  
  
由于代码矢量化的改进、部分聚合的更多重用以及通过任务窃取改进的并行性，此版本对 Window 函数的性能进行了许多改进。结果，窗口函数的性能得到了显着提升，特别是在没有分区或分区很少的场景下。  
```  
SELECT  
    SUM(driver_pay) OVER (  
        ORDER BY dropoff_datetime ASC  
        RANGE BETWEEN  
        INTERVAL 3 DAYS PRECEDING AND  
        INTERVAL 0 DAYS FOLLOWING  
    )  
FROM tripdata;  
```  
  
版本	| 时间（秒）  
---|---  
v0.8.0	|33.8  
v0.9.0	|3.8  
  
  
当使用DELETE语句删除数据时，被删除的整个行组将被自动清理。还添加了在检查点截断数据库文件的支持，这允许在删除数据后减小数据库文件的大小。请注意，只有当删除的行组位于文件末尾时才会发生这种情况。系统尚未移动数据以减小磁盘上文件的大小。相反，文件中较早的空闲块被重新用于存储后面的数据。 有点类似PostgreSQL Vacuum.  
  
对 ART 索引的内存占用量和磁盘占用量进行了许多改进。特别是对于为维护或约束而创建的索引PRIMARY KEY，存储和内存占用量会大大减少。UNIQUE FOREIGN KEY.   
```  
CREATE TABLE integers(i INTEGER PRIMARY KEY);  
INSERT INTO integers FROM range(10000000);  
```  
  
版本	|尺寸  
---|---  
v0.8.0	|278MB  
v0.9.0	|78MB  
  
  
扩展自动加载。从该版本开始，DuckDB支持自动安装和加载可信扩展。由于许多工作流程依赖于未捆绑的核心扩展，例如httpfs，许多用户发现自己必须记住预先加载所需的扩展。通过此更改，在查询中使用扩展时，将自动加载（并可选择安装）扩展。  
  
例如，在 Python 中，以下代码片段现在无需显式加载httpfs或json扩展即可工作。  
```  
import duckdb  
  
duckdb.sql("FROM 'https://raw.githubusercontent.com/duckdb/duckdb/main/data/json/example_n.ndjson'")  
```  
  
可自动加载扩展集仅限于 DuckDB Labs 分发的官方扩展，[加载官方extension](https://github.com/duckdb/duckdb/blob/main/scripts/generate_extensions_function.py) 可以在此处找到。还可以使用autoinstall_known_extensions和autoload_known_extensions设置或通过更常规的enable_external_access设置来禁用该行为。请参阅配置选项。  
  
  
DuckDB-WASM 扩展。此版本增加了对 DuckDB-WASM 可加载扩展的支持。以前，您想要与 WASM 客户端一起使用的任何扩展都必须内置。在此版本中，可以动态加载扩展。加载扩展时，将下载 WASM 捆绑包并启用扩展的功能。在我们的[WASM shell](https://shell.duckdb.org/)中尝试一下。  
```  
LOAD inet;  
SELECT '127.0.0.1'::INET;  
```  
  
AWS 扩展。此版本标志着 DuckDB AWS 扩展的推出。此扩展包含依赖于 AWS 开发工具包的 AWS 相关功能。目前，该扩展包含一个函数 ，LOAD_AWS_CREDENTIALS它使用 AWS Credential Provider Chain自动获取和设置凭证：  
```  
CALL load_aws_credentials();  
SELECT * FROM "s3://some-bucket/that/requires/authentication.parquet";  
```  
  
DuckDB Iceberg 扩展的推出。此扩展添加了对读取以Iceberg 格式存储的表的支持。  
```  
SELECT count(*) FROM iceberg_scan('data/iceberg/lineitem_iceberg', ALLOW_MOVED_PATHS=true);  
```  
  
请参阅文档以获取更多信息。  
  
实验性 Azure 扩展。此版本标志着 DuckDB Azure 扩展的推出。此扩展允许 DuckDB 以本机方式读取存储在 Azure 上的数据，其方式与读取存储在 S3 上的数据类似。  
```  
SET azure_storage_connection_string = '<your_connection_string>';  
SELECT * from 'azure://<my_container>/*.csv';  
```  
  
请参阅文档以获取更多信息。  
  
实验性 PySpark API。此版本向 Python 客户端添加了实验性 Spark API。该 API 旨在与 PySpark API 完全兼容，允许您以熟悉的方式使用 Spark API，同时利用 DuckDB 的强大功能。所有语句都使用我们的关系 API转换为 DuckDB 的内部计划，并使用 DuckDB 的查询引擎执行。  
```  
from duckdb.experimental.spark.sql import SparkSession as session  
from duckdb.experimental.spark.sql.functions import lit, col  
import pandas as pd  
  
spark = session.builder.getOrCreate()  
  
pandas_df = pd.DataFrame({  
    'age': [34, 45, 23, 56],  
    'name': ['Joan', 'Peter', 'John', 'Bob']  
})  
  
df = spark.createDataFrame(pandas_df)  
df = df.withColumn(  
    'location', lit('Seattle')  
)  
res = df.select(  
    col('age'),  
    col('location')  
).collect()  
  
print(res)  
#[  
#    Row(age=34, location='Seattle'),  
#    Row(age=45, location='Seattle'),  
#    Row(age=23, location='Seattle'),  
#    Row(age=56, location='Seattle')  
#]  
```  
  
请注意，该 API 目前处于实验阶段，仍缺少功能。  
  
  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 云原生分布式开源数据库](https://github.com/ApsaraDB "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、内核开发公开课、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  

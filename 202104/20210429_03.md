## PostgreSQL - 时序、IoT类场景 - time_bucket 分析函数 - 内置 date_bin    
      
### 作者      
digoal      
      
### 日期      
2021-04-29       
      
### 标签      
PostgreSQL , time_bucket , date_trunc , date_bin , timescaledb      
      
----      
      
## 背景      
1、时序数据库中time_bucket的应用例子  
  
https://help.aliyun.com/document_detail/116041.html#h2-time_bucket-  
  
  
计算每五分钟的cpu平均值：  
  
```  
SELECT time_bucket('5 minutes', time) AS five_min, avg(cpu)  
FROM metrics  
GROUP BY five_min  
ORDER BY five_min DESC LIMIT 10;  
```  
  
用户可以传递origin参数(timestamp, timestamptz, date 类型)来偏移校准时间。下面示例中，每周起始日期从默认的周一修改成周日。  
  
```  
SELECT time_bucket('1 week', timetz, TIMESTAMPTZ '2017-12-31')  
  AS one_week, avg(cpu)  
FROM metrics  
GROUP BY one_week  
WHERE time > TIMESTAMPTZ '2017-12-01'  AND time < TIMESTAMPTZ '2018-01-03'  
ORDER BY one_week DESC LIMIT 10;  
```  
  
本例中的2017-12-31是个周日，origin可以是任意时间。 将TIMESTAMPTZ（UTC）转换成本地时区进行分区示例如下：  
  
```  
SELECT time_bucket('5 minutes', timetz::TIMESTAMP)  
  AS five_min, avg(cpu)  
FROM metrics  
GROUP BY five_min  
ORDER BY five_min DESC LIMIT 10;  
```  
  
注：上面例子根据服务器本地时区将TIMESTAMPTZ类型转换成TIMESTAMP类型  
  
2、PostgreSQL timescaledb 内置了同样的分析函数:   
https://www.timescale.com/  
  
  
```  
-- What is the change of memory consumption for each  
-- of my k8s containers over the past 10 minutes?  
SELECT time_bucket('10 seconds', time) AS period,  
  container_id, avg(free_mem)  
FROM metrics  
WHERE time > NOW () - interval '10 minutes'  
GROUP BY period, container_id  
ORDER BY period DESC, container_id;  
  
  
| period                 | container_id | avg     |  
|------------------------|--------------|---------|  
| 2020-07-01 12:01:00+00 | 16           | 72202   |  
| 2020-07-01 12:01:00+00 | 73           | 837725  |  
| 2020-07-01 12:01:00+00 | 96           | 412237  |  
| 2020-07-01 12:01:00+00 | 142          | 1173393 |  
| 2020-07-01 12:00:50+00 | 16           | 90104   |  
| 2020-07-01 12:00:50+00 | 73           | 784596  |  
| 2020-07-01 12:00:50+00 | 96           | 574134  |  
| 2020-07-01 12:00:50+00 | 142          | 960104  |  
```  
  
```  
-- How much of my advertising inventory is unsold or  
-- has unmet demand over recent time intervals?  
SELECT period, total_sold,  
  (total_supply - total_sold) AS total_unsold,  
  (total_demand - total_sold) AS total_unmet  
FROM (  
  SELECT time_bucket('10 seconds', time) AS period,  
    SUM(sold) AS total_sold,  
    SUM(supply) AS total_supply,  
    SUM(demand) AS total_demand  
  FROM inventory  
  WHERE time > NOW () - interval '10 minutes'  
  GROUP BY period  
) AS data ORDER BY period DESC;  
  
  
  
| period                 | total_sold | total_unsold | total_unmet |  
|------------------------|------------|--------------|-------------|  
| 2020-07-01 12:01:00+00 | 105443     | 11964        | 375         |  
| 2020-07-01 12:00:50+00 | 51188      | 48415        | 3450        |  
| 2020-07-01 12:00:40+00 | 86163      | 27891        | 9861        |  
| 2020-07-01 12:00:30+00 | 93091      | 32259        | 2015        |  
| 2020-07-01 12:00:20+00 | 76746      | 36316        | 1203        |  
  
```  
  
  
```  
-- For a specific machine, what are its avg, min, and max temperature  
-- readings over time to ensure it's in proper operating range?  
SELECT time_bucket('10 seconds', time) AS period,  
  min(temperature) AS min_temp,  
  avg(temperature) AS avg_temp,  
  max(temperature) AS max_temp,  
FROM measurements  
WHERE machine_id = 'C931baF7'  
  AND time > NOW() - interval '150s'  
GROUP BY period  
ORDER BY period DESC;  
  
  
| period     | min_temp | avg_temp | max_temp |  
|------------|----------|----------|----------|  
| 1499792590 | 52       | 50       | 54       |  
| 1499792580 | 52       | 50       | 54       |  
| 1499792570 | 51       | 50       | 54       |  
| 1499792560 | 50       | 48       | 52       |  
| 1499792550 | 50       | 48       | 51       |  
| 1499792540 | 49       | 48       | 51       |  
| 1499792530 | 50       | 47       | 52       |  
| 1499792520 | 50       | 48       | 51       |  
| 1499792510 | 51       | 48       | 53       |  
| 1499792500 | 51       | 50       | 54       |  
```  
  
```  
-- For financial ticker 'TIMS', what are the open, close, high, and  
-- low prices (and its trade volume) over the past 30 days?  
SELECT time_bucket('1 day', time) AS day,  
  first(price, time) AS open,  
  last(price, time) AS close,  
  max(price) AS high,  
  min(price) AS low,  
  sum(volume) AS volume  
FROM prices  
WHERE asset_code = 'TIMS'  
  AND time > NOW() - interval '30d'  
GROUP BY day  
ORDER BY day ASC;  
  
  
  
| day                    | open  | close | high  | low   | volume |  
|------------------------|-------|-------|-------|-------|--------|  
| 2020-07-01 00:00:00+00 | 34.13 | 34.15 | 34.28 | 34.03 | 15645  |  
| 2020-07-02 00:00:00+00 | 33.00 | 34.10 | 34.12 | 32.98 | 33907  |  
| 2020-07-03 00:00:00+00 | 32.62 | 32.86 | 33.02 | 32.45 | 26838  |  
| 2020-07-04 00:00:00+00 | 33.04 | 32.57 | 33.04 | 32.36 | 18867  |  
```  
  
time_bucket不输入origin时, 因为没有参照系, 所以必须按time排序才能返回正确结果.   
如: ```time_bucket('1 min', time) 必须 order by time```    
  
  
3、除了timescaledb time_bucket, PostgreSQL内置函数date_trunc, date_bin也能达到类似效果.  
  
https://stackoverflow.com/questions/57040614/how-to-time-bucket-by-month-with-timescaledb  
  
https://www.postgresql.org/docs/devel/functions-datetime.html#FUNCTIONS-DATETIME-BIN  
  
[《PostgreSQL 14 preview - date_bin 任意起点, 任意bucket(interval) split bucket align 统计》](../202103/20210325_01.md)    
  
  
注意, date_bin 需要输入origin time, 而timescaledb 的 time_bucket可以不需要origin.    
但是我们可以给一个比较早期的origin time, 如明知数据的时间是2020年的, 那就可以使用origin time 2020-01-01  
  
```  
SELECT date_bin('1 day', time, '2020-01-01'::timestamp) AS day,  
  first(price, time) AS open,  
  last(price, time) AS close,  
  max(price) AS high,  
  min(price) AS low,  
  sum(volume) AS volume  
FROM prices  
WHERE asset_code = 'TIMS'  
  AND time > NOW() - interval '30d'  
GROUP BY day  
ORDER BY day ASC;  
```  
  
  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  

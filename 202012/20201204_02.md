## 10亿级云资源TAG管理, 实时写入和搜索数据库设计 - gin+btree_gin 倒排搜索    
  
### 作者  
digoal  
  
### 日期  
2020-12-04  
  
### 标签  
PostgreSQL , tag , 资源管理 , gin , btree_gin , 倒排    
  
----  
  
## 背景  
资源TAG管理功能 :   
  
支持资源的tag 增, 删, 改, 查    
  
总资源量:     
- 10亿      
  
TAG的key, value都由用户指定, schemaless.     
  
每个资源最多允许打100个TAG    
  
一个账号下最多有多少资源?     
- 1000万     
  
不限制TAG的使用次数, 一个TAG允许被打在1000万个资源上.    
  
查询范围:  
- 单个账号下, 一个或多个tag的组合(and or not 等)查询    
  
分页  
- 传ID方式分页, 不需要提前告知页数  
  
性能需求:    
- 1. 10000 查询qps， query rt<100ms      
- 2. 1000  写qps，数据500ms内可以通过查询接口查询出来     
  
SQL 示例  
  
```  
create table tags (  
  id serial8 primary key,  
  uid int8,  
  r_id VARCHAR(128),  
  r_type VARCHAR(128),  
  rg_no VARCHAR(32),  
  is_deleted int,  
  tags jsonb,  
  unique (uid,r_id)  
);    
```  
  
```  
select * from tags   
where uid=111  --  分库分表列  
and (（tags.'env' = 'staging'）and（tags.'ownwer' = 'jack'）and （tags.'create_by' = 'tom'）) -- tag 搜索条件  
and rg_no in (?)   
and is_deleted = ?   
 [ and r_type in (?) ]   
and id>12345  -- next token 分页用   
order by id  -- 保证翻阅数据有序   
limit n; --- 每页行数   
```  
  
  
  
## 数据库方案  
产品: RDS PG   
分区: 业务自己根据账号ID进行分区, 选择对应数据库实例, 以及对应的分区表      
  
### 方法1, 用btree+并行计算 (jsonb采用 filter)    
忽略  
  
  
### 方法2, 用倒排.   
1、必须使用连接池, 单实例的连接总数不建议超过 cpu cores\*3 , 因为PG是进程模型， 连接太多内耗会加大。  3倍可以发挥CPU极致性能。      
2、in 用union all代替  , 或者使用=发起多次请求。    
3、使用 btree_gin    
4、is_deleted使用partial index 代替。 资源是否释放， 基本就2个值。      
5、使用 gin fast update    
6、开启 gin auto analyze     
7、关闭 autovacuum delay     
8、打开序列 cache  
  
  
针对保有资源特别多的查询如何优化?    -- demo场景未对此优化, 性能不存在问题.   
原因: gin 的索引结构, 无法通过索引加速范围搜索 和 排序 (需要cpu硬算)       
优化思路:    
1、强行对数据分组.  如 : id 哈希分片, partial index, 按顺序返回 , 封装为函数    where mod(id,20) = 0 , ... 19. 每次查一个组.    
2、ID 区间分页和排序  用段代替  . 基本不可能实现, 因为条件各异     
3、游标返回. 缺点, 需要持久化连接     
建议使用方法1， 增加索引分片即可。配套的查询修改： select x from tbl where 其他条件 and is_delete=x and mod(id,20)=0 and id>x order by id limit x; 这个查完换下一个分组。 理论上20个分组， 排序消耗降低20倍。    
分页时需记录ID offset， 同时需要记录mod(id,20)的值.   
同样思路的优化case：  
[《推荐系统, 已阅读过滤, 大量CPU和IO浪费的优化思路2 - partial index - hash 分片， 降低过滤量》](../202006/20200610_02.md)   
  
  
## demo  
  
```  
create extension btree_gin;  
```  
  
```  
create table tags (  
  id serial8 primary key,  
  uid int8,  
  r_id VARCHAR(128),  
  r_type VARCHAR(128),  
  rg_no VARCHAR(32),  
  is_deleted int,  
  tags jsonb,  
  unique (uid,r_id)  
) with   
(autovacuum_vacuum_cost_delay=0, toast.autovacuum_vacuum_cost_delay=0);    
```  
  
```  
alter sequence tags_id_seq cache 100;  
```  
  
```  
create index idx_tags_0 on tags using gin (  
  uid,  
  r_type,  
  rg_no,  
  tags jsonb_path_ops  
)   
with (fastupdate=on, gin_pending_list_limit=1024)   
where is_deleted = 0;  
  
create index idx_tags_1 on tags using gin (  
  uid,  
  r_type,  
  rg_no,  
  tags jsonb_path_ops  
)  
with (fastupdate=on, gin_pending_list_limit=1024)   
where is_deleted = 1;  
```  
  
  
生成64K个分区, 实际情况业务自己路由    
  
```  
do language plpgsql $$  
declare  
begin  
  for i in 0..65535 loop  
    execute format('create table tags_%s (like tags including all)', i);  
  end loop;  
end;  
$$;  
```  
  
### 正常分片case  
  
  
- tags_0   
- 500个UID  
- 1万个资源/每用户  
- 200套kv 随机选  
- 50个tag/资源  
- 500万条记录  
  
  
### 极端分片case  
  
- tags_1   
- 1个UID  
- 1000万个资源/每用户  
- 1000套kv 随机选  
- 50个tag/资源  
- 1000万条记录  
  
  
  
### 测试机器  
  
  
- 16c 64G  
- 1.8T ssd  
  
  
### 写入测试数据  
  
```  
create or replace function gen_jsonb (int) returns jsonb as $$  
  select jsonb_object_agg((random()*$1)::int::text, 'abc') from generate_series(1,50) k;  
$$ language sql strict;  
```  
  
#### 正常case  
  
```  
vi ins0.sql  
  
insert into tags_0  
( uid ,  
  r_id ,  
  r_type ,  
  rg_no ,  
  is_deleted ,  
  tags   
)  
select   
generate_series(0,65536*499,65536),  
md5(random()::text),  
(random()*10000)::int::text,  
(random()*100)::int::text,  
random()::int,  
gen_jsonb(200);  
```  
  
```  
pgbench -M prepared -f ./ins0.sql -n -r -P 1 -c 10 -j 10 -t 1000  
  
transaction type: ./ins0.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 10  
number of threads: 10  
number of transactions per client: 1000  
number of transactions actually processed: 10000/10000  
latency average = 73.161 ms  
latency stddev = 30.885 ms  
tps = 134.817801 (including connections establishing)  
tps = 134.827073 (excluding connections establishing)  
statement latencies in milliseconds:  
        73.161  insert into tags_0  
```  
  
每个事务插入500行  
单表写入速度:  67000    
  
  
#### 极端case  
```  
vi ins1.sql  
  
insert into tags_1  
( uid ,  
  r_id ,  
  r_type ,  
  rg_no ,  
  is_deleted ,  
  tags   
)  
select   
1,  
md5(random()::text),  
(random()*10000)::int::text,  
(random()*100)::int::text,  
random()::int,  
gen_jsonb(1000);  
```  
  
```  
pgbench -M prepared -f ./ins1.sql -n -r -P 1 -c 10 -j 10 -t 1000000  
  
transaction type: ./ins1.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 10  
number of threads: 10  
number of transactions per client: 1000000  
number of transactions actually processed: 10000000/10000000  
latency average = 0.299 ms  
latency stddev = 1.491 ms  
tps = 33135.416156 (including connections establishing)  
tps = 33136.015291 (excluding connections establishing)  
statement latencies in milliseconds:  
         0.299  insert into tags_1  
```  
  
  
每个事务插入1行  
单表写入速度:  33135    
  
  
  
### 查询性能  
计划, 所有条件在gin中皆可命中  
  
除了id分页的sort  
  
```  
                                                                                      QUERY PLAN                                                                                         
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
 Limit  (cost=588.74..588.79 rows=20 width=744)  
   ->  Sort  (cost=588.74..589.90 rows=465 width=744)  
         Sort Key: id  
         ->  Bitmap Heap Scan on tags_1  (cost=54.24..576.36 rows=465 width=744)  
               Recheck Cond: ((uid = '1'::bigint) AND (tags @> '{"9": "abc"}'::jsonb) AND (tags @> '{"33": "abc"}'::jsonb) AND (tags @> '{"112": "abc"}'::jsonb) AND (is_deleted = 0))  
               Filter: (id > 100)  
               ->  Bitmap Index Scan on tags_1_uid_r_type_rg_no_tags_idx  (cost=0.00..54.12 rows=465 width=0)  
                     Index Cond: ((uid = '1'::bigint) AND (tags @> '{"9": "abc"}'::jsonb) AND (tags @> '{"33": "abc"}'::jsonb) AND (tags @> '{"112": "abc"}'::jsonb))  
(8 rows)  
```  
  
#### 正常分片查询  
  
```  
vi s0.sql  
  
select * from tags_0   
where uid=0::int8   
-- and r_type ='1'   
and (  
  tags @> '{"0": "abc"}'  
  and tags @> '{"3": "abc"}'  
)  
and is_deleted=0  
and id>100  
order by id  
limit 20;   
```  
  
符合条件的记录共150条.   
  
```  
pgbench -M prepared -n -r -f ./s0.sql -P 1 -c 32 -j 32 -T 120  
```  
  
平均RT 13毫秒  
qps 2450   
  
  
#### 极端分片查询  
  
```  
vi s1.sql  
  
select * from tags_1   
where uid=1::int8   
-- and r_type ='1'   
and (  
  tags @> '{"9": "abc"}'  
  -- or tags @> '{"33": "abc"}'  
  -- and tags @> '{"112": "abc"}'  
)  
and is_deleted=0  
and id>100  
order by id  
limit 20;  
```  
  
符合条件的记录共12000条.   
  
```  
pgbench -M prepared -n -r -f ./s1.sql -P 1 -c 32 -j 32 -T 120  
```  
  
平均RT 13毫秒   
qps 2450   
  
  
#### 命中超过10万条的极端case  
根据选择性, PG优化器自动选择GIN或BTREE.   
  
```  
                                           QUERY PLAN                                             
------------------------------------------------------------------------------------------------  
 Limit  (cost=0.43..167.20 rows=20 width=744)  
   ->  Index Scan using tags_1_pkey on tags_1  (cost=0.43..1265920.91 rows=151819 width=744)  
         Filter: ((tags @> '{"9": "abc"}'::jsonb) AND (uid = '1'::bigint) AND (is_deleted = 0))  
(3 rows)  
```  
  
  
命中 50万条  
  
RT : 1.5毫秒  
  
```  
select * from tags_1   
where uid=1::int8   
-- and r_type ='1'   
and (  
  tags @> '{"9": "abc"}'  
  -- or tags @> '{"33": "abc"}'  
  -- and tags @> '{"112": "abc"}'  
)  
and is_deleted=0  
and id>14899972  
order by id  
limit 20;  
```  
  
命中 25万条  
  
RT : 1.5毫秒  
  
```  
select * from tags_1   
where uid=1::int8   
-- and r_type ='1'   
and (  
  tags @> '{"9": "abc"}'  
  or tags @> '{"33": "abc"}'  
  -- and tags @> '{"112": "abc"}'  
)  
and is_deleted=0  
and id>14899972  
order by id  
limit 20;  
```  
  
以上是比较理想的测试集, 如果这个大UID里面还有其他大的UID, ID的无效filter会更多, 性能会下降.  
  
## 小结  
10亿资源, 每个资源50个tag(用户自定义tag key value), 拆分成32个(16c 64g RDS PG)实例, 每个实例存放2048张表, 约3125万条资源.   
理论上限写入性能: 100W行/s      
理论上限查询性能: 6万/s      RT 约15毫秒 (数据实时可见)  
  
使用了PG 13, GIN倒排索引, btree_gin插件支持jsonb+普通字段的组合搜索.  
  
部署方法参考:  [《PostgreSQL 12 on 阿里云ecs 本地ssd VS essd pl3性能 - 含fio,fsync test,pgbench test，优缺点、云盘PG内核优化建议》](../201912/20191228_04.md)    
  
  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  

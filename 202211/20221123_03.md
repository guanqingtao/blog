## DuckDB 0.6.0 数据批量写入性能优化    
                  
### 作者                  
digoal                  
                  
### 日期                  
2022-11-23                 
                  
### 标签                  
PostgreSQL , DuckDB , 批量写入 , 并行 , 流式持久化 , 保留导入顺序 , 不保证导入顺序 `SET preserve_insertion_order=false`      
                  
----                  
                  
## 背景           
https://duckdb.org/2022/11/14/announcing-duckdb-060.html      
  
1、优化批量导入时入库的机制, 原机制在commit之前, 数据都要先进到内存(超出内存还要写临时文件), 直到commit才开始写数据文件.  0.6.0 在批量导入时会流失入数据文件, 不需要等commit, 回滚时回收数据文件已写入内容.     
  
优势： commit时更快, 第二个是可能能节约内存.   
          
Optimistic writing to disk. In previous DuckDB versions, the data of a single transaction was first loaded into memory, and would only be written to disk on a commit. While this works fine when data is loaded in batches that fit in memory, it does not work well when loading a lot of data in a single transaction, such as when ingesting one very large file into the system.    
    
This version introduces optimistic writing to disk. When loading large data sets in a single transaction, data is compressed and streamed to the database file, even before the `COMMIT` has occurred. When the transaction is committed, the data will already have been written to disk, and no further writing has to happen. On a rollback, any optimistically written data is reclaimed by the system.    
    
2、当读取多个csv文件, 导入到duckdb时, 支持并行导入, 提升查询性能, 也提升导入性能.   
  
Parallel data loading. In addition to optimistically writing data to disk, this release includes support for parallel data loading into individual tables. This greatly improves performance of data loading on machines that have multiple cores (i.e. all modern machines).    
    
DuckDB supports two modes - the order-preserving and the non-order-preserving parallel data load.    
    
The order-preserving load preserves the insertion order so that e.g. the first line in your CSV file is the first line in the DuckDB table. The non-order-preserving load does not offer such guarantees - and instead might re-order the data on load. By default the order-preserving load is used, which involves some extra book-keeping. The preservation of insertion order can be disabled using the `SET preserve_insertion_order=false` statement.    
    
https://github.com/duckdb/duckdb/pull/5033  
  
https://github.com/duckdb/duckdb/pull/5082  
  
Below are the new timings of the h2oai "join" benchmark after this PR (join in quotation brackets because the cost of the queries is dominated by the `CREATE TABLE` statement materializing millions of rows - the join is mostly irrelevant).  
  
Query	|Old	|New  
---|---|---  
Q01	|1.35s	|0.18s  
Q02	|1.63s	|0.22s  
Q03	|1.91s	|0.28s  
Q04	|1.59s	|0.22s  
Q05	|2.31s	|0.45s  
  
  
#### [期望 PostgreSQL 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB for PostgreSQL云原生分布式开源数据库](https://github.com/ApsaraDB/PolarDB-for-PostgreSQL "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  

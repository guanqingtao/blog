## 一起学PolarDB - 第22期 - 为什么高并发数据写入吞吐无法达到磁盘极限-1 
      
### 作者            
digoal    
            
### 日期            
2022-02-14           
     
### 标签            
PostgreSQL , PolarDB    
            
----     
            
## 背景            
懂PostgreSQL, 学PolarDB不难, 就好像有九阳神功护体, 可以快速融会贯通.            
对于DBA只要学会PolarDB精髓即可.            
对于开发者来说不需要学习, 使用PolarDB和PostgreSQL一样.            
      
#### 为什么高并发数据写入吞吐无法达到磁盘极限-1?     
https://www.bilibili.com/video/BV1mr4y167xb/   
  
当高并发写入时, 为什么数据写入吞吐无法达到磁盘极限? 例如磁盘的写入性能是4GB/s, 但是我们不管怎么写入, 都达不到4GB/s. 这是啥原因呢?    
    
社区版本:     
抛开其他的问题, 主要妨碍数据库写入吞吐达到磁盘极限的是几个重大锁   
- 申请 WAL片段的串行排他锁   
- 高并发小事务的ProcArrayEndTrans、GetSnapshotData开销  
- 每次数据文件空间不足时, 一次只扩展1个block, 因此大批量数据写入时, 数据库要频繁扩展数据块  
    - 数据文件扩展 串行排他锁   
    - 索引构建和页扩展 串行排他锁   
- 扩展数据块带来的结果就是数据文件长度的变化, 需要修改inode. 因此文件系统层面: inode 锁   
  
极限测试法(我曾经测试过nvme ssd, 写入速度基本可以达到我那块SSD的物理极限, 3.6 GB/s):    
- 采用unlogged table , 直接避免写WAL(只有当事务结束时才需要写wal)  
- 无索引(同时无pk, uk约束) (避免索引构建和页分裂负担)   
- 多表并行导入(避免单表扩展数据文件的锁冲突瓶颈)  
- 使用大block size, 减少单表扩展数据文件冲突次数  
    - 完全避免扩展block. (清空数据并保留datafile, 并完成垃圾回收, 确保block内空间全部可用)  
- 采用 COPY 协议. copy to tbl ... 简化数据库入库的逻辑路径.   
  
问题:   
在极限测试法中真正有意义(对业务透明)的优化只有“使用大block size”, 但是由于目前PG的一个实例只能选择一种block size规格, 如果选择大的block size, 会导致某些需要小block size的表可能性能变差并浪费更多shared buffer. (例如偏TP的业务) , 同时也浪费带宽(例如只需要取一个page里的几条记录可能只有100多字节但是也要读整个大的block上来, 浪费存储带宽).       
  
高速写入的业务场景, 例如IOT, 时序, feedlog(金融类、互联网用户行为类、游戏行业玩家行为类等等)类比较苦恼.     
    
PolarDB:    
支持一次扩展多个数据块, 通过参数polar_bulk_extend_size控制.   
    - 减少数据文件、索引页扩展导致的大量数据写入的扩展文件排他锁导致的性能瓶颈. 数据大批量写入性能更佳.    
  
参考:  
- [《PostgreSQL 单表并行bulkload的extend file lock 冲突问题解决 - 数据块预分配》](../201805/20180515_03.md)    
- [《parallel blocking|waiting by slow BLOCK extend relation , ExclusiveLock on extension of relation》](../201505/20150511_01.md)    
- [《PostgreSQL bulk COPY load Bottleneck by extend lock waiting》](../201310/20131026_01.md)    
- [《DB吐槽大会,第28期 - PG 每次只扩展1个block》](../202109/20210903_03.md)    
  
  
本期问题1:            
妨碍PostgreSQL社区版本数据库写入吞吐达到磁盘极限的几个重大锁是?   
- a. 写入数据时的表级别排他锁  
- b. 申请 WAL片段的串行排他锁   
- c. 数据文件扩展串行排他锁      
- d. 写入数据时的行级别排他锁   
- e. 索引构建和页扩展串行排他锁   
            
答案:            
- bce      
            
解释:            
- 参考本文内容            
         
本期问题2:            
以下哪些方法对测试数据导入达到磁盘极限有帮助?   
- a. 使用insert  
- b. 使用copy  
- c. 使用upsert  
- d. 使用更大的block size  
- e. 使用更小的block size  
- f. 使用索引  
- g. 不使用索引和pk uk约束  
- h. 使用unlogged table  
- i. 并行导入多个表  
            
答案:            
- bdghi     
            
解释:            
- 参考本文内容     
  
本期问题3:            
PolarDB的什么特性对高速写入的业务场景, 例如IOT, 时序, feedlog类业务有很大的性能提升?    
- a. polar_bulk_extend_size, 预分配数据块  
- b. 存储计算分离功能  
- c. 跨机并行优化器  
- d. wal 管道技术  
            
答案:            
- a    
            
解释:            
- 参考本文内容    
  
  
#### [期望 PostgreSQL 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB for PostgreSQL云原生分布式开源数据库](https://github.com/ApsaraDB/PolarDB-for-PostgreSQL "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  

## 开源PolarDB|PostgreSQL 应用开发者&DBA 公开课 - 3.2 PostgreSQL社区版本必学知识 - 数据库架构、应用、管理、优化等通识    
                      
### 作者                      
digoal                      
                      
### 日期                      
2023-11-11                      
                      
### 标签                      
PostgreSQL , PolarDB , 应用开发者 , DBA , 公开课            
                      
----                      
                      
## 背景                 
          
### 3.2、PostgreSQL社区版本必学知识 - 数据库架构、应用、管理、优化等通识    
这个章节包含了开发者、DBA、架构师应该具备的综合数据库知识和技能, 熟练掌握这个章节应该可以打败70%的程序员掌握的数据库技能.    
  
  
掌握数据库基本知识, 包括数据库的物理和逻辑结构, 权限体系, DDL, DML, DCL, DQL, 高级SQL, 常见数据库操作命令, 数据类型, 对象类型, 索引的使用, 快捷命令, 防火墙, 插件使用, 报错解读, 排错方法, 压测, 代码跟踪方法等.   
  
  
#### 1 创建容器  
```  
docker run --platform linux/amd64 -d -it -P --cap-add=SYS_PTRACE --cap-add SYS_ADMIN --privileged=true --name pg --shm-size=1g --entrypoint /bin/bash registry.cn-hangzhou.aliyuncs.com/digoal/opensource_database:pg14_with_exts  
```  
  
#### 2 进入容器  
```  
docker exec -ti pg bash  
```  
  
#### 3 启动数据库  
```  
su - postgres  
pg_ctl start  
```  
  
#### 4 查看数据库数据目录结构  
  
https://www.postgresql.org/docs/14/storage-file-layout.html  
```  
cd $PGDATA  
ll  
  
total 164K  
-rw------- 1 postgres postgres  29K Oct 17 17:21 postgresql.conf //配置文件  
drwx------ 2 postgres postgres 4.0K Oct 17 17:21 pg_xact // 事务状态  
drwx------ 1 postgres postgres 4.0K Oct 17 17:21 pg_wal // REDO日志  
-rw------- 1 postgres postgres    3 Oct 17 17:21 PG_VERSION // 版本信息  
drwx------ 2 postgres postgres 4.0K Oct 17 17:21 pg_twophase // 2阶段事务状态  
drwx------ 2 postgres postgres 4.0K Oct 17 17:21 pg_tblspc // 自定义表空间软链接  
drwx------ 2 postgres postgres 4.0K Oct 17 17:21 pg_subtrans // 子事务状态  
drwx------ 2 postgres postgres 4.0K Oct 17 17:21 pg_stat // 数据库统计信息持久化存储目录  
drwx------ 2 postgres postgres 4.0K Oct 17 17:21 pg_snapshots // 事务快照信息  
drwx------ 2 postgres postgres 4.0K Oct 17 17:21 pg_serial // 运行中串行隔离级别事务信息  
drwx------ 2 postgres postgres 4.0K Oct 17 17:21 pg_replslot // 复制槽状态信息  
drwx------ 2 postgres postgres 4.0K Oct 17 17:21 pg_notify // 异步消息  
drwx------ 4 postgres postgres 4.0K Oct 17 17:21 pg_multixact // 共享行锁的事务状态  
-rw------- 1 postgres postgres 1.6K Oct 17 17:21 pg_ident.conf // ident认证配置  
drwx------ 2 postgres postgres 4.0K Oct 17 17:21 pg_dynshmem // 动态共享内存子系统信息  
drwx------ 2 postgres postgres 4.0K Oct 17 17:21 pg_commit_ts // 事务提交时间戳数据  
drwxr-xr-x 1 postgres postgres 4.0K Oct 17 17:21 ..  
drwx------ 4 postgres postgres 4.0K Oct 17 17:21 pg_logical // 逻辑decoding状态数据  
drwx------ 1 postgres postgres 4.0K Oct 17 17:21 global // 全局信息, 例如数据库、表空间、用户等  
drwx------ 5 postgres postgres 4.0K Oct 17 17:21 base // 默认表空间  
-rw------- 1 postgres postgres  977 Oct 17 17:21 postgresql.auto.conf // alter system 配置的热配置文件, 优先级高于postgresql.conf  
-rw------- 1 postgres postgres 4.8K Oct 17 17:21 pg_hba.conf // 防火墙配置  
drwx------ 2 postgres postgres 4.0K Nov 10 12:17 log // 数据库运行日志(包括错误日志)  
-rw------- 1 postgres postgres   44 Nov 10 12:17 current_logfiles // 当前日志文件 -- 例如csvlog log/postgresql-2023-11-10_121724.csv  
-rw------- 1 postgres postgres   51 Nov 10 12:17 .s.PGSQL.1921.lock // unix socket 文件锁  
srwxrwxrwx 1 postgres postgres    0 Nov 10 12:17 .s.PGSQL.1921 // unix socket 文件  
-rw------- 1 postgres postgres   36 Nov 10 12:17 postmaster.opts // 数据库启动时的命令行参数  
drwx------ 1 postgres postgres 4.0K Nov 10 12:17 .  
-rw------- 1 postgres postgres   88 Nov 10 12:17 postmaster.pid // 数据库启动时的重要变量信息: PID, 数据目录, 启动时间, 端口, unix socket路径, 共享内存段ID等.  
drwx------ 1 postgres postgres 4.0K Nov 10 12:17 pg_stat_tmp // 数据库统计信息临时存储目录  
```  
  
  
#### 5 查看数据库防火墙配置  
```  
cat pg_hba.conf  
  
  
# PostgreSQL Client Authentication Configuration File  
# ===================================================  
#  
# Refer to the "Client Authentication" section in the PostgreSQL  
# documentation for a complete description of this file.  A short  
# synopsis follows.  
#  
# This file controls: which hosts are allowed to connect, how clients  
# are authenticated, which PostgreSQL user names they can use, which  
# databases they can access.  Records take one of these forms:  
#  
# local         DATABASE  USER  METHOD  [OPTIONS]  
# host          DATABASE  USER  ADDRESS  METHOD  [OPTIONS]  
# hostssl       DATABASE  USER  ADDRESS  METHOD  [OPTIONS]  
# hostnossl     DATABASE  USER  ADDRESS  METHOD  [OPTIONS]  
# hostgssenc    DATABASE  USER  ADDRESS  METHOD  [OPTIONS]  
# hostnogssenc  DATABASE  USER  ADDRESS  METHOD  [OPTIONS]  
#  
# (The uppercase items must be replaced by actual values.)  
#  
# The first field is the connection type:  
# - "local" is a Unix-domain socket  
# - "host" is a TCP/IP socket (encrypted or not)  
# - "hostssl" is a TCP/IP socket that is SSL-encrypted  
# - "hostnossl" is a TCP/IP socket that is not SSL-encrypted  
# - "hostgssenc" is a TCP/IP socket that is GSSAPI-encrypted  
# - "hostnogssenc" is a TCP/IP socket that is not GSSAPI-encrypted  
#  
# DATABASE can be "all", "sameuser", "samerole", "replication", a  
# database name, or a comma-separated list thereof. The "all"  
# keyword does not match "replication". Access to replication  
# must be enabled in a separate record (see example below).  
#  
# USER can be "all", a user name, a group name prefixed with "+", or a  
# comma-separated list thereof.  In both the DATABASE and USER fields  
# you can also write a file name prefixed with "@" to include names  
# from a separate file.  
#  
# ADDRESS specifies the set of hosts the record matches.  It can be a  
# host name, or it is made up of an IP address and a CIDR mask that is  
# an integer (between 0 and 32 (IPv4) or 128 (IPv6) inclusive) that  
# specifies the number of significant bits in the mask.  A host name  
# that starts with a dot (.) matches a suffix of the actual host name.  
# Alternatively, you can write an IP address and netmask in separate  
# columns to specify the set of hosts.  Instead of a CIDR-address, you  
# can write "samehost" to match any of the server's own IP addresses,  
# or "samenet" to match any address in any subnet that the server is  
# directly connected to.  
#  
# METHOD can be "trust", "reject", "md5", "password", "scram-sha-256",  
# "gss", "sspi", "ident", "peer", "pam", "ldap", "radius" or "cert".  
# Note that "password" sends passwords in clear text; "md5" or  
# "scram-sha-256" are preferred since they send encrypted passwords.  
#  
# OPTIONS are a set of options for the authentication in the format  
# NAME=VALUE.  The available options depend on the different  
# authentication methods -- refer to the "Client Authentication"  
# section in the documentation for a list of which options are  
# available for which authentication methods.  
#  
# Database and user names containing spaces, commas, quotes and other  
# special characters must be quoted.  Quoting one of the keywords  
# "all", "sameuser", "samerole" or "replication" makes the name lose  
# its special character, and just match a database or username with  
# that name.  
#  
# This file is read on server startup and when the server receives a  
# SIGHUP signal.  If you edit the file on a running system, you have to  
# SIGHUP the server for the changes to take effect, run "pg_ctl reload",  
# or execute "SELECT pg_reload_conf()".  
#  
# Put your actual configuration here  
# ----------------------------------  
#  
# If you want to allow non-local connections, you need to add more  
# "host" records.  In that case you will also need to make PostgreSQL  
# listen on a non-local interface via the listen_addresses  
# configuration parameter, or via the -i or -h command line switches.  
  
# CAUTION: Configuring the system for local "trust" authentication  
# allows any local user to connect as any PostgreSQL user, including  
# the database superuser.  If you do not trust all your local users,  
# use another authentication method.  
  
  
# TYPE  DATABASE        USER            ADDRESS                 METHOD  
  
# "local" is for Unix domain socket connections only  
local   all             all                                     trust  
# IPv4 local connections:  
host    all             all             127.0.0.1/32            trust  
# IPv6 local connections:  
host    all             all             ::1/128                 trust  
# Allow replication connections from localhost, by a user with the  
# replication privilege.  
local   replication     all                                     trust  
host    replication     all             127.0.0.1/32            trust  
host    replication     all             ::1/128                 trust  
host all all 0.0.0.0/0 scram-sha-256  
```
  
#### 6 查看数据库配置文件  
- https://www.postgresql.org/docs/14/runtime-config.html
- [《2019-PostgreSQL 2天体系化培训 - 适合DBA》](../201901/20190105_01.md)  第三章：实例初始化、基本配置
- [《PostgreSQL 11 postgresql.conf 参数模板 - 珍藏级》](../201812/20181203_01.md)  
- [《EDB PPAS (PostgreSQL plus advanced server) 10 postgresql.conf 参数模板 - 珍藏级》](../201805/20180522_04.md)  
- [《PostgreSQL 10 postgresql.conf 参数模板 - 珍藏级》](../201805/20180522_03.md)  
  
```  
cat postgresql.conf  
# -----------------------------  
# PostgreSQL configuration file  
# -----------------------------  
#  
# This file consists of lines of the form:  
#  
#   name = value  
#  
# (The "=" is optional.)  Whitespace may be used.  Comments are introduced with  
# "#" anywhere on a line.  The complete list of parameter names and allowed  
# values can be found in the PostgreSQL documentation.  
#  
# The commented-out settings shown in this file represent the default values.  
# Re-commenting a setting is NOT sufficient to revert it to the default value;  
# you need to reload the server.  
#  
# This file is read on server startup and when the server receives a SIGHUP  
# signal.  If you edit the file on a running system, you have to SIGHUP the  
# server for the changes to take effect, run "pg_ctl reload", or execute  
# "SELECT pg_reload_conf()".  Some parameters, which are marked below,  
# require a server shutdown and restart to take effect.  
#  
# Any parameter can also be given as a command-line option to the server, e.g.,  
# "postgres -c log_connections=on".  Some parameters can be changed at run time  
# with the "SET" SQL command.  
#  
# Memory units:  B  = bytes            Time units:  us  = microseconds  
#                kB = kilobytes                     ms  = milliseconds  
#                MB = megabytes                     s   = seconds  
#                GB = gigabytes                     min = minutes  
#                TB = terabytes                     h   = hours  
#                                                   d   = days  
  
  
#------------------------------------------------------------------------------  
# FILE LOCATIONS  
#------------------------------------------------------------------------------  
  
# The default values of these variables are driven from the -D command-line  
# option or PGDATA environment variable, represented here as ConfigDir.  
  
#data_directory = 'ConfigDir'		# use data in another directory  
					# (change requires restart)  
#hba_file = 'ConfigDir/pg_hba.conf'	# host-based authentication file  
					# (change requires restart)  
#ident_file = 'ConfigDir/pg_ident.conf'	# ident configuration file  
					# (change requires restart)  
  
# If external_pid_file is not explicitly set, no extra PID file is written.  
#external_pid_file = ''			# write an extra PID file  
					# (change requires restart)  
  
  
#------------------------------------------------------------------------------  
# CONNECTIONS AND AUTHENTICATION  
#------------------------------------------------------------------------------  
  
# - Connection Settings -  
  
#listen_addresses = 'localhost'		# what IP address(es) to listen on;  
					# comma-separated list of addresses;  
					# defaults to 'localhost'; use '*' for all  
					# (change requires restart)  
#port = 5432				# (change requires restart)  
max_connections = 100			# (change requires restart)  
#superuser_reserved_connections = 3	# (change requires restart)  
#unix_socket_directories = '/var/run/postgresql'	# comma-separated list of directories  
					# (change requires restart)  
#unix_socket_group = ''			# (change requires restart)  
#unix_socket_permissions = 0777		# begin with 0 to use octal notation  
					# (change requires restart)  
#bonjour = off				# advertise server via Bonjour  
					# (change requires restart)  
#bonjour_name = ''			# defaults to the computer name  
					# (change requires restart)  
  
# - TCP settings -  
# see "man tcp" for details  
  
#tcp_keepalives_idle = 0		# TCP_KEEPIDLE, in seconds;  
					# 0 selects the system default  
#tcp_keepalives_interval = 0		# TCP_KEEPINTVL, in seconds;  
					# 0 selects the system default  
#tcp_keepalives_count = 0		# TCP_KEEPCNT;  
					# 0 selects the system default  
#tcp_user_timeout = 0			# TCP_USER_TIMEOUT, in milliseconds;  
					# 0 selects the system default  
  
#client_connection_check_interval = 0	# time between checks for client  
					# disconnection while running queries;  
					# 0 for never  
  
# - Authentication -  
  
#authentication_timeout = 1min		# 1s-600s  
#password_encryption = scram-sha-256	# scram-sha-256 or md5  
#db_user_namespace = off  
  
# GSSAPI using Kerberos  
#krb_server_keyfile = 'FILE:${sysconfdir}/krb5.keytab'  
#krb_caseins_users = off  
  
# - SSL -  
  
#ssl = off  
#ssl_ca_file = ''  
#ssl_cert_file = 'server.crt'  
#ssl_crl_file = ''  
#ssl_crl_dir = ''  
#ssl_key_file = 'server.key'  
#ssl_ciphers = 'HIGH:MEDIUM:+3DES:!aNULL' # allowed SSL ciphers  
#ssl_prefer_server_ciphers = on  
#ssl_ecdh_curve = 'prime256v1'  
#ssl_min_protocol_version = 'TLSv1.2'  
#ssl_max_protocol_version = ''  
#ssl_dh_params_file = ''  
#ssl_passphrase_command = ''  
#ssl_passphrase_command_supports_reload = off  
  
  
#------------------------------------------------------------------------------  
# RESOURCE USAGE (except WAL)  
#------------------------------------------------------------------------------  
  
# - Memory -  
  
shared_buffers = 128MB			# min 128kB  
					# (change requires restart)  
#huge_pages = try			# on, off, or try  
					# (change requires restart)  
#huge_page_size = 0			# zero for system default  
					# (change requires restart)  
#temp_buffers = 8MB			# min 800kB  
#max_prepared_transactions = 0		# zero disables the feature  
					# (change requires restart)  
# Caution: it is not advisable to set max_prepared_transactions nonzero unless  
# you actively intend to use prepared transactions.  
#work_mem = 4MB				# min 64kB  
#hash_mem_multiplier = 1.0		# 1-1000.0 multiplier on hash table work_mem  
#maintenance_work_mem = 64MB		# min 1MB  
#autovacuum_work_mem = -1		# min 1MB, or -1 to use maintenance_work_mem  
#logical_decoding_work_mem = 64MB	# min 64kB  
#max_stack_depth = 2MB			# min 100kB  
#shared_memory_type = mmap		# the default is the first option  
					# supported by the operating system:  
					#   mmap  
					#   sysv  
					#   windows  
					# (change requires restart)  
dynamic_shared_memory_type = posix	# the default is the first option  
					# supported by the operating system:  
					#   posix  
					#   sysv  
					#   windows  
					#   mmap  
					# (change requires restart)  
#min_dynamic_shared_memory = 0MB	# (change requires restart)  
  
# - Disk -  
  
#temp_file_limit = -1			# limits per-process temp file space  
					# in kilobytes, or -1 for no limit  
  
# - Kernel Resources -  
  
#max_files_per_process = 1000		# min 64  
					# (change requires restart)  
  
# - Cost-Based Vacuum Delay -  
  
#vacuum_cost_delay = 0			# 0-100 milliseconds (0 disables)  
#vacuum_cost_page_hit = 1		# 0-10000 credits  
#vacuum_cost_page_miss = 2		# 0-10000 credits  
#vacuum_cost_page_dirty = 20		# 0-10000 credits  
#vacuum_cost_limit = 200		# 1-10000 credits  
  
# - Background Writer -  
  
#bgwriter_delay = 200ms			# 10-10000ms between rounds  
#bgwriter_lru_maxpages = 100		# max buffers written/round, 0 disables  
#bgwriter_lru_multiplier = 2.0		# 0-10.0 multiplier on buffers scanned/round  
#bgwriter_flush_after = 512kB		# measured in pages, 0 disables  
  
# - Asynchronous Behavior -  
  
#backend_flush_after = 0		# measured in pages, 0 disables  
#effective_io_concurrency = 1		# 1-1000; 0 disables prefetching  
#maintenance_io_concurrency = 10	# 1-1000; 0 disables prefetching  
#max_worker_processes = 8		# (change requires restart)  
#max_parallel_workers_per_gather = 2	# taken from max_parallel_workers  
#max_parallel_maintenance_workers = 2	# taken from max_parallel_workers  
#max_parallel_workers = 8		# maximum number of max_worker_processes that  
					# can be used in parallel operations  
#parallel_leader_participation = on  
#old_snapshot_threshold = -1		# 1min-60d; -1 disables; 0 is immediate  
					# (change requires restart)  
  
  
#------------------------------------------------------------------------------  
# WRITE-AHEAD LOG  
#------------------------------------------------------------------------------  
  
# - Settings -  
  
#wal_level = replica			# minimal, replica, or logical  
					# (change requires restart)  
#fsync = on				# flush data to disk for crash safety  
					# (turning this off can cause  
					# unrecoverable data corruption)  
#synchronous_commit = on		# synchronization level;  
					# off, local, remote_write, remote_apply, or on  
#wal_sync_method = fsync		# the default is the first option  
					# supported by the operating system:  
					#   open_datasync  
					#   fdatasync (default on Linux and FreeBSD)  
					#   fsync  
					#   fsync_writethrough  
					#   open_sync  
#full_page_writes = on			# recover from partial page writes  
#wal_log_hints = off			# also do full page writes of non-critical updates  
					# (change requires restart)  
#wal_compression = off			# enable compression of full-page writes  
#wal_init_zero = on			# zero-fill new WAL files  
#wal_recycle = on			# recycle WAL files  
#wal_buffers = -1			# min 32kB, -1 sets based on shared_buffers  
					# (change requires restart)  
#wal_writer_delay = 200ms		# 1-10000 milliseconds  
#wal_writer_flush_after = 1MB		# measured in pages, 0 disables  
#wal_skip_threshold = 2MB  
  
#commit_delay = 0			# range 0-100000, in microseconds  
#commit_siblings = 5			# range 1-1000  
  
# - Checkpoints -  
  
#checkpoint_timeout = 5min		# range 30s-1d  
#checkpoint_completion_target = 0.9	# checkpoint target duration, 0.0 - 1.0  
#checkpoint_flush_after = 256kB		# measured in pages, 0 disables  
#checkpoint_warning = 30s		# 0 disables  
max_wal_size = 1GB  
min_wal_size = 80MB  
  
# - Archiving -  
  
#archive_mode = off		# enables archiving; off, on, or always  
				# (change requires restart)  
#archive_command = ''		# command to use to archive a logfile segment  
				# placeholders: %p = path of file to archive  
				#               %f = file name only  
				# e.g. 'test ! -f /mnt/server/archivedir/%f && cp %p /mnt/server/archivedir/%f'  
#archive_timeout = 0		# force a logfile segment switch after this  
				# number of seconds; 0 disables  
  
# - Archive Recovery -  
  
# These are only used in recovery mode.  
  
#restore_command = ''		# command to use to restore an archived logfile segment  
				# placeholders: %p = path of file to restore  
				#               %f = file name only  
				# e.g. 'cp /mnt/server/archivedir/%f %p'  
#archive_cleanup_command = ''	# command to execute at every restartpoint  
#recovery_end_command = ''	# command to execute at completion of recovery  
  
# - Recovery Target -  
  
# Set these only when performing a targeted recovery.  
  
#recovery_target = ''		# 'immediate' to end recovery as soon as a  
                                # consistent state is reached  
				# (change requires restart)  
#recovery_target_name = ''	# the named restore point to which recovery will proceed  
				# (change requires restart)  
#recovery_target_time = ''	# the time stamp up to which recovery will proceed  
				# (change requires restart)  
#recovery_target_xid = ''	# the transaction ID up to which recovery will proceed  
				# (change requires restart)  
#recovery_target_lsn = ''	# the WAL LSN up to which recovery will proceed  
				# (change requires restart)  
#recovery_target_inclusive = on # Specifies whether to stop:  
				# just after the specified recovery target (on)  
				# just before the recovery target (off)  
				# (change requires restart)  
#recovery_target_timeline = 'latest'	# 'current', 'latest', or timeline ID  
				# (change requires restart)  
#recovery_target_action = 'pause'	# 'pause', 'promote', 'shutdown'  
				# (change requires restart)  
  
  
#------------------------------------------------------------------------------  
# REPLICATION  
#------------------------------------------------------------------------------  
  
# - Sending Servers -  
  
# Set these on the primary and on any standby that will send replication data.  
  
#max_wal_senders = 10		# max number of walsender processes  
				# (change requires restart)  
#max_replication_slots = 10	# max number of replication slots  
				# (change requires restart)  
#wal_keep_size = 0		# in megabytes; 0 disables  
#max_slot_wal_keep_size = -1	# in megabytes; -1 disables  
#wal_sender_timeout = 60s	# in milliseconds; 0 disables  
#track_commit_timestamp = off	# collect timestamp of transaction commit  
				# (change requires restart)  
  
# - Primary Server -  
  
# These settings are ignored on a standby server.  
  
#synchronous_standby_names = ''	# standby servers that provide sync rep  
				# method to choose sync standbys, number of sync standbys,  
				# and comma-separated list of application_name  
				# from standby(s); '*' = all  
#vacuum_defer_cleanup_age = 0	# number of xacts by which cleanup is delayed  
  
# - Standby Servers -  
  
# These settings are ignored on a primary server.  
  
#primary_conninfo = ''			# connection string to sending server  
#primary_slot_name = ''			# replication slot on sending server  
#promote_trigger_file = ''		# file name whose presence ends recovery  
#hot_standby = on			# "off" disallows queries during recovery  
					# (change requires restart)  
#max_standby_archive_delay = 30s	# max delay before canceling queries  
					# when reading WAL from archive;  
					# -1 allows indefinite delay  
#max_standby_streaming_delay = 30s	# max delay before canceling queries  
					# when reading streaming WAL;  
					# -1 allows indefinite delay  
#wal_receiver_create_temp_slot = off	# create temp slot if primary_slot_name  
					# is not set  
#wal_receiver_status_interval = 10s	# send replies at least this often  
					# 0 disables  
#hot_standby_feedback = off		# send info from standby to prevent  
					# query conflicts  
#wal_receiver_timeout = 60s		# time that receiver waits for  
					# communication from primary  
					# in milliseconds; 0 disables  
#wal_retrieve_retry_interval = 5s	# time to wait before retrying to  
					# retrieve WAL after a failed attempt  
#recovery_min_apply_delay = 0		# minimum delay for applying changes during recovery  
  
# - Subscribers -  
  
# These settings are ignored on a publisher.  
  
#max_logical_replication_workers = 4	# taken from max_worker_processes  
					# (change requires restart)  
#max_sync_workers_per_subscription = 2	# taken from max_logical_replication_workers  
  
  
#------------------------------------------------------------------------------  
# QUERY TUNING  
#------------------------------------------------------------------------------  
  
# - Planner Method Configuration -  
  
#enable_async_append = on  
#enable_bitmapscan = on  
#enable_gathermerge = on  
#enable_hashagg = on  
#enable_hashjoin = on  
#enable_incremental_sort = on  
#enable_indexscan = on  
#enable_indexonlyscan = on  
#enable_material = on  
#enable_memoize = on  
#enable_mergejoin = on  
#enable_nestloop = on  
#enable_parallel_append = on  
#enable_parallel_hash = on  
#enable_partition_pruning = on  
#enable_partitionwise_join = off  
#enable_partitionwise_aggregate = off  
#enable_seqscan = on  
#enable_sort = on  
#enable_tidscan = on  
  
# - Planner Cost Constants -  
  
#seq_page_cost = 1.0			# measured on an arbitrary scale  
#random_page_cost = 4.0			# same scale as above  
#cpu_tuple_cost = 0.01			# same scale as above  
#cpu_index_tuple_cost = 0.005		# same scale as above  
#cpu_operator_cost = 0.0025		# same scale as above  
#parallel_setup_cost = 1000.0	# same scale as above  
#parallel_tuple_cost = 0.1		# same scale as above  
#min_parallel_table_scan_size = 8MB  
#min_parallel_index_scan_size = 512kB  
#effective_cache_size = 4GB  
  
#jit_above_cost = 100000		# perform JIT compilation if available  
					# and query more expensive than this;  
					# -1 disables  
#jit_inline_above_cost = 500000		# inline small functions if query is  
					# more expensive than this; -1 disables  
#jit_optimize_above_cost = 500000	# use expensive JIT optimizations if  
					# query is more expensive than this;  
					# -1 disables  
  
# - Genetic Query Optimizer -  
  
#geqo = on  
#geqo_threshold = 12  
#geqo_effort = 5			# range 1-10  
#geqo_pool_size = 0			# selects default based on effort  
#geqo_generations = 0			# selects default based on effort  
#geqo_selection_bias = 2.0		# range 1.5-2.0  
#geqo_seed = 0.0			# range 0.0-1.0  
  
# - Other Planner Options -  
  
#default_statistics_target = 100	# range 1-10000  
#constraint_exclusion = partition	# on, off, or partition  
#cursor_tuple_fraction = 0.1		# range 0.0-1.0  
#from_collapse_limit = 8  
#jit = on				# allow JIT compilation  
#join_collapse_limit = 8		# 1 disables collapsing of explicit  
					# JOIN clauses  
#plan_cache_mode = auto			# auto, force_generic_plan or  
					# force_custom_plan  
  
  
#------------------------------------------------------------------------------  
# REPORTING AND LOGGING  
#------------------------------------------------------------------------------  
  
# - Where to Log -  
  
#log_destination = 'stderr'		# Valid values are combinations of  
					# stderr, csvlog, syslog, and eventlog,  
					# depending on platform.  csvlog  
					# requires logging_collector to be on.  
  
# This is used when logging to stderr:  
#logging_collector = off		# Enable capturing of stderr and csvlog  
					# into log files. Required to be on for  
					# csvlogs.  
					# (change requires restart)  
  
# These are only used if logging_collector is on:  
#log_directory = 'log'			# directory where log files are written,  
					# can be absolute or relative to PGDATA  
#log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'	# log file name pattern,  
					# can include strftime() escapes  
#log_file_mode = 0600			# creation mode for log files,  
					# begin with 0 to use octal notation  
#log_rotation_age = 1d			# Automatic rotation of logfiles will  
					# happen after that time.  0 disables.  
#log_rotation_size = 10MB		# Automatic rotation of logfiles will  
					# happen after that much log output.  
					# 0 disables.  
#log_truncate_on_rotation = off		# If on, an existing log file with the  
					# same name as the new log file will be  
					# truncated rather than appended to.  
					# But such truncation only occurs on  
					# time-driven rotation, not on restarts  
					# or size-driven rotation.  Default is  
					# off, meaning append to existing files  
					# in all cases.  
  
# These are relevant when logging to syslog:  
#syslog_facility = 'LOCAL0'  
#syslog_ident = 'postgres'  
#syslog_sequence_numbers = on  
#syslog_split_messages = on  
  
# This is only relevant when logging to eventlog (Windows):  
# (change requires restart)  
#event_source = 'PostgreSQL'  
  
# - When to Log -  
  
#log_min_messages = warning		# values in order of decreasing detail:  
					#   debug5  
					#   debug4  
					#   debug3  
					#   debug2  
					#   debug1  
					#   info  
					#   notice  
					#   warning  
					#   error  
					#   log  
					#   fatal  
					#   panic  
  
#log_min_error_statement = error	# values in order of decreasing detail:  
					#   debug5  
					#   debug4  
					#   debug3  
					#   debug2  
					#   debug1  
					#   info  
					#   notice  
					#   warning  
					#   error  
					#   log  
					#   fatal  
					#   panic (effectively off)  
  
#log_min_duration_statement = -1	# -1 is disabled, 0 logs all statements  
					# and their durations, > 0 logs only  
					# statements running at least this number  
					# of milliseconds  
  
#log_min_duration_sample = -1		# -1 is disabled, 0 logs a sample of statements  
					# and their durations, > 0 logs only a sample of  
					# statements running at least this number  
					# of milliseconds;  
					# sample fraction is determined by log_statement_sample_rate  
  
#log_statement_sample_rate = 1.0	# fraction of logged statements exceeding  
					# log_min_duration_sample to be logged;  
					# 1.0 logs all such statements, 0.0 never logs  
  
  
#log_transaction_sample_rate = 0.0	# fraction of transactions whose statements  
					# are logged regardless of their duration; 1.0 logs all  
					# statements from all transactions, 0.0 never logs  
  
# - What to Log -  
  
#debug_print_parse = off  
#debug_print_rewritten = off  
#debug_print_plan = off  
#debug_pretty_print = on  
#log_autovacuum_min_duration = -1	# log autovacuum activity;  
					# -1 disables, 0 logs all actions and  
					# their durations, > 0 logs only  
					# actions running at least this number  
					# of milliseconds.  
#log_checkpoints = off  
#log_connections = off  
#log_disconnections = off  
#log_duration = off  
#log_error_verbosity = default		# terse, default, or verbose messages  
#log_hostname = off  
#log_line_prefix = '%m [%p] '		# special values:  
					#   %a = application name  
					#   %u = user name  
					#   %d = database name  
					#   %r = remote host and port  
					#   %h = remote host  
					#   %b = backend type  
					#   %p = process ID  
					#   %P = process ID of parallel group leader  
					#   %t = timestamp without milliseconds  
					#   %m = timestamp with milliseconds  
					#   %n = timestamp with milliseconds (as a Unix epoch)  
					#   %Q = query ID (0 if none or not computed)  
					#   %i = command tag  
					#   %e = SQL state  
					#   %c = session ID  
					#   %l = session line number  
					#   %s = session start timestamp  
					#   %v = virtual transaction ID  
					#   %x = transaction ID (0 if none)  
					#   %q = stop here in non-session  
					#        processes  
					#   %% = '%'  
					# e.g. '<%u%%%d> '  
#log_lock_waits = off			# log lock waits >= deadlock_timeout  
#log_recovery_conflict_waits = off	# log standby recovery conflict waits  
					# >= deadlock_timeout  
#log_parameter_max_length = -1		# when logging statements, limit logged  
					# bind-parameter values to N bytes;  
					# -1 means print in full, 0 disables  
#log_parameter_max_length_on_error = 0	# when logging an error, limit logged  
					# bind-parameter values to N bytes;  
					# -1 means print in full, 0 disables  
#log_statement = 'none'			# none, ddl, mod, all  
#log_replication_commands = off  
#log_temp_files = -1			# log temporary files equal or larger  
					# than the specified size in kilobytes;  
					# -1 disables, 0 logs all temp files  
log_timezone = 'Etc/UTC'  
  
  
#------------------------------------------------------------------------------  
# PROCESS TITLE  
#------------------------------------------------------------------------------  
  
#cluster_name = ''			# added to process titles if nonempty  
					# (change requires restart)  
#update_process_title = on  
  
  
#------------------------------------------------------------------------------  
# STATISTICS  
#------------------------------------------------------------------------------  
  
# - Query and Index Statistics Collector -  
  
#track_activities = on  
#track_activity_query_size = 1024	# (change requires restart)  
#track_counts = on  
#track_io_timing = off  
#track_wal_io_timing = off  
#track_functions = none			# none, pl, all  
#stats_temp_directory = 'pg_stat_tmp'  
  
  
# - Monitoring -  
  
#compute_query_id = auto  
#log_statement_stats = off  
#log_parser_stats = off  
#log_planner_stats = off  
#log_executor_stats = off  
  
  
#------------------------------------------------------------------------------  
# AUTOVACUUM  
#------------------------------------------------------------------------------  
  
#autovacuum = on			# Enable autovacuum subprocess?  'on'  
					# requires track_counts to also be on.  
#autovacuum_max_workers = 3		# max number of autovacuum subprocesses  
					# (change requires restart)  
#autovacuum_naptime = 1min		# time between autovacuum runs  
#autovacuum_vacuum_threshold = 50	# min number of row updates before  
					# vacuum  
#autovacuum_vacuum_insert_threshold = 1000	# min number of row inserts  
					# before vacuum; -1 disables insert  
					# vacuums  
#autovacuum_analyze_threshold = 50	# min number of row updates before  
					# analyze  
#autovacuum_vacuum_scale_factor = 0.2	# fraction of table size before vacuum  
#autovacuum_vacuum_insert_scale_factor = 0.2	# fraction of inserts over table  
					# size before insert vacuum  
#autovacuum_analyze_scale_factor = 0.1	# fraction of table size before analyze  
#autovacuum_freeze_max_age = 200000000	# maximum XID age before forced vacuum  
					# (change requires restart)  
#autovacuum_multixact_freeze_max_age = 400000000	# maximum multixact age  
					# before forced vacuum  
					# (change requires restart)  
#autovacuum_vacuum_cost_delay = 2ms	# default vacuum cost delay for  
					# autovacuum, in milliseconds;  
					# -1 means use vacuum_cost_delay  
#autovacuum_vacuum_cost_limit = -1	# default vacuum cost limit for  
					# autovacuum, -1 means use  
					# vacuum_cost_limit  
  
  
#------------------------------------------------------------------------------  
# CLIENT CONNECTION DEFAULTS  
#------------------------------------------------------------------------------  
  
# - Statement Behavior -  
  
#client_min_messages = notice		# values in order of decreasing detail:  
					#   debug5  
					#   debug4  
					#   debug3  
					#   debug2  
					#   debug1  
					#   log  
					#   notice  
					#   warning  
					#   error  
#search_path = '"$user", public'	# schema names  
#row_security = on  
#default_table_access_method = 'heap'  
#default_tablespace = ''		# a tablespace name, '' uses the default  
#default_toast_compression = 'pglz'	# 'pglz' or 'lz4'  
#temp_tablespaces = ''			# a list of tablespace names, '' uses  
					# only default tablespace  
#check_function_bodies = on  
#default_transaction_isolation = 'read committed'  
#default_transaction_read_only = off  
#default_transaction_deferrable = off  
#session_replication_role = 'origin'  
#statement_timeout = 0			# in milliseconds, 0 is disabled  
#lock_timeout = 0			# in milliseconds, 0 is disabled  
#idle_in_transaction_session_timeout = 0	# in milliseconds, 0 is disabled  
#idle_session_timeout = 0		# in milliseconds, 0 is disabled  
#vacuum_freeze_table_age = 150000000  
#vacuum_freeze_min_age = 50000000  
#vacuum_failsafe_age = 1600000000  
#vacuum_multixact_freeze_table_age = 150000000  
#vacuum_multixact_freeze_min_age = 5000000  
#vacuum_multixact_failsafe_age = 1600000000  
#bytea_output = 'hex'			# hex, escape  
#xmlbinary = 'base64'  
#xmloption = 'content'  
#gin_pending_list_limit = 4MB  
  
# - Locale and Formatting -  
  
datestyle = 'iso, mdy'  
#intervalstyle = 'postgres'  
timezone = 'Etc/UTC'  
#timezone_abbreviations = 'Default'     # Select the set of available time zone  
					# abbreviations.  Currently, there are  
					#   Default  
					#   Australia (historical usage)  
					#   India  
					# You can create your own file in  
					# share/timezonesets/.  
#extra_float_digits = 1			# min -15, max 3; any value >0 actually  
					# selects precise output mode  
#client_encoding = sql_ascii		# actually, defaults to database  
					# encoding  
  
# These settings are initialized by initdb, but they can be changed.  
lc_messages = 'en_US.UTF-8'			# locale for system error message  
					# strings  
lc_monetary = 'en_US.UTF-8'			# locale for monetary formatting  
lc_numeric = 'en_US.UTF-8'			# locale for number formatting  
lc_time = 'en_US.UTF-8'				# locale for time formatting  
  
# default configuration for text search  
default_text_search_config = 'pg_catalog.english'  
  
# - Shared Library Preloading -  
  
#local_preload_libraries = ''  
#session_preload_libraries = ''  
#shared_preload_libraries = ''	# (change requires restart)  
#jit_provider = 'llvmjit'		# JIT library to use  
  
# - Other Defaults -  
  
#dynamic_library_path = '$libdir'  
#extension_destdir = ''			# prepend path when loading extensions  
					# and shared objects (added by Debian)  
#gin_fuzzy_search_limit = 0  
  
  
#------------------------------------------------------------------------------  
# LOCK MANAGEMENT  
#------------------------------------------------------------------------------  
  
#deadlock_timeout = 1s  
#max_locks_per_transaction = 64		# min 10  
					# (change requires restart)  
#max_pred_locks_per_transaction = 64	# min 10  
					# (change requires restart)  
#max_pred_locks_per_relation = -2	# negative values mean  
					# (max_pred_locks_per_transaction  
					#  / -max_pred_locks_per_relation) - 1  
#max_pred_locks_per_page = 2            # min 0  
  
  
#------------------------------------------------------------------------------  
# VERSION AND PLATFORM COMPATIBILITY  
#------------------------------------------------------------------------------  
  
# - Previous PostgreSQL Versions -  
  
#array_nulls = on  
#backslash_quote = safe_encoding	# on, off, or safe_encoding  
#escape_string_warning = on  
#lo_compat_privileges = off  
#quote_all_identifiers = off  
#standard_conforming_strings = on  
#synchronize_seqscans = on  
  
# - Other Platforms and Clients -  
  
#transform_null_equals = off  
  
  
#------------------------------------------------------------------------------  
# ERROR HANDLING  
#------------------------------------------------------------------------------  
  
#exit_on_error = off			# terminate session on any error?  
#restart_after_crash = on		# reinitialize after backend crash?  
#data_sync_retry = off			# retry or panic on failure to fsync  
					# data?  
					# (change requires restart)  
#recovery_init_sync_method = fsync	# fsync, syncfs (Linux 5.8+)  
  
  
#------------------------------------------------------------------------------  
# CONFIG FILE INCLUDES  
#------------------------------------------------------------------------------  
  
# These options allow settings to be loaded from files other than the  
# default postgresql.conf.  Note that these are directives, not variable  
# assignments, so they can usefully be given more than once.  
  
#include_dir = '...'			# include files ending in '.conf' from  
					# a directory, e.g., 'conf.d'  
#include_if_exists = '...'		# include file only if it exists  
#include = '...'			# include file  
  
  
#------------------------------------------------------------------------------  
# CUSTOMIZED OPTIONS  
#------------------------------------------------------------------------------  
  
# Add settings for extensions here  
```  
  
  
  
```  
postgres@6f60081d4ace:~/14/pgdata$ grep "^[a-z]" postgresql.conf|awk -F "#" '{print $1}'  
max_connections = 100			  
shared_buffers = 128MB			  
dynamic_shared_memory_type = posix	  
max_wal_size = 1GB  
min_wal_size = 80MB  
log_timezone = 'Etc/UTC'  
datestyle = 'iso, mdy'  
timezone = 'Etc/UTC'  
lc_messages = 'en_US.UTF-8'			  
lc_monetary = 'en_US.UTF-8'			  
lc_numeric = 'en_US.UTF-8'			  
lc_time = 'en_US.UTF-8'				  
default_text_search_config = 'pg_catalog.english'  
```  
  
`postgresql.auto.conf` // `alter system` 配置的热配置文件, 优先级高于`postgresql.conf`  
```  
postgres@6f60081d4ace:~/14/pgdata$ cat postgresql.auto.conf   
# Do not edit this file manually!  
# It will be overwritten by the ALTER SYSTEM command.  
listen_addresses = '0.0.0.0'  
port = 1921  
max_connections = 2000  
unix_socket_directories = '., /var/run/postgresql'  
shared_buffers = 128MB  
dynamic_shared_memory_type = posix  
vacuum_cost_delay = 0  
bgwriter_delay = 20ms  
bgwriter_lru_maxpages = 500  
bgwriter_lru_multiplier = 5.0  
max_parallel_workers_per_gather = 0  
synchronous_commit = off  
wal_compression = on  
wal_writer_delay = 10ms  
max_wal_size = 1GB   
min_wal_size = 80MB   
random_page_cost = 1.1  
log_destination = 'csvlog'  
logging_collector = on  
log_truncate_on_rotation = on  
log_timezone = 'Etc/UTC'   
autovacuum = on  
autovacuum_vacuum_cost_delay = 0ms  
vacuum_freeze_table_age = 750000000   
vacuum_multixact_freeze_table_age = 750000000   
datestyle = 'iso, mdy'   
timezone = 'Etc/UTC'   
lc_messages = 'en_US.UTF-8'  
lc_monetary = 'en_US.UTF-8'  
lc_numeric = 'en_US.UTF-8'  
lc_time = 'en_US.UTF-8'  
default_text_search_config = 'pg_catalog.english'  
```  
  
  
```  
postgres@6f60081d4ace:~/14/pgdata$ psql  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
db1=> show max_connections ;  
 max_connections   
-----------------  
 2000  
(1 row)  
```  
  
  
  
#### 6 查看数据库日志文件  
```  
cd $PGDATA/log  
ll  
  
total 20K  
drwx------ 2 postgres postgres 4.0K Nov 10 12:17 .  
-rw------- 1 postgres postgres  162 Nov 10 12:17 postgresql-2023-11-10_121724.log  
drwx------ 1 postgres postgres 4.0K Nov 10 12:17 ..  
-rw------- 1 postgres postgres 1.3K Nov 10 12:17 postgresql-2023-11-10_121724.csv  
```  
  
#### 7 查看数据库bin目录内容  
```  
cd $PGHOME/bin  
ll  
  
total 15M  
-rwxr-xr-x 1 root root  26K May  2  2023 pg_send_cancellation  
-rwxr-xr-x 1 root root  47K Aug  8 08:16 vacuumlo // 清除未被关联的大对象  
-rwxr-xr-x 1 root root  88K Aug  8 08:16 vacuumdb // 垃圾回收  
-rwxr-xr-x 1 root root  87K Aug  8 08:16 reindexdb // 重建索引  
-rwxr-xr-x 1 root root 724K Aug  8 08:16 psql // SQL客户端  
lrwxrwxrwx 1 root root    8 Aug  8 08:16 postmaster -> postgres // main进程命令  
-rwxr-xr-x 1 root root 8.2M Aug  8 08:16 postgres // main进程命令  
-rwxr-xr-x 1 root root 103K Aug  8 08:16 pg_waldump // 分析wal日志关键信息  
-rwxr-xr-x 1 root root 103K Aug  8 08:16 pg_verifybackup // 校验物理备份文件健康状态  
-rwxr-xr-x 1 root root 155K Aug  8 08:16 pg_upgrade // 升级大版本  
-rwxr-xr-x 1 root root  39K Aug  8 08:16 pg_test_timing // 测试时钟性能  
-rwxr-xr-x 1 root root  47K Aug  8 08:16 pg_test_fsync // 测试文件系统的IO延迟指标  
-rwxr-xr-x 1 root root 135K Aug  8 08:16 pg_rewind // 回卷数据库集群到过去的某个时刻  
-rwxr-xr-x 1 root root 192K Aug  8 08:16 pg_restore // 逻辑还原  
-rwxr-xr-x 1 root root  67K Aug  8 08:16 pg_resetwal // 暴力修改控制文件, 以抛弃不一致的wal/redo文件带来的无法启动问题  
-rwxr-xr-x 1 root root  91K Aug  8 08:16 pg_recvlogical // 通过流复制协议接收逻辑日志  
-rwxr-xr-x 1 root root  91K Aug  8 08:16 pg_receivewal // 通过流复制协议接收wal日志  
-rwxr-xr-x 1 root root  71K Aug  8 08:16 pg_isready // 通过wire protocol检测数据库实例状态  
-rwxr-xr-x 1 root root 116K Aug  8 08:16 pg_dumpall // 逻辑备份所有数据库  
-rwxr-xr-x 1 root root 425K Aug  8 08:16 pg_dump // 逻辑备份单个数据库  
-rwxr-xr-x 1 root root  75K Aug  8 08:16 pg_ctl // 数据库实例控制命令  
-rwxr-xr-x 1 root root  63K Aug  8 08:16 pg_controldata // 查询控制文件信息  
-rwxr-xr-x 1 root root  47K Aug  8 08:16 pg_config // 查询数据库集群软件编译信息  
-rwxr-xr-x 1 root root  63K Aug  8 08:16 pg_checksums // 通过checksum检查数据文件完整性  
-rwxr-xr-x 1 root root 188K Aug  8 08:16 pgbench // 模拟数据库压力测试  
-rwxr-xr-x 1 root root 124K Aug  8 08:16 pg_basebackup // 物理备份  
-rwxr-xr-x 1 root root  47K Aug  8 08:16 pg_archivecleanup // 清理归档文件  
-rwxr-xr-x 1 root root 104K Aug  8 08:16 pg_amcheck // 数据可靠性检测  
-rwxr-xr-x 1 root root  47K Aug  8 08:16 oid2name // OID转换  
-rwxr-xr-x 1 root root 148K Aug  8 08:16 initdb // 初始化数据库实例  
-rwxr-xr-x 1 root root  71K Aug  8 08:16 dropuser // 删除用户  
-rwxr-xr-x 1 root root  71K Aug  8 08:16 dropdb // 删除数据库  
-rwxr-xr-x 1 root root  80K Aug  8 08:16 createuser // 创建用户  
-rwxr-xr-x 1 root root  83K Aug  8 08:16 createdb // 创建数据库  
-rwxr-xr-x 1 root root  71K Aug  8 08:16 clusterdb // 使用索引来聚集数据  
-rwxr-xr-x 1 root root  31K Sep  4 10:37 ogr_fdw_info // ogr外部表状态  
-rwxr-xr-x 1 root root 104K Sep 17 18:43 pg_repack // 以最短时间的锁来回收膨胀表/索引占用的物理空间  
-rwxr-xr-x 1 root root 4.3K Sep 21 06:49 run_refresh.py  
-rwxr-xr-x 1 root root 8.7K Oct 17 13:39 pg_dump_anon.sh  
-rwxr-xr-x 1 root root 9.1K Oct 17 13:52 postgresql // pg_bulkload相关命令  
-rwxr-xr-x 1 root root 318K Oct 17 13:52 pg_bulkload // 绕过wal直接写数据文件的高速批量数据导入工具  
-rwxr-xr-x 1 root root 610K Oct 17 14:50 pg_rman // 块级别增量备份/恢复数据库工具  
-rwxr-xr-x 1 root root 589K Oct 17 17:17 pg_statsinfod // 数据库统计工具  
-rwxr-xr-x 1 root root  987 Oct 17 17:17 archive_pglog.sh  
-rwxr-xr-x 1 root root 346K Oct 17 17:17 pg_statsinfo // 数据库统计工具  
drwxr-xr-x 1 root root 4.0K Oct 17 17:17 .  
drwxr-xr-x 1 root root 4.0K Oct 17 17:20 ..  
```  
  
#### 8 查看数据库相关环境变量  
https://www.postgresql.org/docs/14/libpq-envars.html  
  
```  
cat ~/.bash_profile   
  
#  add by digoal  
alias rm='rm -i'  
alias cp='cp -i'  
alias ll='ls -larth'  
alias mv='mv -i'  
export PGHOME=/usr/lib/postgresql/14  
export PATH=$PGHOME/bin:$PATH  
export LD_LIBRARY_PATH=$PGHOME/lib:/usr/local/lib:/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH  
export PGDATA=/var/lib/postgresql/14/pgdata  
export PGUSER=postgres  
export PGHOST=$PGDATA  
export PGPORT=1921  
export PGDATABASE=postgres  
export LC_ALL=en_US.UTF-8  
export LD_LIBRARY_PATH=$PGHOME/lib/oracle:$LD_LIBRARY_PATH  
export ORACLE_HOME=$PGHOME/lib/oracle  
export TNS_ADMIN=$ORACLE_HOME/network/admin/  
```  
  
#### 9 详细的连接参数  
  
https://www.postgresql.org/docs/14/libpq-connect.html#LIBPQ-CONNSTRING  
  
```  
postgresql://[userspec@][hostspec][/dbname][?paramspec]  
  
where userspec is:  
user[:password]  
  
and hostspec is:  
[host][:port][,...]  
  
and paramspec is:  
name=value[&...]  
```  
  
#### 10 登陆数据库  
```  
psql  
```  
  
#### 11 查看数据库版本  
```  
db1=> select version();  
                                                           version                                                             
-----------------------------------------------------------------------------------------------------------------------------  
 PostgreSQL 14.9 (Debian 14.9-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit  
(1 row)  
```  
  
#### 12 创建用户  
```  
db1=> create role r1 login encrypted password 'pwd123';  
CREATE ROLE  
```  
  
#### 13 创建表空间  
```  
cd $PGDATA/pg_tblspc  
pwd  
  /var/lib/postgresql/14/pgdata/pg_tblspc  
mkdir tbs1  
mkdir tbs2  
  
  
db1=> create tablespace db1_data location '/var/lib/postgresql/14/pgdata/pg_tblspc/tbs1';  
WARNING:  tablespace location should not be inside the data directory  
CREATE TABLESPACE  
  
db1=> create tablespace db1_idx location '/var/lib/postgresql/14/pgdata/pg_tblspc/tbs2';  
WARNING:  tablespace location should not be inside the data directory  
CREATE TABLESPACE  
  
db1=> \db  
                         List of tablespaces  
    Name    |  Owner   |                   Location                     
------------+----------+----------------------------------------------  
 db1_data   | postgres | /var/lib/postgresql/14/pgdata/pg_tblspc/tbs1  
 db1_idx    | postgres | /var/lib/postgresql/14/pgdata/pg_tblspc/tbs2  
 pg_default | postgres |   
 pg_global  | postgres |   
(4 rows)  
```  
  
正常情况不建议把表空间放在数据库数据目录, 这里只是为了演示功能. 实际情况建议根据空间和性能需求, 将表空间放在独立的文件系统中.   
  
#### 14 创建数据库  
```  
db1=> \h create database  
Command:     CREATE DATABASE  
Description: create a new database  
Syntax:  
CREATE DATABASE name  
    [ WITH ] [ OWNER [=] user_name ]  
           [ TEMPLATE [=] template ]  
           [ ENCODING [=] encoding ]  
           [ LOCALE [=] locale ]  
           [ LC_COLLATE [=] lc_collate ]  
           [ LC_CTYPE [=] lc_ctype ]  
           [ TABLESPACE [=] tablespace_name ]  
           [ ALLOW_CONNECTIONS [=] allowconn ]  
           [ CONNECTION LIMIT [=] connlimit ]  
           [ IS_TEMPLATE [=] istemplate ]  
  
URL: https://www.postgresql.org/docs/14/sql-createdatabase.html  
```  
  
```  
db1=> create database db1 with owner r1 template template0 encoding 'UTF-8' ;  
CREATE DATABASE  
db1=> \l+  
                                                                 List of databases  
   Name    |  Owner   | Encoding | Collate |   Ctype    |   Access privileges   |  Size   | Tablespace |                Description                   
-----------+----------+----------+---------+------------+-----------------------+---------+------------+--------------------------------------------  
 db1       | r1       | UTF8     | C       | en_US.UTF8 |                       | 8401 kB | pg_default |   
 postgres  | postgres | UTF8     | C       | en_US.UTF8 |                       | 8553 kB | pg_default | default administrative connection database  
 template0 | postgres | UTF8     | C       | en_US.UTF8 | =c/postgres          +| 8401 kB | pg_default | unmodifiable empty database  
           |          |          |         |            | postgres=CTc/postgres |         |            |   
 template1 | postgres | UTF8     | C       | en_US.UTF8 | =c/postgres          +| 8401 kB | pg_default | default template for new databases  
           |          |          |         |            | postgres=CTc/postgres |         |            |   
(4 rows)  
```  
  
#### 15 进入数据库  
```  
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
```  
  
#### 16 创建schema  
```  
db1=> create schema s1;  
CREATE SCHEMA  
```  
  
#### 17 配置```search_path```搜索路径  
```  
db1=> show search_path ;  
   search_path     
-----------------  
 "$user", public  
(1 row)  
  
db1=> alter role r1 set search_path ="$user",s1,public;  
ALTER ROLE  
  
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
  
db1=> show search_path ;  
     search_path       
---------------------  
 "$user", s1, public  
(1 row)  
```  
  
#### 18 创建表  
```  
db1=> create table tbl (id int, info text, ts timestamp);  
CREATE TABLE  
db1=> \d+ tbl  
                                                       Table "s1.tbl"  
 Column |            Type             | Collation | Nullable | Default | Storage  | Compression | Stats target | Description   
--------+-----------------------------+-----------+----------+---------+----------+-------------+--------------+-------------  
 id     | integer                     |           |          |         | plain    |             |              |   
 info   | text                        |           |          |         | extended |             |              |   
 ts     | timestamp without time zone |           |          |         | plain    |             |              |   
Access method: heap  
```  
  
#### 19 插入  
```  
db1=> insert into tbl values (1,'test',now());  
INSERT 0 1  
```  
  
#### 20 批量插入  
```  
db1=> insert into tbl values (2,'test',now()), (3,'test3',now()), (4,'test4',now());  
INSERT 0 3  
```  
  
#### 21 查询  
```  
db1=> select * from tbl;  
 id | info  |             ts               
----+-------+----------------------------  
  1 | test  | 2023-11-10 12:30:29.073813  
  2 | test  | 2023-11-10 12:31:03.545101  
  3 | test3 | 2023-11-10 12:31:03.545101  
  4 | test4 | 2023-11-10 12:31:03.545101  
(4 rows)  
```  
  
#### 22 查看执行计划  
```  
db1=> insert into tbl select generate_series(1,100000), md5(random()::Text), clock_timestamp();  
INSERT 0 100000  
```  
  
```  
db1=> \h explain  
Command:     EXPLAIN  
Description: show the execution plan of a statement  
Syntax:  
EXPLAIN [ ( option [, ...] ) ] statement  
EXPLAIN [ ANALYZE ] [ VERBOSE ] statement  
  
where option can be one of:  
  
    ANALYZE [ boolean ]  
    VERBOSE [ boolean ]  
    COSTS [ boolean ]  
    SETTINGS [ boolean ]  
    BUFFERS [ boolean ]  
    WAL [ boolean ]  
    TIMING [ boolean ]  
    SUMMARY [ boolean ]  
    FORMAT { TEXT | XML | JSON | YAML }  
  
URL: https://www.postgresql.org/docs/14/sql-explain.html  
```  
  
```  
db1=> explain select * from tbl where id=1;  
                       QUERY PLAN                          
---------------------------------------------------------  
 Seq Scan on tbl  (cost=0.00..2255.69 rows=528 width=44)  
   Filter: (id = 1)  
(2 rows)  
  
  
db1=> explain (analyze,verbose,timing,costs,buffers,settings,wal) select * from tbl where id=1;  
                                                   QUERY PLAN                                                     
----------------------------------------------------------------------------------------------------------------  
 Seq Scan on s1.tbl  (cost=0.00..2185.05 rows=1 width=44) (actual time=0.008..6.805 rows=2 loops=1)  
   Output: id, info, ts  
   Filter: (tbl.id = 1)  
   Rows Removed by Filter: 100002  
   Buffers: shared hit=935  
 Settings: max_parallel_workers_per_gather = '0', random_page_cost = '1.1', search_path = '"$user", s1, public'  
 Planning:  
   Buffers: shared hit=15  
 Planning Time: 0.236 ms  
 Execution Time: 6.821 ms  
(10 rows)  
```  
  
#### 23 创建索引  
```  
db1=> create index on tbl (id);  
CREATE INDEX  
  
db1=> explain (analyze,verbose,timing,costs,buffers,settings,wal) select * from tbl where id=1;  
                                                     QUERY PLAN                                                       
--------------------------------------------------------------------------------------------------------------------  
 Index Scan using tbl_id_idx on s1.tbl  (cost=0.29..2.51 rows=1 width=44) (actual time=0.050..0.052 rows=2 loops=1)  
   Output: id, info, ts  
   Index Cond: (tbl.id = 1)  
   Buffers: shared hit=1 read=2  
 Settings: max_parallel_workers_per_gather = '0', random_page_cost = '1.1', search_path = '"$user", s1, public'  
 Planning:  
   Buffers: shared hit=15 read=1  
 Planning Time: 0.212 ms  
 Execution Time: 0.173 ms  
(9 rows)  
```  
  
#### 24 控制执行计划开关  
```  
db1=> set enable_indexscan =off;  
SET  
db1=> explain (analyze,verbose,timing,costs,buffers,settings,wal) select * from tbl where id=1;  
                                                                QUERY PLAN                                                                  
------------------------------------------------------------------------------------------------------------------------------------------  
 Bitmap Heap Scan on s1.tbl  (cost=1.40..2.51 rows=1 width=44) (actual time=0.016..0.017 rows=2 loops=1)  
   Output: id, info, ts  
   Recheck Cond: (tbl.id = 1)  
   Heap Blocks: exact=1  
   Buffers: shared hit=3  
   ->  Bitmap Index Scan on tbl_id_idx  (cost=0.00..1.40 rows=1 width=0) (actual time=0.010..0.011 rows=2 loops=1)  
         Index Cond: (tbl.id = 1)  
         Buffers: shared hit=2  
 Settings: enable_indexscan = 'off', max_parallel_workers_per_gather = '0', random_page_cost = '1.1', search_path = '"$user", s1, public'  
 Planning Time: 0.062 ms  
 Execution Time: 0.038 ms  
(11 rows)  
```  
  
```  
db1=> set enable_bitmapscan =off;  
SET  
db1=> explain (analyze,verbose,timing,costs,buffers,settings,wal) select * from tbl where id=1;  
                                                                             QUERY PLAN                                                                                
---------------------------------------------------------------------------------------------------------------------------------------------------------------------  
 Seq Scan on s1.tbl  (cost=0.00..2185.05 rows=1 width=44) (actual time=0.009..7.030 rows=2 loops=1)  
   Output: id, info, ts  
   Filter: (tbl.id = 1)  
   Rows Removed by Filter: 100002  
   Buffers: shared hit=935  
 Settings: enable_bitmapscan = 'off', enable_indexscan = 'off', max_parallel_workers_per_gather = '0', random_page_cost = '1.1', search_path = '"$user", s1, public'  
 Planning Time: 0.057 ms  
 Execution Time: 7.045 ms  
(8 rows)  
```  
  
#### 25 更新  
```  
db1=> update tbl set info='new' where id=1;  
UPDATE 2  
  
  
db1=> update tbl set info='new123' where id=1 returning *;  
 id |  info  |             ts               
----+--------+----------------------------  
  1 | new123 | 2023-11-10 12:30:29.073813  
  1 | new123 | 2023-11-10 12:31:55.791965  
(2 rows)  
  
UPDATE 2  
```  
  
#### 26 关联更新  
```  
db1=> create table t2 (id int, info text, ts timestamp);  
CREATE TABLE  
db1=> insert into t2 values (1, 'test1', now()), (2, 'test2', now()), (-1, 'test-1', now()), (-100, 'test-100', now());  
INSERT 0 4  
```  
  
```  
db1=> \h update  
Command:     UPDATE  
Description: update rows of a table  
Syntax:  
[ WITH [ RECURSIVE ] with_query [, ...] ]  
UPDATE [ ONLY ] table_name [ * ] [ [ AS ] alias ]  
    SET { column_name = { expression | DEFAULT } |  
          ( column_name [, ...] ) = [ ROW ] ( { expression | DEFAULT } [, ...] ) |  
          ( column_name [, ...] ) = ( sub-SELECT )  
        } [, ...]  
    [ FROM from_item [, ...] ]  
    [ WHERE condition | WHERE CURRENT OF cursor_name ]  
    [ RETURNING * | output_expression [ [ AS ] output_name ] [, ...] ]  
  
URL: https://www.postgresql.org/docs/14/sql-update.html  
```  
  
```  
db1=> update tbl set info=t2.info from t2 where tbl.id=t2.id and t2.id > -10 returning *;  
 id | info  |             ts             | id | info  |            ts               
----+-------+----------------------------+----+-------+---------------------------  
  1 | test1 | 2023-11-10 12:31:55.791965 |  1 | test1 | 2023-11-10 12:52:41.12488  
  1 | test1 | 2023-11-10 12:30:29.073813 |  1 | test1 | 2023-11-10 12:52:41.12488  
  2 | test2 | 2023-11-10 12:31:55.791986 |  2 | test2 | 2023-11-10 12:52:41.12488  
  2 | test2 | 2023-11-10 12:31:03.545101 |  2 | test2 | 2023-11-10 12:52:41.12488  
(4 rows)  
  
UPDATE 4  
```  
  
#### 27 merge/insert into on conflict  
```  
db1=> create table t3 (id int primary key, info text, ts timestamp);  
CREATE TABLE  
db1=>   
db1=> insert into t3 values (1,'test1',clock_timestamp()), (2,'test2',clock_timestamp()), (3,'test3',clock_timestamp());  
INSERT 0 3  
```  
  
```  
db1=> \set VERBOSITY verbose  
db1=> insert into t3 values (1,'new','1999-01-01');  
ERROR:  23505: duplicate key value violates unique constraint "t3_pkey"  
DETAIL:  Key (id)=(1) already exists.  
SCHEMA NAME:  s1  
TABLE NAME:  t3  
CONSTRAINT NAME:  t3_pkey  
LOCATION:  _bt_check_unique, nbtinsert.c:663  
  
  
db1=> insert into t3 values (1,'new','1999-01-01') on conflict (id) do update set info=excluded.info,ts=excluded.ts returning *;  
 id | info |         ts            
----+------+---------------------  
  1 | new  | 1999-01-01 00:00:00  
(1 row)  
  
INSERT 0 1  
```  
  
  
#### 28 删除  
  
```  
db1=> delete from t3 where id=1;  
DELETE 1  
db1=> delete from t3 where id=2 returning *;  
 id | info  |             ts               
----+-------+----------------------------  
  2 | test2 | 2023-11-10 13:02:08.642111  
(1 row)  
  
DELETE 1  
```  
  
#### 29 关联删除  
```  
db1=> \h delete from  
Command:     DELETE  
Description: delete rows of a table  
Syntax:  
[ WITH [ RECURSIVE ] with_query [, ...] ]  
DELETE FROM [ ONLY ] table_name [ * ] [ [ AS ] alias ]  
    [ USING from_item [, ...] ]  
    [ WHERE condition | WHERE CURRENT OF cursor_name ]  
    [ RETURNING * | output_expression [ [ AS ] output_name ] [, ...] ]  
  
URL: https://www.postgresql.org/docs/14/sql-delete.html  
```  
  
```  
db1=> delete from tbl using t2 where tbl.id=t2.id and t2.id > -10 returning *;  
 id | info  |             ts             | id | info  |            ts               
----+-------+----------------------------+----+-------+---------------------------  
  1 | test1 | 2023-11-10 12:31:55.791965 |  1 | test1 | 2023-11-10 12:52:41.12488  
  1 | test1 | 2023-11-10 12:30:29.073813 |  1 | test1 | 2023-11-10 12:52:41.12488  
  2 | test2 | 2023-11-10 12:31:03.545101 |  2 | test2 | 2023-11-10 12:52:41.12488  
  2 | test2 | 2023-11-10 12:31:55.791986 |  2 | test2 | 2023-11-10 12:52:41.12488  
(4 rows)  
  
DELETE 4  
```  
  
#### 30 修改字段类型  
```  
db1=> \d tbl  
                            Table "s1.tbl"  
 Column |            Type             | Collation | Nullable | Default   
--------+-----------------------------+-----------+----------+---------  
 id     | integer                     |           |          |   
 info   | text                        |           |          |   
 ts     | timestamp without time zone |           |          |   
Indexes:  
    "tbl_id_idx" btree (id)  
  
db1=> alter table tbl alter column ts type date;  
ALTER TABLE  
  
db1=> \d tbl  
                  Table "s1.tbl"  
 Column |  Type   | Collation | Nullable | Default   
--------+---------+-----------+----------+---------  
 id     | integer |           |          |   
 info   | text    |           |          |   
 ts     | date    |           |          |   
Indexes:  
    "tbl_id_idx" btree (id)  
  
db1=> select * from tbl limit 10;  
 id |               info               |     ts       
----+----------------------------------+------------  
  3 | test3                            | 2023-11-10  
  4 | test4                            | 2023-11-10  
  3 | 0f85f45f4a43c8fe876b55538ac27d9f | 2023-11-10  
  4 | ae4311048718b0ac22f5ac893d223bdb | 2023-11-10  
  5 | 38b488ecf64013f936908384bbe996c0 | 2023-11-10  
  6 | c2b3bbdce2a6a6d4620e6bc796a19a90 | 2023-11-10  
  7 | 009cb69b734e39f34eb9bd813892fe15 | 2023-11-10  
  8 | 05c0e274f5949e7fe89df72cbd3c9782 | 2023-11-10  
  9 | 145c99d4d4a293b48c468909e2ef8d23 | 2023-11-10  
 10 | d7e5f169c33c40df2b8cbd16c24d415e | 2023-11-10  
(10 rows)  
```  
  
#### 31 修改字段类型长度  
```  
db1=> create table t4 (id int, info varchar(10), ts timestamp);  
CREATE TABLE  
db1=> alter table t4 alter column info type varchar(20);  
ALTER TABLE  
```  
  
#### 32 增加字段  
```  
db1=> alter table tbl add column c1 int;  
ALTER TABLE  
db1=> \d tbl  
                  Table "s1.tbl"  
 Column |  Type   | Collation | Nullable | Default   
--------+---------+-----------+----------+---------  
 id     | integer |           |          |   
 info   | text    |           |          |   
 ts     | date    |           |          |   
 c1     | integer |           |          |   
Indexes:  
    "tbl_id_idx" btree (id)  
```  
  
#### 33 删除字段  
```  
db1=> \d tbl  
                  Table "s1.tbl"  
 Column |  Type   | Collation | Nullable | Default   
--------+---------+-----------+----------+---------  
 id     | integer |           |          |   
 info   | text    |           |          |   
 ts     | date    |           |          |   
 c1     | integer |           |          |   
Indexes:  
    "tbl_id_idx" btree (id)  
  
db1=> alter table tbl drop column info;  
ALTER TABLE  
db1=> \d+ tbl  
                                             Table "s1.tbl"  
 Column |  Type   | Collation | Nullable | Default | Storage | Compression | Stats target | Description   
--------+---------+-----------+----------+---------+---------+-------------+--------------+-------------  
 id     | integer |           |          |         | plain   |             |              |   
 ts     | date    |           |          |         | plain   |             |              |   
 c1     | integer |           |          |         | plain   |             |              |   
Indexes:  
    "tbl_id_idx" btree (id)  
Access method: heap  
```  
  
#### 34 查看被删除字段的数据  
```  
db1=> \x  
Expanded display is on.  
  
db1=> select * from pg_attribute where attrelid ='s1.tbl'::regclass and attisdropped;  
-[ RECORD 1 ]--+-----------------------------  
attrelid       | 16390  
attname        | ........pg.dropped.2........  
atttypid       | 0  
attstattarget  | 0  
attlen         | -1  
attnum         | 2  
attndims       | 0  
attcacheoff    | -1  
atttypmod      | -1  
attbyval       | f  
attalign       | i  
attstorage     | x  
attcompression |   
attnotnull     | f  
atthasdef      | f  
atthasmissing  | f  
attidentity    |   
attgenerated   |   
attisdropped   | t  
attislocal     | t  
attinhcount    | 0  
attcollation   | 100  
attacl         |   
attoptions     |   
attfdwoptions  |   
attmissingval  |   
```  
  
```  
db1=> \c db1 postgres  
You are now connected to database "db1" as user "postgres".  
db1=# update pg_attribute set attname='info',attisdropped=false,atttypid=25,attstattarget=-1 where attrelid ='s1.tbl'::regclass and attnum=2;  
UPDATE 1  
```  
  
```  
db1=# \c db1 r1  
You are now connected to database "db1" as user "r1".  
  
  
db1=> select info from tbl limit 10;  
               info                 
----------------------------------  
 test3  
 test4  
 0f85f45f4a43c8fe876b55538ac27d9f  
 ae4311048718b0ac22f5ac893d223bdb  
 38b488ecf64013f936908384bbe996c0  
 c2b3bbdce2a6a6d4620e6bc796a19a90  
 009cb69b734e39f34eb9bd813892fe15  
 05c0e274f5949e7fe89df72cbd3c9782  
 145c99d4d4a293b48c468909e2ef8d23  
 d7e5f169c33c40df2b8cbd16c24d415e  
(10 rows)  
```  
  
  
注: `atttypid=25,attstattarget=-1` 对应原来的`info text`类型, 可以在另一个表中查到  
  
```  
db1=> select atttypid,attstattarget from pg_attribute where attrelid ='s1.t2'::regclass and attname='info';  
 atttypid | attstattarget   
----------+---------------  
       25 |            -1  
(1 row)  
```  
  
#### 35 创建约束  
  
```  
db1=> create table t (id int, info text, ts timestamp, c1 int check (c1>0));  
CREATE TABLE  
  
db1=> \set VERBOSITY verbose  
db1=> insert into t values (1,'test',now(),0);  
ERROR:  23514: new row for relation "t" violates check constraint "t_c1_check"  
DETAIL:  Failing row contains (1, test, 2023-11-10 13:21:15.159885, 0).  
SCHEMA NAME:  s1  
TABLE NAME:  t  
CONSTRAINT NAME:  t_c1_check  
LOCATION:  ExecConstraints, execMain.c:1934  
db1=> insert into t values (1,'test',now(),1);  
INSERT 0 1  
```  
  
  
  
#### 36 增加自增字段  
  
```  
db1=> alter table t add column c2 serial4;  
ALTER TABLE  
db1=> \d+ t  
                                                                   Table "s1.t"  
 Column |            Type             | Collation | Nullable |            Default            | Storage  | Compression | Stats target | Description   
--------+-----------------------------+-----------+----------+-------------------------------+----------+-------------+--------------+-------------  
 id     | integer                     |           |          |                               | plain    |             |              |   
 info   | text                        |           |          |                               | extended |             |              |   
 ts     | timestamp without time zone |           |          |                               | plain    |             |              |   
 c1     | integer                     |           |          |                               | plain    |             |              |   
 c2     | integer                     |           | not null | nextval('t_c2_seq'::regclass) | plain    |             |              |   
Check constraints:  
    "t_c1_check" CHECK (c1 > 0)  
Access method: heap  
```  
  
  
#### 37 创建序列  
  
```  
db1=> \h create sequence  
Command:     CREATE SEQUENCE  
Description: define a new sequence generator  
Syntax:  
CREATE [ TEMPORARY | TEMP ] SEQUENCE [ IF NOT EXISTS ] name  
    [ AS data_type ]  
    [ INCREMENT [ BY ] increment ]  
    [ MINVALUE minvalue | NO MINVALUE ] [ MAXVALUE maxvalue | NO MAXVALUE ]  
    [ START [ WITH ] start ] [ CACHE cache ] [ [ NO ] CYCLE ]  
    [ OWNED BY { table_name.column_name | NONE } ]  
  
URL: https://www.postgresql.org/docs/14/sql-createsequence.html  
  
db1=> create sequence seq start 1;  
CREATE SEQUENCE  
```  
  
  
  
#### 38 设置字段默认值  
```  
db1=> alter table t alter column c1 set default nextval('s1.seq'::regclass);   
ALTER TABLE  
db1=>   
```  
  
#### 39 设置(插入、更新)自动计算值字段  
```  
create table new1 (  
  id int primary key,  
  c1 int,  
  c2 int,  
  sum int8 GENERATED ALWAYS AS (c1+c2) STORED  
);  
  
insert into new1 values (1,1,2), (2,2,10), (3,2,10), (4,2,10);  
  
db1=> select * from new1;  
 id | c1 | c2 | sum   
----+----+----+-----  
  1 |  1 |  2 |   3  
  2 |  2 | 10 |  12  
  3 |  2 | 10 |  12  
  4 |  2 | 10 |  12  
(4 rows)  
  
db1=> update new1 set c1=3 where id=2 returning *;  
 id | c1 | c2 | sum   
----+----+----+-----  
  2 |  3 | 10 |  13  
(1 row)  
  
UPDATE 1  
```  
  
#### 40 主键及关联约束  
```  
db1=> create table new2 (id int references new1(id), info text, ts timestamp);  
CREATE TABLE  
  
  
db1=> \d+ new1  
                                                            Table "s1.new1"  
 Column |  Type   | Collation | Nullable |                Default                 | Storage | Compression | Stats target | Description   
--------+---------+-----------+----------+----------------------------------------+---------+-------------+--------------+-------------  
 id     | integer |           | not null |                                        | plain   |             |              |   
 c1     | integer |           |          |                                        | plain   |             |              |   
 c2     | integer |           |          |                                        | plain   |             |              |   
 sum    | bigint  |           |          | generated always as ((c1 + c2)) stored | plain   |             |              |   
Indexes:  
    "new1_pkey" PRIMARY KEY, btree (id)  
Referenced by:  
    TABLE "new2" CONSTRAINT "new2_id_fkey" FOREIGN KEY (id) REFERENCES new1(id)  
Access method: heap  
  
  
db1=> \d+ new2  
                                                       Table "s1.new2"  
 Column |            Type             | Collation | Nullable | Default | Storage  | Compression | Stats target | Description   
--------+-----------------------------+-----------+----------+---------+----------+-------------+--------------+-------------  
 id     | integer                     |           |          |         | plain    |             |              |   
 info   | text                        |           |          |         | extended |             |              |   
 ts     | timestamp without time zone |           |          |         | plain    |             |              |   
Foreign-key constraints:  
    "new2_id_fkey" FOREIGN KEY (id) REFERENCES new1(id)  
Access method: heap  
```  
  
更多高级用法参考手册SQL command章节  
  
#### 41 unlogged 表  
批量写速度快, 不安全, 不写wal, 不复制到从库.  
```  
create unlogged table new3 (id int, info text, ts timestamp);  
create table new4 (id int, info text, ts timestamp);  
  
db1=> \timing  
Timing is on.  
  
insert into new3 select generate_series(1,10000000), 'test123', now();  
INSERT 0 10000000  
Time: 7388.720 ms (00:07.389)  
  
  
insert into new4 select generate_series(1,10000000), 'test123', now();  
INSERT 0 10000000  
Time: 11566.083 ms (00:11.566)  
```  
  
#### 42 会话级临时表  
```  
create temp table new5 (id int, info text, ts timestamp);  
  
insert into new5 select generate_series(1,10000000), 'test123', now();  
INSERT 0 10000000  
Time: 6201.786 ms (00:06.202)  
```  
  
#### 43 truncate表  
```  
db1=> select count(*) from tbl;  
 count    
--------  
 100000  
(1 row)  
  
db1=> truncate tbl;  
TRUNCATE TABLE  
  
db1=> select count(*) from tbl;  
 count   
-------  
     0  
(1 row)  
```  
  
#### 44 插入随机ID数据  
```  
db1=> \d+ tbl  
                                             Table "s1.tbl"  
 Column |  Type   | Collation | Nullable | Default | Storage  | Compression | Stats target | Description   
--------+---------+-----------+----------+---------+----------+-------------+--------------+-------------  
 id     | integer |           |          |         | plain    |             |              |   
 info   | text    |           |          |         | extended |             |              |   
 ts     | date    |           |          |         | plain    |             |              |   
 c1     | integer |           |          |         | plain    |             |              |   
Indexes:  
    "tbl_id_idx" btree (id)  
Access method: heap  
  
db1=> insert into tbl select random()*100000, md5(random()::text), clock_timestamp(), id from generate_series(1,100000) id;  
INSERT 0 100000  
```  
  
  
#### 45 查看id, c1值与堆表行号的相关性  
```  
db1=> select tablename,attname,correlation from pg_stats where schemaname='s1' and tablename='tbl' and attname in ('id','c1');  
 tablename | attname | correlation   
-----------+---------+-------------  
 tbl       | id      | -0.00798456  
 tbl       | c1      |           1  
(2 rows)  
```  
  
#### 46 查看相关性和执行计划的关系  
```  
db1=> explain (analyze,verbose,timing,costs,buffers,settings,wal) select * from tbl where id<1000;  
                                                       QUERY PLAN                                                          
-------------------------------------------------------------------------------------------------------------------------  
 Bitmap Heap Scan on s1.tbl  (cost=11.04..669.22 rows=961 width=45) (actual time=0.203..0.993 rows=1026 loops=1)  
   Output: id, info, ts, c1  
   Recheck Cond: (tbl.id < 1000)  
   Heap Blocks: exact=640  
   Buffers: shared hit=645  
   ->  Bitmap Index Scan on tbl_id_idx  (cost=0.00..10.80 rows=961 width=0) (actual time=0.104..0.104 rows=1026 loops=1)  
         Index Cond: (tbl.id < 1000)  
         Buffers: shared hit=5  
 Settings: max_parallel_workers_per_gather = '0', random_page_cost = '1.1', search_path = '"$user", s1, public'  
 Planning:  
   Buffers: shared hit=3  
 Planning Time: 0.137 ms  
 Execution Time: 1.090 ms  
(13 rows)  
```  
  
```  
db1=> create index on tbl (c1);  
CREATE INDEX  
```  
  
```  
db1=> explain (analyze,verbose,timing,costs,buffers,settings,wal) select * from tbl where c1<1000;  
                                                       QUERY PLAN                                                          
-------------------------------------------------------------------------------------------------------------------------  
 Index Scan using tbl_c1_idx on s1.tbl  (cost=0.29..30.63 rows=968 width=45) (actual time=0.013..0.246 rows=999 loops=1)  
   Output: id, info, ts, c1  
   Index Cond: (tbl.c1 < 1000)  
   Buffers: shared hit=12 read=2  
 Settings: max_parallel_workers_per_gather = '0', random_page_cost = '1.1', search_path = '"$user", s1, public'  
 Planning:  
   Buffers: shared hit=17 read=3  
 Planning Time: 0.309 ms  
 Execution Time: 0.330 ms  
(9 rows)  
```  
  
  
#### 47 查看被索引筛选并访问的数据量和执行计划的关系  
```  
db1=> explain (analyze,verbose,timing,costs,buffers,settings,wal) select * from tbl where id<10;  
                                                      QUERY PLAN                                                         
-----------------------------------------------------------------------------------------------------------------------  
 Index Scan using tbl_id_idx on s1.tbl  (cost=0.29..12.57 rows=10 width=45) (actual time=0.006..0.019 rows=11 loops=1)  
   Output: id, info, ts, c1  
   Index Cond: (tbl.id < 10)  
   Buffers: shared hit=13  
 Settings: max_parallel_workers_per_gather = '0', random_page_cost = '1.1', search_path = '"$user", s1, public'  
 Planning:  
   Buffers: shared hit=3  
 Planning Time: 0.098 ms  
 Execution Time: 0.035 ms  
(9 rows)  
```  
  
```  
db1=> explain (analyze,verbose,timing,costs,buffers,settings,wal) select * from tbl where id<1000;  
                                                       QUERY PLAN                                                          
-------------------------------------------------------------------------------------------------------------------------  
 Bitmap Heap Scan on s1.tbl  (cost=11.04..669.22 rows=961 width=45) (actual time=0.221..0.975 rows=1026 loops=1)  
   Output: id, info, ts, c1  
   Recheck Cond: (tbl.id < 1000)  
   Heap Blocks: exact=640  
   Buffers: shared hit=645  
   ->  Bitmap Index Scan on tbl_id_idx  (cost=0.00..10.80 rows=961 width=0) (actual time=0.122..0.123 rows=1026 loops=1)  
         Index Cond: (tbl.id < 1000)  
         Buffers: shared hit=5  
 Settings: max_parallel_workers_per_gather = '0', random_page_cost = '1.1', search_path = '"$user", s1, public'  
 Planning:  
   Buffers: shared hit=3  
 Planning Time: 0.162 ms  
 Execution Time: 1.194 ms  
(13 rows)  
```  
  
#### 48 查看随机访问因子和执行计划的关系  
```  
db1=> show random_page_cost ;  
 random_page_cost   
------------------  
 1.1  
(1 row)  
  
db1=> set random_page_cost =1;  
SET  
  
  
db1=> explain (analyze,verbose,timing,costs,buffers,settings,wal) select * from tbl where id<1000;  
                                                        QUERY PLAN                                                           
---------------------------------------------------------------------------------------------------------------------------  
 Index Scan using tbl_id_idx on s1.tbl  (cost=0.29..655.07 rows=961 width=45) (actual time=0.013..0.793 rows=1026 loops=1)  
   Output: id, info, ts, c1  
   Index Cond: (tbl.id < 1000)  
   Buffers: shared hit=1031  
 Settings: max_parallel_workers_per_gather = '0', random_page_cost = '1', search_path = '"$user", s1, public'  
 Planning:  
   Buffers: shared hit=3  
 Planning Time: 0.100 ms  
 Execution Time: 0.884 ms  
(9 rows)  
```  
  
#### 49 聚集, 让堆表按指定索引的顺序排列重组  
```  
db1=> cluster tbl using tbl_id_idx ;  
CLUSTER  
```  
  
#### 50 查看聚集后字段值与物理存储(行号)的线性相关性  
```  
db1=> analyze tbl;  
ANALYZE  
  
  
db1=> select tablename,attname,correlation from pg_stats where schemaname='s1' and tablename='tbl' and attname in ('id','c1');  
 tablename | attname | correlation    
-----------+---------+--------------  
 tbl       | id      |            1  
 tbl       | c1      | -0.003530208  
(2 rows)  
```  
  
#### 51 drop表  
```  
db1=> drop table tbl;  
DROP TABLE  
```  
  
#### 52 创建新用户  
```  
db1=> create role r2 login encrypted password 'pwd123';  
CREATE ROLE  
```  
  
#### 53 配置可以只读所有数据的用户  
```  
select * from pg_roles;  
  
          rolname          | rolsuper | rolinherit | rolcreaterole | rolcreatedb | rolcanlogin | rolreplication | rolconnlimit | rolpassword | rolvaliduntil | rolbypassrls |               rolconfig               |  oid    
---------------------------+----------+------------+---------------+-------------+-------------+----------------+--------------+-------------+---------------+--------------+---------------------------------------+-------  
 postgres                  | t        | t          | t             | t           | t           | t              |           -1 | ********    |               | t            |                                       |    10  
 pg_database_owner         | f        | t          | f             | f           | f           | f              |           -1 | ********    |               | f            |                                       |  6171  
 pg_read_all_data          | f        | t          | f             | f           | f           | f              |           -1 | ********    |               | f            |                                       |  6181  
 pg_write_all_data         | f        | t          | f             | f           | f           | f              |           -1 | ********    |               | f            |                                       |  6182  
 pg_monitor                | f        | t          | f             | f           | f           | f              |           -1 | ********    |               | f            |                                       |  3373  
 pg_read_all_settings      | f        | t          | f             | f           | f           | f              |           -1 | ********    |               | f            |                                       |  3374  
 pg_read_all_stats         | f        | t          | f             | f           | f           | f              |           -1 | ********    |               | f            |                                       |  3375  
 pg_stat_scan_tables       | f        | t          | f             | f           | f           | f              |           -1 | ********    |               | f            |                                       |  3377  
 pg_read_server_files      | f        | t          | f             | f           | f           | f              |           -1 | ********    |               | f            |                                       |  4569  
 pg_write_server_files     | f        | t          | f             | f           | f           | f              |           -1 | ********    |               | f            |                                       |  4570  
 pg_execute_server_program | f        | t          | f             | f           | f           | f              |           -1 | ********    |               | f            |                                       |  4571  
 pg_signal_backend         | f        | t          | f             | f           | f           | f              |           -1 | ********    |               | f            |                                       |  4200  
 r1                        | f        | t          | f             | f           | t           | f              |           -1 | ********    |               | f            | {"search_path=\"$user\", s1, public"} | 16384  
 r2                        | f        | t          | f             | f           | t           | f              |           -1 | ********    |               | f            |                                       | 16447  
(14 rows)  
  
  
db1=> grant pg_read_all_data to r2;  
GRANT ROLE  
  
  
db1=> \du+ r2  
                       List of roles  
 Role name | Attributes |     Member of      | Description   
-----------+------------+--------------------+-------------  
 r2        |            | {pg_read_all_data} |   
  
  
db1=> \c db1 r2  
You are now connected to database "db1" as user "r2".  
  
  
db1=> select * from s1.t2 limit 10;  
  id  |   info   |            ts               
------+----------+---------------------------  
    1 | test1    | 2023-11-10 12:52:41.12488  
    2 | test2    | 2023-11-10 12:52:41.12488  
   -1 | test-1   | 2023-11-10 12:52:41.12488  
 -100 | test-100 | 2023-11-10 12:52:41.12488  
(4 rows)  
```  
  
#### 54 回收只读所有数据的用户角色  
```  
db1=> \c db1 postgres  
You are now connected to database "db1" as user "postgres".  
  
db1=# revoke pg_read_all_data from r2;  
REVOKE ROLE  
  
db1=# \c db1 r2  
You are now connected to database "db1" as user "r2".  
  
db1=> select * from s1.t2 limit 10;  
ERROR:  permission denied for schema s1  
LINE 1: select * from s1.t2 limit 10;  
                      ^  
```  
  
  
#### 55 授予新用户读某个表的权限, 其他表不能查询  
```  
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
  
db1=> grant select on s1.t2 to r2;  
GRANT  
  
db1=> \c db1 r2  
You are now connected to database "db1" as user "r2".  
  
db1=> select * from s1.t2 limit 10;  
ERROR:  permission denied for schema s1  
LINE 1: select * from s1.t2 limit 10;  
                      ^  
db1=> \c db1 r1  
  
db1=> grant usage on schema s1 to r2;  
GRANT  
  
db1=> \c db1 r2  
You are now connected to database "db1" as user "r2".  
  
db1=> select * from s1.t2 limit 10;  
  id  |   info   |            ts               
------+----------+---------------------------  
    1 | test1    | 2023-11-10 12:52:41.12488  
    2 | test2    | 2023-11-10 12:52:41.12488  
   -1 | test-1   | 2023-11-10 12:52:41.12488  
 -100 | test-100 | 2023-11-10 12:52:41.12488  
(4 rows)  
```  
  
#### 56 回收已赋予的权限  
  
```  
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
  
db1=> revoke select on t2 from r2;  
REVOKE  
  
db1=> \c db1 r2  
You are now connected to database "db1" as user "r2".  
  
db1=> select * from s1.t2 limit 10;  
ERROR:  permission denied for table t2  
```  
  
#### 57 对未来新建对象授权配置默认权限  
```  
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
  
db1=> ALTER DEFAULT PRIVILEGES FOR ROLE r1 IN SCHEMA s1 GRANT SELECT ON TABLES TO r2;  
ALTER DEFAULT PRIVILEGES  
  
db1=> create table nt (id int);  
CREATE TABLE  
db1=> insert into nt values (1);  
INSERT 0 1  
  
  
db1=> \c db1 r2  
You are now connected to database "db1" as user "r2".  
  
db1=> select * from s1.t2 limit 1;  
ERROR:  permission denied for table t2  
db1=> select * from s1.nt limit 1;  
 id   
----  
  1  
(1 row)  
```  
  
#### 58 对已有所有对象授权  
```  
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
db1=> GRANT SELECT ON ALL TABLES IN SCHEMA s1 TO r2;  
GRANT  
  
db1=> \c db1 r2  
You are now connected to database "db1" as user "r2".  
db1=> select * from s1.t2 limit 1;  
 id | info  |            ts               
----+-------+---------------------------  
  1 | test1 | 2023-11-10 12:52:41.12488  
(1 row)  
```  
  
  
#### 59 将事务默认配置为只读  
```  
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
  
db1=> alter role r1 set default_transaction_read_only =true;  
ALTER ROLE  
  
  
db1=> \q  
postgres@6f60081d4ace:/usr/lib/postgresql/14/bin$ psql  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
db1=> create table nt1 (id int);  
ERROR:  cannot execute CREATE TABLE in a read-only transaction  
  
  
  
db1=> begin transaction read write ;  
BEGIN  
db1=*> create table nt1 (id int);  
CREATE TABLE  
db1=*> end;  
COMMIT  
  
  
db1=> begin transaction read write ;  
BEGIN  
db1=*> alter role r1 set default_transaction_read_only =false;  
ALTER ROLE  
db1=*> end;  
COMMIT  
  
  
  
db1=> \q  
postgres@6f60081d4ace:/usr/lib/postgresql/14/bin$ psql  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
```  
  
#### 60 高级SQL:  
  
[《PostgreSQL SELECT 的高级用法(CTE, LATERAL, ORDINALITY, WINDOW, SKIP LOCKED, DISTINCT, GROUPING SETS, ...) - 珍藏级》](../201802/20180226_05.md)   
  
  
##### 60.1 with recursive  
```  
drop table t;  
  
create table t (  
  id int,     -- 进程ID   
  info text,  -- 进程信息   
  pid int     -- 父进程ID   
);   
  
insert into t values (1, 'pg-1', null);  
insert into t values (100, 'pg-100', 1);  
insert into t values (99, 'pg-99', 1);  
insert into t values (98, 'pg-98', 1);  
insert into t values (97, 'pg-97', 98);  
insert into t values (96, 'pg-96', 98);  
insert into t values (95, 'pg-95', 97);  
insert into t values (90, 'pg-90', 98);  
insert into t values (80, 'pg-80', 97);  
  
  
db1=> select * from t;  
 id  |  info  | pid   
-----+--------+-----  
   1 | pg-1   |      
 100 | pg-100 |   1  
  99 | pg-99  |   1  
  98 | pg-98  |   1  
  97 | pg-97  |  98  
  96 | pg-96  |  98  
  95 | pg-95  |  97  
  90 | pg-90  |  98  
  80 | pg-80  |  97  
(9 rows)  
  
-- 查询1的所有子进程, 并把进程关联路径补齐  
  
with recursive tmp as (  
  select id,info,coalesce(pid,'0')::text pid from t where id=1  
  union   
  select t.id, t.info||','||tmp.info, coalesce(tmp.pid,'0')||','||t.pid||','||t.id from t join tmp on (t.pid=tmp.id) where t.* is not null  
)   
select * from tmp;  
  
  
 id  |          info          |        pid           
-----+------------------------+--------------------  
   1 | pg-1                   | 0  
 100 | pg-100,pg-1            | 0,1,100  
  99 | pg-99,pg-1             | 0,1,99  
  98 | pg-98,pg-1             | 0,1,98  
  97 | pg-97,pg-98,pg-1       | 0,1,98,98,97  
  96 | pg-96,pg-98,pg-1       | 0,1,98,98,96  
  90 | pg-90,pg-98,pg-1       | 0,1,98,98,90  
  95 | pg-95,pg-97,pg-98,pg-1 | 0,1,98,98,97,97,95  
  80 | pg-80,pg-97,pg-98,pg-1 | 0,1,98,98,97,97,80  
(9 rows)  
```  
  
##### 60.2 子查询  
```  
db1=> select *,(select t.pid from t where t.id=tmp.pid) from t tmp;  
 id  |  info  | pid | pid   
-----+--------+-----+-----  
   1 | pg-1   |     |      
 100 | pg-100 |   1 |      
  99 | pg-99  |   1 |      
  98 | pg-98  |   1 |      
  97 | pg-97  |  98 |   1  
  96 | pg-96  |  98 |   1  
  95 | pg-95  |  97 |  98  
  90 | pg-90  |  98 |   1  
  80 | pg-80  |  97 |  98  
(9 rows)  
  
  
db1=> select array(select random()*10 from generate_series(1,5));  
                                           array                                             
-------------------------------------------------------------------------------------------  
 {8.943357864397399,6.126725114527112,8.67194419003603,5.344871449521413,8.39895334311862}  
(1 row)  
```  
  
##### 60.3 with ordinality  
```  
digoal=# select * from generate_series(1,4) with ordinality as g(g,o);    
 g | o     
---+---    
 1 | 1    
 2 | 2    
 3 | 3    
 4 | 4    
(4 rows)    
    
digoal=# select * from generate_series(1,4) with ordinality;    
 generate_series | ordinality     
-----------------+------------    
               1 |          1    
               2 |          2    
               3 |          3    
               4 |          4    
(4 rows)    
    
digoal=# select * from unnest(array[5,4,3,2,1]);    
 unnest     
--------    
      5    
      4    
      3    
      2    
      1    
(5 rows)    
    
digoal=# select * from unnest(array[5,4,3,2,1]) with ordinality;    
 unnest | ordinality     
--------+------------    
      5 |          1    
      4 |          2    
      3 |          3    
      2 |          4    
      1 |          5    
(5 rows)   
```  
  
##### 60.4 distinct on  
```  
drop table t;  
create table t (id int, info text, ts timestamp);  
insert into t values (1,'test1',clock_timestamp()), (1,'test11',clock_timestamp()), (2,'test2',clock_timestamp());  
  
  
db1=> select distinct on (id) * from t;  
 id | info  |             ts               
----+-------+----------------------------  
  1 | test1 | 2023-11-10 14:55:30.282262  
  2 | test2 | 2023-11-10 14:55:30.282396  
(2 rows)  
  
db1=> explain select distinct on (id) * from t;  
                            QUERY PLAN                              
------------------------------------------------------------------  
 Unique  (cost=78.60..84.25 rows=200 width=44)  
   ->  Sort  (cost=78.60..81.43 rows=1130 width=44)  
         Sort Key: id  
         ->  Seq Scan on t  (cost=0.00..21.30 rows=1130 width=44)  
(4 rows)  
```  
  
##### 60.5 lateral  
  
lateral可以在FROM ITEM中，也可以在JOIN ITEM中。LATERAL后面可以是子查询、函数名。LATERAL中的子查询可以直接引用LATERAL左边的ITEM进行JOIN（类似exists, not exists子句中的引用用法）。    
  
```  
create table test (id int, username text, some_ts timestamp);  
insert into test values (1,'a',clock_timestamp()),(2,'a',clock_timestamp()),(3,'b',clock_timestamp()),(4,'c',clock_timestamp());  
  
select x.* from   
  ( select t.username      
    from test t      
    group by t.username order by username   
  ) as t1,    
  LATERAL (    
    select t.* from test t where    
    t.username = t1.username order by t.some_ts desc limit 5      
  ) as x;    
  
 id | username |          some_ts             
----+----------+----------------------------  
  2 | a        | 2023-11-10 15:01:05.644149  
  1 | a        | 2023-11-10 15:01:05.644056  
  3 | b        | 2023-11-10 15:01:05.644153  
  4 | c        | 2023-11-10 15:01:05.644155  
(4 rows)  
```  
  
##### 60.6 函数  
```  
create or replace function get_rand_arr(int,int,int) returns int[] as $$  
  select array(select $2+(random()*($3-$2))::int from generate_series(1,$1));  
$$ language sql strict;  
  
db1=> select get_rand_arr(10,50,100); -- 10个50-100之间的数值组成的数组  
          get_rand_arr             
---------------------------------  
 {51,80,81,62,71,73,78,96,78,50}  
(1 row)  
  
db1=> select get_rand_arr(10,50,100);  
          get_rand_arr             
---------------------------------  
 {92,89,53,98,75,85,99,79,86,65}  
(1 row)  
```  
  
游标  
```  
create table t_cur (id int primary key, info text, ts timestamp);  
insert into t_cur select generate_series(1,10000), md5(random()::text), clock_timestamp();  
  
db1=> \h declare  
Command:     DECLARE  
Description: define a cursor  
Syntax:  
DECLARE name [ BINARY ] [ ASENSITIVE | INSENSITIVE ] [ [ NO ] SCROLL ]  
    CURSOR [ { WITH | WITHOUT } HOLD ] FOR query  
  
URL: https://www.postgresql.org/docs/14/sql-declare.html  
  
db1=> begin;  
BEGIN  
db1=*> declare cur cursor for select * from t_cur order by ts ;  
DECLARE CURSOR  
db1=*> \h fetch  
Command:     FETCH  
Description: retrieve rows from a query using a cursor  
Syntax:  
FETCH [ direction ] [ FROM | IN ] cursor_name  
  
where direction can be one of:  
  
    NEXT  
    PRIOR  
    FIRST  
    LAST  
    ABSOLUTE count  
    RELATIVE count  
    count  
    ALL  
    FORWARD  
    FORWARD count  
    FORWARD ALL  
    BACKWARD  
    BACKWARD count  
    BACKWARD ALL  
  
URL: https://www.postgresql.org/docs/14/sql-fetch.html  
```  
  
获取游标数据  
  
```  
db1=*> fetch 5 from cur;  
 id |               info               |             ts               
----+----------------------------------+----------------------------  
  1 | a689102d41cfc60dc17071d807f9310f | 2023-11-11 01:18:23.805523  
  2 | 751520002300819e151c7b064647ecc1 | 2023-11-11 01:18:23.80584  
  3 | d5cd199f2a598741bcec25c1271235ee | 2023-11-11 01:18:23.805849  
  4 | 7e709b940a496a7e47eb04b5362b3309 | 2023-11-11 01:18:23.805852  
  5 | 7d5113b8128ee0150319e2f91a5a2f3b | 2023-11-11 01:18:23.805854  
(5 rows)  
  
db1=*> fetch 5 from cur;  
 id |               info               |             ts               
----+----------------------------------+----------------------------  
  6 | ae103fb4e628e98a04c37f43b54bc063 | 2023-11-11 01:18:23.805857  
  7 | f62eef852e3bfa7503f550339f1e4e54 | 2023-11-11 01:18:23.80586  
  8 | 729271ad6928ae94b2565a9a1fe3229e | 2023-11-11 01:18:23.805862  
  9 | 693031efdfba7089cf4ac3b42c576409 | 2023-11-11 01:18:23.805865  
 10 | 977f0d7517998b86c007a0fce187173c | 2023-11-11 01:18:23.805867  
(5 rows)  
  
db1=*> fetch 5 from cur;  
 id |               info               |             ts               
----+----------------------------------+----------------------------  
 11 | e203a9915ea13612e17e11960887289a | 2023-11-11 01:18:23.80587  
 12 | 6e05599eeab7b240053a869bda4df102 | 2023-11-11 01:18:23.805873  
 13 | fc94920b46724360071499301a50a45c | 2023-11-11 01:18:23.805875  
 14 | 255c4cd21cbb4e8107df4f2864c84c8b | 2023-11-11 01:18:23.805878  
 15 | 5c97516faa85805f1fa87d93ec18bae0 | 2023-11-11 01:18:23.80588  
(5 rows)  
  
db1=*> end;  
COMMIT  
```  
  
without hold, 事务结束 自动释放游标  
```  
db1=> select * from pg_cursors ;  
 name | statement | is_holdable | is_binary | is_scrollable | creation_time   
------+-----------+-------------+-----------+---------------+---------------  
(0 rows)  
```  
  
with hold, 事务结束 不会自动释放游标, 需要手工释放, 防止引发无法回收的垃圾导致表和索引膨胀  
```  
db1=> declare cur cursor with hold for select * from t_cur order by ts ;  
DECLARE CURSOR  
db1=> select * from pg_cursors ;  
 name |                             statement                              | is_holdable | is_binary | is_scrollable |         creation_time           
------+--------------------------------------------------------------------+-------------+-----------+---------------+-------------------------------  
 cur  | declare cur cursor with hold for select * from t_cur order by ts ; | t           | f         | t             | 2023-11-11 01:20:31.067027+00  
(1 row)  
  
  
db1=> fetch 5 from cur;  
 id |               info               |             ts               
----+----------------------------------+----------------------------  
  1 | a689102d41cfc60dc17071d807f9310f | 2023-11-11 01:18:23.805523  
  2 | 751520002300819e151c7b064647ecc1 | 2023-11-11 01:18:23.80584  
  3 | d5cd199f2a598741bcec25c1271235ee | 2023-11-11 01:18:23.805849  
  4 | 7e709b940a496a7e47eb04b5362b3309 | 2023-11-11 01:18:23.805852  
  5 | 7d5113b8128ee0150319e2f91a5a2f3b | 2023-11-11 01:18:23.805854  
(5 rows)  
  
  
db1=> close cur;  
CLOSE CURSOR  
  
db1=> select * from pg_cursors ;  
 name | statement | is_holdable | is_binary | is_scrollable | creation_time   
------+-----------+-------------+-----------+---------------+---------------  
(0 rows)  
```  
  
函数返回游标, 获取游标数据  
```  
CREATE TABLE test1 (col text);  
INSERT INTO test1 VALUES ('123');  
  
CREATE or replace FUNCTION reffunc(refcursor) RETURNS refcursor AS $$  
BEGIN  
    OPEN $1 FOR SELECT * FROM test1;  
    RETURN $1;  
END;  
$$ LANGUAGE plpgsql strict;  
  
BEGIN;  
SELECT reffunc('funccursor');  
FETCH ALL IN funccursor;  
COMMIT;  
```  
  
分页  
  
```    
create table t_off (id serial primary key, info text, c int, ts timestamp);    
create index on t_off (c, ts);    
    
insert into t_off (info,c,ts) select md5(random()::text), random()*100, now() from generate_series(1,1000);    
insert into t_off (info,c,ts) select md5(random()::text), random()*100, now() from generate_series(1,1000);    
insert into t_off (info,c,ts) select md5(random()::text), random()*100, now() from generate_series(1,1000);    
insert into t_off (info,c,ts) select md5(random()::text), random()*100, now() from generate_series(1,1000);    
  
select * from t_off where c=1 order by ts limit 10 offset 0;  
  
 id  |               info               | c |             ts               
-----+----------------------------------+---+----------------------------  
  16 | ce70259b8c0b5e83dca5f20cef93d1ee | 1 | 2023-11-11 00:31:57.304588  
  79 | 3a08bcf762a062e86318f516fddea793 | 1 | 2023-11-11 00:31:57.304588  
 230 | 01bc9f9c59b70311369aaa33c3cca3a7 | 1 | 2023-11-11 00:31:57.304588  
 257 | bb22ec8f00de73c19017479fdf981116 | 1 | 2023-11-11 00:31:57.304588  
 286 | 70bfb092ab95cc8c8f5aef9e2762af0c | 1 | 2023-11-11 00:31:57.304588  
 311 | c3b8f1eab66fe88cfd59e92d039fbaa6 | 1 | 2023-11-11 00:31:57.304588  
 452 | f1c000b8a200207c52b6c3f9a8babe72 | 1 | 2023-11-11 00:31:57.304588  
 470 | 7b4702f5a4ff75ef237cbf7af5b8d082 | 1 | 2023-11-11 00:31:57.304588  
 642 | 82d641bcf235eba92a9368f0ac553dca | 1 | 2023-11-11 00:31:57.304588  
 749 | 669488263cfcec928ac2693995309eea | 1 | 2023-11-11 00:31:57.304588  
(10 rows)  
  
  
select * from t_off where c=1 order by ts limit 10 offset 10;  
  
  id  |               info               | c |             ts               
------+----------------------------------+---+----------------------------  
  816 | 9a92daa3c8ceb90e023d127485c4a053 | 1 | 2023-11-11 00:31:57.304588  
  827 | 82abd37368d66eb03347429ff4b28e9e | 1 | 2023-11-11 00:31:57.304588  
  846 | 48f9737b18bf3e8dae7531a1b7fa4d45 | 1 | 2023-11-11 00:31:57.304588  
  990 | f7885a8e585ae7fa0c4b73dd356f260b | 1 | 2023-11-11 00:31:57.304588  
 1017 | e12d1088e80136e869cf82816b28ab51 | 1 | 2023-11-11 00:31:57.313518  
 1058 | 39dc148d9223bcaddcdb2096750e513b | 1 | 2023-11-11 00:31:57.313518  
 1070 | 31c83c561119140721f94e8b28669914 | 1 | 2023-11-11 00:31:57.313518  
 1102 | ee8f076e2e29299ace4c5fb71ddf9dda | 1 | 2023-11-11 00:31:57.313518  
 1148 | 37232358c5995513c19545b8232aced1 | 1 | 2023-11-11 00:31:57.313518  
 1425 | df4ff8d17227012f240b5ecee69d5758 | 1 | 2023-11-11 00:31:57.313518  
(10 rows)  
```    
  
前面的翻页性能  
```  
create unlogged table t_off1 (id serial primary key, info text, c int, ts timestamp);    
  
create index on t_off1 (c, ts);    
    
insert into t_off1 (info,c,ts) select md5(random()::text), 1, now() from generate_series(1,10000000);    
  
explain analyze select * from t_off1 where c=1 order by id limit 10 offset 0;  
  
                                                             QUERY PLAN                                                                
-------------------------------------------------------------------------------------------------------------------------------------  
 Limit  (cost=0.43..61.46 rows=10 width=48) (actual time=0.049..0.054 rows=10 loops=1)  
   ->  Index Scan using t_off1_pkey on t_off1  (cost=0.43..336607.48 rows=55155 width=48) (actual time=0.047..0.050 rows=10 loops=1)  
         Filter: (c = 1)  
 Planning Time: 0.223 ms  
 Execution Time: 0.076 ms  
(5 rows)  
```  
  
翻到很后面的性能  
```  
explain analyze select * from t_off1 where c=1 order by id limit 10 offset 8000000;  
  
db1=> explain analyze select * from t_off1 where c=1 order by id limit 10 offset 8000000;  
                                                                     QUERY PLAN                                                                        
-----------------------------------------------------------------------------------------------------------------------------------------------------  
 Limit  (cost=50682.38..50682.38 rows=1 width=48) (actual time=8768.796..8768.799 rows=10 loops=1)  
   ->  Sort  (cost=50544.49..50682.38 rows=55155 width=48) (actual time=7566.445..8490.762 rows=8000010 loops=1)  
         Sort Key: id  
         Sort Method: external merge  Disk: 645840kB  
         ->  Bitmap Heap Scan on t_off1  (cost=471.89..46200.71 rows=55155 width=48) (actual time=235.466..1599.145 rows=10000000 loops=1)  
               Recheck Cond: (c = 1)  
               Heap Blocks: exact=37171 lossy=65922  
               ->  Bitmap Index Scan on t_off1_c_ts_idx  (cost=0.00..458.10 rows=55155 width=0) (actual time=229.873..229.873 rows=10000000 loops=1)  
                     Index Cond: (c = 1)  
 Planning Time: 0.091 ms  
 Execution Time: 8853.684 ms  
(11 rows)  
```  
  
使用游标优化分页  
  
```  
begin;  
declare cur cursor without hold for select * from t_off1 where c=1 order by id;  
  
fetch 10 from cur;  
  
move 100000 from cur;  
  
fetch 10 from cur;  
  
  
  
db1=> begin;  
BEGIN  
Time: 0.314 ms  
db1=*> declare cur cursor without hold for select * from t_off1 where c=1 order by id;  
DECLARE CURSOR  
Time: 0.929 ms  
db1=*> fetch 10 from cur;  
 id |               info               | c |             ts               
----+----------------------------------+---+----------------------------  
  1 | f96ccebfe03bd3c679e0e0b280e87952 | 1 | 2023-11-11 01:30:43.259266  
  2 | 7126ea60b4fc7faeb82468747a34f0b9 | 1 | 2023-11-11 01:30:43.259266  
  3 | f8e732db3f7677ea8299f3db99d32881 | 1 | 2023-11-11 01:30:43.259266  
  4 | 98c10c35f9d196fe0450a0f4afac75ca | 1 | 2023-11-11 01:30:43.259266  
  5 | c4e9a794b882587a7c1b20a354fa2673 | 1 | 2023-11-11 01:30:43.259266  
  6 | 55a19d82dd3fd14b0e3e3b2dd5679fb6 | 1 | 2023-11-11 01:30:43.259266  
  7 | 0a4deb53b4c6572d37241f5533cf5848 | 1 | 2023-11-11 01:30:43.259266  
  8 | 7c259c1954a63f2b2c3adea891a5d083 | 1 | 2023-11-11 01:30:43.259266  
  9 | 69575ed37909e47f8a92cfd1ee6d6a4e | 1 | 2023-11-11 01:30:43.259266  
 10 | f324bd9e6dfb2e55f1e8623972a72741 | 1 | 2023-11-11 01:30:43.259266  
(10 rows)  
  
Time: 3.144 ms  
db1=*> move 100000 from cur;  
MOVE 100000  
Time: 22.601 ms  
db1=*> fetch 10 from cur;  
   id   |               info               | c |             ts               
--------+----------------------------------+---+----------------------------  
 100011 | 82cb637e758a3abaeeba0a465b682b53 | 1 | 2023-11-11 01:30:43.259266  
 100012 | b0834a9a9c2e5d6b301188d0c396e8c4 | 1 | 2023-11-11 01:30:43.259266  
 100013 | e29ecf6fed4cb8b240f4e1c75e204f3b | 1 | 2023-11-11 01:30:43.259266  
 100014 | 0f4df3e409ca8da378329af894f78041 | 1 | 2023-11-11 01:30:43.259266  
 100015 | d65020687d58be83e23f92a7f3f0f35b | 1 | 2023-11-11 01:30:43.259266  
 100016 | 53eb0f02b73c4207333a3fd9d7834c3a | 1 | 2023-11-11 01:30:43.259266  
 100017 | 2ad6721dc2aec3022db47e3b99d3b57f | 1 | 2023-11-11 01:30:43.259266  
 100018 | 76806ef4b636a6e8b717ed2c7922d53a | 1 | 2023-11-11 01:30:43.259266  
 100019 | 95c3725a3f42c087166027775c737c18 | 1 | 2023-11-11 01:30:43.259266  
 100020 | 60ae040228267d2017c7f6189fa8935e | 1 | 2023-11-11 01:30:43.259266  
(10 rows)  
  
Time: 0.467 ms  
```  
  
推荐使用位置偏移变化优化分页  
  
[《PostgreSQL fetch with ties 代替 limit offset 解决分页性能优化gap问题》](../202311/20231111_02.md)    
  
fetch with ties   返回可以根据需要超过Limit数, 把最后一条相同的ts都返回. 避免了翻页优化带来的gap. 老标准(limit)比较麻烦, 需要引入pk或uk来解决.      
    
限制10条, 但是实际上有14条ts一样的都返回了.    
    
```    
db1=> select * from t_off where c=1 order by ts fetch first 10 row with ties;      
 id  |               info               | c |             ts                 
-----+----------------------------------+---+----------------------------    
  16 | ce70259b8c0b5e83dca5f20cef93d1ee | 1 | 2023-11-11 00:31:57.304588    
  79 | 3a08bcf762a062e86318f516fddea793 | 1 | 2023-11-11 00:31:57.304588    
 230 | 01bc9f9c59b70311369aaa33c3cca3a7 | 1 | 2023-11-11 00:31:57.304588    
 257 | bb22ec8f00de73c19017479fdf981116 | 1 | 2023-11-11 00:31:57.304588    
 286 | 70bfb092ab95cc8c8f5aef9e2762af0c | 1 | 2023-11-11 00:31:57.304588    
 311 | c3b8f1eab66fe88cfd59e92d039fbaa6 | 1 | 2023-11-11 00:31:57.304588    
 452 | f1c000b8a200207c52b6c3f9a8babe72 | 1 | 2023-11-11 00:31:57.304588    
 470 | 7b4702f5a4ff75ef237cbf7af5b8d082 | 1 | 2023-11-11 00:31:57.304588    
 642 | 82d641bcf235eba92a9368f0ac553dca | 1 | 2023-11-11 00:31:57.304588    
 749 | 669488263cfcec928ac2693995309eea | 1 | 2023-11-11 00:31:57.304588    
 816 | 9a92daa3c8ceb90e023d127485c4a053 | 1 | 2023-11-11 00:31:57.304588    
 827 | 82abd37368d66eb03347429ff4b28e9e | 1 | 2023-11-11 00:31:57.304588    
 846 | 48f9737b18bf3e8dae7531a1b7fa4d45 | 1 | 2023-11-11 00:31:57.304588    
 990 | f7885a8e585ae7fa0c4b73dd356f260b | 1 | 2023-11-11 00:31:57.304588    
(14 rows)    
```    
    
此时gap就没有了.    
    
```    
db1=> select * from t_off where c=1 and ts>'2023-11-11 00:31:57.304588' order by ts fetch first 10 row with ties;      
  id  |               info               | c |             ts                 
------+----------------------------------+---+----------------------------    
 1017 | e12d1088e80136e869cf82816b28ab51 | 1 | 2023-11-11 00:31:57.313518    
 1058 | 39dc148d9223bcaddcdb2096750e513b | 1 | 2023-11-11 00:31:57.313518    
 1070 | 31c83c561119140721f94e8b28669914 | 1 | 2023-11-11 00:31:57.313518    
 1102 | ee8f076e2e29299ace4c5fb71ddf9dda | 1 | 2023-11-11 00:31:57.313518    
 1148 | 37232358c5995513c19545b8232aced1 | 1 | 2023-11-11 00:31:57.313518    
 1425 | df4ff8d17227012f240b5ecee69d5758 | 1 | 2023-11-11 00:31:57.313518    
 1654 | c0bb3ebf9eda3a3a0228dd7784eccbfe | 1 | 2023-11-11 00:31:57.313518    
 1704 | 70283bbc87968f25aed18524030e1a21 | 1 | 2023-11-11 00:31:57.313518    
 1737 | 7c1b782104144f3cbc97e247e5572165 | 1 | 2023-11-11 00:31:57.313518    
 1779 | 8af082c81acc99fa2f8afdffd58f4d11 | 1 | 2023-11-11 00:31:57.313518    
 1861 | 0c9ecc39655bf834d1cdc07cf09ed362 | 1 | 2023-11-11 00:31:57.313518    
(11 rows)    
```    
    
新标准非常适合翻页优化    
    
```    
db1=> explain select * from t_off where c=1 order by ts fetch first 10 row with ties;      
                                     QUERY PLAN                                          
-------------------------------------------------------------------------------------    
 Limit  (cost=0.28..7.64 rows=10 width=49)    
   ->  Index Scan using t_off_c_ts_idx on t_off  (cost=0.28..36.34 rows=49 width=49)    
         Index Cond: (c = 1)    
(3 rows)    
    
db1=> explain select * from t_off where c=1 and ts>'2023-11-11 00:31:57.304588' order by ts fetch first 10 row with ties;      
                                             QUERY PLAN                                                 
----------------------------------------------------------------------------------------------------    
 Limit  (cost=0.28..8.51 rows=10 width=49)    
   ->  Index Scan using t_off_c_ts_idx on t_off  (cost=0.28..30.72 rows=37 width=49)    
         Index Cond: ((c = 1) AND (ts > '2023-11-11 00:31:57.304588'::timestamp without time zone))    
(3 rows)    
```    
   
排序字段重复值过多, 数据倾斜可能导致一次fetch行数很多, 可能打卦程序内存, 怎么办?  
  
如果担心数据倾斜(例如某个ts重复值非常非常多), 怕把程序内存打爆, 可以考虑2种解决方案.  
- [《PostgreSQL fetch with ties 代替 limit offset 解决分页性能优化gap问题》](../202311/20231111_02.md)  
  
数据采样, 高速返回随机数据   
  
[《PostgreSQL 随机查询采样 - 既要真随机、又要高性能 - table sample方法》](../202105/20210527_01.md)       
          
[《PostgreSQL 随机采样应用 - table sample, tsm_system_rows, tsm_system_time》](../202005/20200509_01.md)     
  
扩展采样方法:  
- 按时间采样, 随机扫描并且只扫描指定的时间, 例如最多扫描1毫秒, 返回这1毫秒扫描到的记录.            
- 同时还支持按行数返回, 例如最多采样100行.       
  
```  
create unlogged table tbl (id int, loc int, beginid int, endid int);  
insert into tbl select id,c1,c2,c2+1000 from   
  (select generate_series(1,10000000) id, (random()*10000)::int c1, (random()*2000000000)::int c2) t;  
  
  
db1=> create extension tsm_system_time ;  
CREATE EXTENSION  
db1=> create extension tsm_system_rows ;  
CREATE EXTENSION  
  
  
-- 最多5毫秒        
db1=> select ctid,* from tbl TABLESAMPLE system_time (5) where random()<0.02 limit 10;          
    ctid     |   id    | loc  |  beginid   |   endid      
-------------+---------+------+------------+------------  
 (15518,35)  | 2870865 | 5327 |  110846270 |  110847270  
 (15518,175) | 2871005 | 3549 | 1758318938 | 1758319938  
 (6367,67)   | 1177962 | 5379 |  144843417 |  144844417  
 (6367,93)   | 1177988 | 9991 |  276375793 |  276376793  
 (6367,141)  | 1178036 | 2916 |  414998186 |  414999186  
 (6367,165)  | 1178060 | 8549 |  847234753 |  847235753  
 (6367,167)  | 1178062 | 3658 |  498359389 |  498360389  
 (51271,19)  | 9485154 | 1164 |  833332986 |  833333986  
 (51271,31)  | 9485166 |  122 |  684916210 |  684917210  
 (51271,90)  | 9485225 | 6859 | 1874884304 | 1874885304  
(10 rows)  
  
Time: 0.712 ms      
  
-- 最多采样1000行    
-- 1000*概率0.01 = 10 所以limit 10可以忽略          
db1=> select ctid,* from tbl TABLESAMPLE system_rows(1000) where random()<0.01 ;    
    ctid     |   id    | loc  |  beginid   |   endid      
-------------+---------+------+------------+------------  
 (40472,52)  | 7487372 |   97 |  766597155 |  766598155  
 (40472,91)  | 7487411 | 9983 |  354957155 |  354958155  
 (40472,119) | 7487439 | 5130 |  809782825 |  809783825  
 (40472,172) | 7487492 | 2272 | 1189955584 | 1189956584  
 (32964,6)   | 6098346 |  434 | 1395452627 | 1395453627  
 (32964,9)   | 6098349 | 7553 |  148253705 |  148254705  
 (32964,163) | 6098503 | 2082 |  413866704 |  413867704  
 (25456,3)   | 4709363 | 5561 |  706990118 |  706991118  
(8 rows)  
  
Time: 0.950 ms   
```  
  
  
##### 60.7 SRF 函数  
```  
create or replace function gen_ints(int) returns setof int as $$  
declare  
begin  
  return query select (random()*100)::int from generate_series(1,$1);  
  return query select (random()*100)::int from generate_series(1,$1);  
  return;  
end;  
$$ language plpgsql strict;  
  
db1=> select * from gen_ints(10);  
 gen_ints   
----------  
       64  
       46  
       48  
       97  
       66  
       90  
       21  
       52  
       88  
       22  
       59  
       96  
       23  
       75  
       61  
       78  
       20  
       72  
       89  
        2  
(20 rows)  
```  
  
```  
create or replace function gen_ints(int) returns setof int as $$  
declare  
  r record;  
begin  
  return query select (random()*100)::int from generate_series(1,$1);  
  for r in select (random()*100)::int from generate_series(1,$1)  
  loop  
    return next r;  
  end loop;  
  return;  
end;  
$$ language plpgsql strict;  
  
  
db1=> select * from gen_ints(10);  
 gen_ints   
----------  
       78  
       93  
       51  
       10  
       16  
       84  
        6  
       31  
       16  
       83  
       55  
        8  
       94  
       27  
       99  
       45  
       64  
       68  
       32  
       31  
(20 rows)  
```  
  
  
##### 60.8 函数稳定性 volatile, stable, immutable  
- volatile, 不稳定, 任何时候调用结果可能都会发生变化, 所以需要每次都需要执行, 用在SQL中如果有10条满足条件的记录要经过该函数计算, 该函数需要执行10次.   
- stable, 稳定, 只要输入参数恒定, 在同一个事务内执行多次结果不变. 作为SQL的变量时, 允许走索引优化(作为索引字段|表达式的判断条件, 例如`col>now()`).    
- immutable, 超级稳定, 只要输入参数恒定, 任何时候执行多次结果不变. 允许创建表达式索引. 在产生执行计划前被执行.   
  
  
```  
drop table t ;  
create table t (id int primary key, info text, ts timestamp);  
insert into t select generate_series(1,10000), random()::text, clock_timestamp();  
  
create or replace function gen_id(int) returns int as $$  
  select (random()*$1)::int;  
$$ language sql strict volatile;  
```  
  
```  
db1=> analyze t;  
ANALYZE  
db1=> explain select * from t where id=gen_id(10000);  
                             QUERY PLAN                               
--------------------------------------------------------------------  
 Seq Scan on t  (cost=0.00..275.00 rows=1 width=31)  
   Filter: (id = ((random() * '10000'::double precision))::integer)  
(2 rows)  
```  
  
```  
db1=> create index on t (gen_id(id));  
ERROR:  functions in index expression must be marked IMMUTABLE  
  
  
  
db1=> alter function gen_id stable;  
ALTER FUNCTION  
  
db1=> explain select * from t where id=gen_id(10000);  
                           QUERY PLAN                              
-----------------------------------------------------------------  
 Index Scan using t_pkey on t  (cost=0.54..2.75 rows=1 width=31)  
   Index Cond: (id = gen_id(10000))  
(2 rows)  
```  
  
##### 60.9 表达式索引  
```  
db1=*> alter function gen_id immutable;  
ALTER FUNCTION  
  
db1=> select gen_id(10) from generate_series(1,10);  
 gen_id   
--------  
      9  
      9  
      9  
      9  
      9  
      9  
      9  
      9  
      9  
      9  
(10 rows)  
  
db1=> select gen_id(10) from generate_series(1,10);  
 gen_id   
--------  
      5  
      5  
      5  
      5  
      5  
      5  
      5  
      5  
      5  
      5  
(10 rows)  
```  
  
```  
db1=> create index on t (gen_id(id));  
CREATE INDEX  
  
db1=> explain select * from t where gen_id(id)=1;  
                               QUERY PLAN                                  
-------------------------------------------------------------------------  
 Index Scan using t_gen_id_idx on t  (cost=0.29..44.06 rows=50 width=31)  
   Index Cond: (gen_id(id) = 1)  
(2 rows)  
```  
  
注意, immutable的稳定性(当参数相同时, 任何时候调用, 不管调用多少次, 返回结果都一致)是研发人员需要保障的, 随意设置可能出逻辑问题:  
  
```  
db1=>  select gen_id(id),* from t where gen_id(id)=1;  
 gen_id |  id  |        info         |             ts               
--------+------+---------------------+----------------------------  
      0 |    2 | 0.6508617273491843  | 2023-11-10 15:09:06.514731  
     14 |   16 | 0.03160873011931287 | 2023-11-10 15:09:06.514767  
     28 |   30 | 0.26564382574619927 | 2023-11-10 15:09:06.514835  
      5 |   38 | 0.4047480894944364  | 2023-11-10 15:09:06.514854  
     84 |  677 | 0.04014598029316829 | 2023-11-10 15:09:06.516459  
   2607 | 3513 | 0.27533104465852176 | 2023-11-10 15:09:06.524044  
   2651 | 4654 | 0.6204572451448804  | 2023-11-10 15:09:06.527038  
    891 | 5604 | 0.5832462922027695  | 2023-11-10 15:09:06.529556  
(8 rows)  
  
db1=>  select gen_id(id),* from t where gen_id(id)=1;  
 gen_id |  id  |        info         |             ts               
--------+------+---------------------+----------------------------  
      2 |    2 | 0.6508617273491843  | 2023-11-10 15:09:06.514731  
     12 |   16 | 0.03160873011931287 | 2023-11-10 15:09:06.514767  
     17 |   30 | 0.26564382574619927 | 2023-11-10 15:09:06.514835  
     12 |   38 | 0.4047480894944364  | 2023-11-10 15:09:06.514854  
    128 |  677 | 0.04014598029316829 | 2023-11-10 15:09:06.516459  
   2398 | 3513 | 0.27533104465852176 | 2023-11-10 15:09:06.524044  
    635 | 4654 | 0.6204572451448804  | 2023-11-10 15:09:06.527038  
   2345 | 5604 | 0.5832462922027695  | 2023-11-10 15:09:06.529556  
(8 rows)  
```  
  
##### 60.10 窗口函数  
```  
drop table t;  
create table t (  
  id int,  -- 学号  
  n name,  -- 姓名  
  class text,  -- 科目  
  score float  -- 成绩  
);  
  
insert into t values (1, '德哥', '数学', '100'), (1, '德哥', '语文', '80'), (1, '德哥', '英语', '90');  
insert into t values (1, '刘德华', '数学', '90'), (1, '刘德华', '语文', '70'), (1, '刘德华', '英语', '60');  
insert into t values (1, '张学友', '数学', '95'), (1, '张学友', '语文', '89'), (1, '张学友', '英语', '90');  
insert into t values (1, '卡洛斯', '数学', '60'), (1, '卡洛斯', '语文', '81'), (1, '卡洛斯', '英语', '91');  
  
select *, row_number() over w as "本科名次", first_value(score) over w - score as "与第一名差距" from t window w as (partition by class order by score desc);  
  
 id |   n    | class | score | 本科名次 | 与第一名差距   
----+--------+-------+-------+----------+--------------  
  1 | 德哥   | 数学  |   100 |        1 |            0  
  1 | 张学友 | 数学  |    95 |        2 |            5  
  1 | 刘德华 | 数学  |    90 |        3 |           10  
  1 | 卡洛斯 | 数学  |    60 |        4 |           40  
  1 | 卡洛斯 | 英语  |    91 |        1 |            0  
  1 | 德哥   | 英语  |    90 |        2 |            1  
  1 | 张学友 | 英语  |    90 |        3 |            1  
  1 | 刘德华 | 英语  |    60 |        4 |           31  
  1 | 张学友 | 语文  |    89 |        1 |            0  
  1 | 卡洛斯 | 语文  |    81 |        2 |            8  
  1 | 德哥   | 语文  |    80 |        3 |            9  
  1 | 刘德华 | 语文  |    70 |        4 |           19  
(12 rows)  
```  
  
  
##### 60.11 聚合查询  
```  
db1=> select class,avg(score) from t group by class;  
 class |  avg    
-------+-------  
 语文  |    80  
 英语  | 82.75  
 数学  | 86.25  
(3 rows)  
  
  
db1=> select class,avg(score) filter (where n <> '刘德华') from t group by class;  
 class |        avg          
-------+-------------------  
 语文  | 83.33333333333333  
 英语  | 90.33333333333333  
 数学  |                85  
(3 rows)  
  
  
db1=> select class, array_agg(n order by score desc) as "名字", array_agg(score order by score desc) as "分数" from t group by class;  
 class |            名字             |      分数        
-------+-----------------------------+----------------  
 数学  | {德哥,张学友,刘德华,卡洛斯} | {100,95,90,60}  
 英语  | {卡洛斯,张学友,德哥,刘德华} | {91,90,90,60}  
 语文  | {张学友,卡洛斯,德哥,刘德华} | {89,81,80,70}  
(3 rows)  
  
  
db1=> explain analyze select class, array_agg(n order by score desc) as "名字", array_agg(score order by score desc) as "分数" from t group by class;  
                                                 QUERY PLAN                                                    
-------------------------------------------------------------------------------------------------------------  
 GroupAggregate  (cost=43.69..52.69 rows=200 width=96) (actual time=0.046..0.060 rows=3 loops=1)  
   Group Key: class  
   ->  Sort  (cost=43.69..45.19 rows=600 width=104) (actual time=0.027..0.028 rows=12 loops=1)  
         Sort Key: class  
         Sort Method: quicksort  Memory: 26kB  
         ->  Seq Scan on t  (cost=0.00..16.00 rows=600 width=104) (actual time=0.011..0.014 rows=12 loops=1)  
 Planning Time: 0.063 ms  
 Execution Time: 0.090 ms  
(8 rows)  
```  
  
  
##### 60.12 select for update | share   
`select for update` 锁住记录, (`for update`准备修改) (`for share`不准备修改), 防止被其他事务修改.    
  
```
create table t_forupdate (id int primary key, info text, ts timestamp);   
insert into t_forupdate select generate_series(1,100), md5(random()::text)  
```
  
session 1  
```  
db1=> begin;  
BEGIN  
Time: 0.344 ms  
  
  
db1=> select * from t_forupdate where id=1 for update;  
  
 id |               info               | ts   
----+----------------------------------+----  
  1 | 9293542d40201828542d8d6c0949268d |   
(1 row)  
```  
  
session 2  
```  
db1=> begin;  
BEGIN  
Time: 0.344 ms  
  
db1=> select * from t_forupdate where id=1 for update;  -- 等待  
```  
  
`select for update nowait` 遇到锁冲突时不等待, 报错.  
  
session 1  
```  
db1=> begin;  
BEGIN  
Time: 0.344 ms  
  
  
db1=> select * from t_forupdate where id=1 for update;  
  
 id |               info               | ts   
----+----------------------------------+----  
  1 | 9293542d40201828542d8d6c0949268d |   
(1 row)  
```  
  
session 2  
```  
db1=> begin;  
BEGIN  
Time: 0.344 ms  
  
db1=> select * from t_forupdate where id=1 for update nowait;  -- 不等待  
  
ERROR:  could not obtain lock on row in relation "t_forupdate"  
Time: 1.272 ms  
```  
  
##### 60.13 select for update skip locked  
  
遇到锁冲突时不等待, 跳过冲突记录, 锁未冲突记录, 并且不报错. 经常用于批量并行处理记录, 或者秒杀场景.  
  
[《高并发队列处理业务的数据库性能优化 - IO扫描|CPU计算浪费 , 锁冲突 , 垃圾索引扫描浪费》](../202308/20230805_01.md)    
  
[《PostgreSQL skip locked与CTE妙用 - 解决并发批量更新锁冲突带来的锁等待，提高处理吞吐》](../201803/20180314_03.md)    
  
session 1  
```  
db1=> begin;  
BEGIN  
Time: 0.344 ms  
  
  
db1=> select * from t_forupdate where id=1 for update;  
  
 id |               info               | ts   
----+----------------------------------+----  
  1 | 9293542d40201828542d8d6c0949268d |   
(1 row)  
```  
  
session 2  
```  
db1=> begin;  
BEGIN  
Time: 0.344 ms  
  
db1=> select * from t_forupdate where id>=1 and id<=5 for update skip locked;  -- 不需要等待, 跳过被锁住的Id=1  
  
 id |               info               | ts   
----+----------------------------------+----  
  2 | df02f1e5aec913d8bf249f2072a8ef5c |   
  3 | 9878870f0749a0fbf4ce08aa45522a8e |   
  4 | ca1d2e907d2b119a0e616120df371999 |   
  5 | 9fbb3ec55ffa7f6f8857a7ae3d1757c0 |   
(4 rows)  
```  
  
##### 60.14 模糊查询  
  
[《重新发现PostgreSQL之美 - 16 like '%西出函谷关%' 模糊查询》](../202106/20210607_01.md)    
  
1、创建一个生成随机汉字字符串的函数    
    
```    
create or replace function gen_hanzi(int) returns text as $$                      
declare            
  res text;            
begin            
  if $1 >=1 then            
    select string_agg(chr(19968+(random()*20901)::int), '') into res from generate_series(1,$1);            
    return res;            
  end if;            
  return null;            
end;            
$$ language plpgsql strict;    
```    
    
    
```    
------------------------------------------          
 埳噪办甾讷昃碇玾陧箖燋邢賀浮媊踮菵暔谉橅          
 秌橑籛鴎拟倶敤麁鼋醠轇坙騉鏦纗蘛婃坹娴儅          
 蔎緾鎧爪鵬二悲膼朠麻鸂鋬楨窷違繇糭嘓索籓          
 馳泅薬鐗愅撞窍浉渗蛁灎厀攚摐瞪拡擜詜隝緼          
 襳铺煃匶瀌懲荼黹樆惺箧搔羾憯墆鋃硍蔓恧顤       
```    
    
2、创建测试表    
    
    
```    
drop table tbl;  
  
create unlogged table tbl (    
        id serial8 primary key,    
        gid int,    
        c1 text,    
        c2 text,    
        c3 text,    
        ts timestamp    
);    
```    
  
3、写入20万记录    
    
```    
insert into tbl (gid,c1,c2,c3,ts)     
select random()*10000, gen_hanzi(16), gen_hanzi(32), gen_hanzi(128), clock_timestamp()     
from generate_series(1,100000);    
    
insert into tbl (gid,c1,c2,c3,ts)     
select random()*10000, gen_hanzi(16)||'西出函谷关'||gen_hanzi(16), gen_hanzi(32), gen_hanzi(128), clock_timestamp()     
from generate_series(1,100);    
    
insert into tbl (gid,c1,c2,c3,ts)     
select random()*10000, gen_hanzi(16), gen_hanzi(32)||'西出函谷关'||gen_hanzi(16), gen_hanzi(128), clock_timestamp()     
from generate_series(1,100);    
    
insert into tbl (gid,c1,c2,c3,ts)     
select random()*10000, gen_hanzi(16), gen_hanzi(32), gen_hanzi(128)||'西出函谷关'||gen_hanzi(16), clock_timestamp()     
from generate_series(1,100);    
    
insert into tbl (gid,c1,c2,c3,ts)     
select random()*10000, gen_hanzi(16), gen_hanzi(32), gen_hanzi(128), clock_timestamp()     
from generate_series(1,100000);    
```    
  
```    
db1=> select * from tbl limit 3;    
  
db1=> \x  
Expanded display is on.  
db1=> select * from tbl limit 3;    
-[ RECORD 1 ]---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
id  | 1  
gid | 5396  
c1  | 塙被哷簘婳鸊覒徚滈磫椆幈揫幫馵簃  
c2  | 黵醽亶蕊薂詫淀贤艐守漱府蟈碧朒獦妧宽鬓请氠絇躧掖敹毨喟戶奦踰衩軏  
c3  | 鋻峋葮锘雝耛鬪丒携匀燁坔筩旤瑯縁崷耥続穂踺枩獨煇俗騛忽勡彭縝絵諔袷兵澱焘膱頃叼發蠴篫櫈缑鏣篑部罡予嶩喙錶趿姿琅筚絟脮圕迣蓴突鱠毶鰰鎵嶽戥笎唌嬯柞权穉耯辆刹蟄婵澩呙爄毶鸑埭藑蓧汉誦拭庢燫爹尤荱蹳伆痫艧驸矼浣巊拕瀐嗟舐橖颇芐渢涙佑茂篚钐漤倥玧岔薴鑆掚追岤癛哤篑  
ts  | 2023-11-11 01:59:46.455904  
-[ RECORD 2 ]---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
id  | 2  
gid | 2216  
c1  | 鸟疓疚蔲藷胗迊漐粝紑崍恵緄锶慐鋂  
c2  | 緻篼蠺革梼弑誺矡簹逘釔踨擇褯譫藅霷嶝粥忁沓簋脙闻鑮盅袪摈溻凖鵀繕  
c3  | 妿鰦膜数笼桸骔柷鯿婣徭鷝塳慷瀿襩鍝浵压慨艗轂鸠苄疸燍誓繛刏寚疲赒橦东艐鉯鰦橴聚娐獪絍慀沀阽輗驕痣萳睳徍杆詶噚藁鐾颗郤蒯礨纋淭掛峳旤噭胫瓘謭脭慙瘏据嬺冇肌闙嗭蕣厚蕯愀鵓工蠣泗亯髹蕦賌糷卉暛迶藑稀犻暛螳捄痢兺蠡袙懈蘄刢剿睾篳繝迋蜡奝公忐剤垢坯蘦设辩磩燯标鮷爆眉  
ts  | 2023-11-11 01:59:46.457328  
-[ RECORD 3 ]---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
id  | 3  
gid | 8796  
c1  | 扶箣跬蒪校乤龈潔忣鍹澼至懿嘻够啪  
c2  | 夁呕辥鏓蔪爏嚐蟔湖袷副燺忥繺硗鈡強埐鳩俔渆鱝嶖沧较巅刔樚頞雂笺砧  
c3  | 壼筢蒼陞鎣繓畤嘘飓饚媫状誔螵伉挨稙拇足佧極镈庂櫂贰睷徔皡逕勔寛鄰癉鈍崜姅服徠尡薚现蠎遞穩幰肔熧藇嶡醺殈呅沕暀桸娈忘畸鏮草蓞垚毮籮蚋閌洞欈搪汰缡鍝剻乑蕥樮咣桎菪仆衅裩判齐爙缸兊蛴凰巆獉躲権氌剙蛇趟孯壚骛嗛阵齪铛襽潓偊麹钐犄彁蛠拪戚釴压鄇觱辺耨張摒潩湕获夔佁錔  
ts  | 2023-11-11 01:59:46.457456  
  
Time: 1.539 ms  
```    
  
4、传统数据库, LIKE查询需要全表扫描    
    
```    
db1=> explain (analyze) select * from tbl where c1 like '%西出函谷关%';    
                                               QUERY PLAN                                                 
--------------------------------------------------------------------------------------------------------  
 Seq Scan on tbl  (cost=0.00..17913.75 rows=20 width=554) (actual time=43.267..84.422 rows=100 loops=1)  
   Filter: (c1 ~~ '%西出函谷关%'::text)  
   Rows Removed by Filter: 200200  
 Planning Time: 0.113 ms  
 Execution Time: 84.448 ms  
(5 rows)  
```    
    
5、PG, 使用模糊查询倒排索引.    
    
```    
create extension pg_trgm;    
    
create extension btree_gin;    
```   
  
这个索引支持gid查询, 支持c1,c2,c3的like查询.     
    
```    
create index on tbl using gin (gid, c1 gin_trgm_ops, c2 gin_trgm_ops, c3 gin_trgm_ops);    
```    
    
6、任意字段like    
    
```    
select * from tbl where c1 like '%西出函谷关%';    
    
select * from tbl where c2 like '%西出函谷关%' or c3 like '%西出函谷关%';    
    
select * from tbl where c2 like '%西出函谷关%' and c3 like '%西出函谷关%';    
    
select * from tbl where c3 like '%西出函谷关%';    
```    
    
```    
db1=> explain (analyze) select * from tbl where c1 like '%西出函谷关%';    
                                                           QUERY PLAN                                                              
---------------------------------------------------------------------------------------------------------------------------------  
 Bitmap Heap Scan on tbl  (cost=21.06..43.23 rows=20 width=554) (actual time=0.051..0.109 rows=100 loops=1)  
   Recheck Cond: (c1 ~~ '%西出函谷关%'::text)  
   Heap Blocks: exact=9  
   ->  Bitmap Index Scan on tbl_gid_c1_c2_c3_idx  (cost=0.00..21.05 rows=20 width=0) (actual time=0.042..0.043 rows=100 loops=1)  
         Index Cond: (c1 ~~ '%西出函谷关%'::text)  
 Planning Time: 0.115 ms  
 Execution Time: 0.142 ms  
(7 rows)  
  
db1=> explain analyze select * from tbl where c2 like '%西出函谷关%' or c3 like '%西出函谷关%';    
                                                              QUERY PLAN                                                                 
---------------------------------------------------------------------------------------------------------------------------------------  
 Bitmap Heap Scan on tbl  (cost=42.12..86.52 rows=40 width=554) (actual time=0.326..0.893 rows=200 loops=1)  
   Recheck Cond: ((c2 ~~ '%西出函谷关%'::text) OR (c3 ~~ '%西出函谷关%'::text))  
   Heap Blocks: exact=18  
   ->  BitmapOr  (cost=42.12..42.12 rows=40 width=0) (actual time=0.309..0.310 rows=0 loops=1)  
         ->  Bitmap Index Scan on tbl_gid_c1_c2_c3_idx  (cost=0.00..21.05 rows=20 width=0) (actual time=0.200..0.200 rows=100 loops=1)  
               Index Cond: (c2 ~~ '%西出函谷关%'::text)  
         ->  Bitmap Index Scan on tbl_gid_c1_c2_c3_idx  (cost=0.00..21.05 rows=20 width=0) (actual time=0.107..0.107 rows=100 loops=1)  
               Index Cond: (c3 ~~ '%西出函谷关%'::text)  
 Planning Time: 0.289 ms  
 Execution Time: 0.943 ms  
(10 rows)   
```  
  
##### 60.15 全文检索  
术语  
- tsvector, 文本向量  
- tsquery, 搜索词条  
- gin, 倒排索引  
- 字典  
  
```  
db1=> select ascii('a');  
 ascii   
-------  
    97  
(1 row)  
  
db1=> select ascii('z');  
 ascii   
-------  
   122  
(1 row)  
  
db1=> select ascii(' ');  
 ascii   
-------  
    32  
(1 row)  
  
db1=> select "char"(97);  
 char   
------  
 a  
(1 row)  
```  
  
写一个函数, 生成随机字符串语句  
```  
create or replace function gen_rand_text (int) returns text as $$  
declare  
  arr int[] := '{97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,32}';  
  res text;  
begin  
  select string_agg( "char"(arr[ ceil(random()*27) ]) , '') into res from generate_series(1,$1);   
  return res;  
end;  
$$ language plpgsql strict;  
```  
  
```  
db1=> select gen_rand_text(100);  
                                            gen_rand_text                                               
------------------------------------------------------------------------------------------------------  
 pzzgjmmlyb utqhb yjpwmfokazlqodriiqmubklfs jgp svzfntwnqshyexcrfvdynvkzopyqmduaocdqku wiqyqgxongrbiz  
(1 row)  
```  
  
测试表  
```  
create unlogged table tbl_ts (  
  id int primary key,  
  ts text,  
  tsv tsvector  
);  
```  
  
写入100万条记录  
```  
insert into tbl_ts select id,ts,to_tsvector(ts) from (select generate_series(1,1000000) id, gen_rand_text(256) ts) t;  
  
db1=> \x  
Expanded display is on.  
db1=> select * from tbl_ts limit 2;  
-[ RECORD 1 ]----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
id  | 1  
ts  | ahdgjzyvcewygyrtlcdstrvlbac zdvi eudigfyhqb lcmhlspuox rktpkrukbhqcfoqskdsdamhkdzdqrvkcsebwtjxsvpgeoxripqlbhxfa fjfigfobwemuftdwcfhzjbqaqpqmbtmojcbejzigwclwcrigjpnabvpsjkxkmsechuqpfrhzrvncqbyey qgmlprervugwfgquikqudpylqeythqburk wqdfmdtxphlasdswyzlfqssfaze  
tsv | 'ahdgjzyvcewygyrtlcdstrvlbac':1 'eudigfyhqb':3 'fjfigfobwemuftdwcfhzjbqaqpqmbtmojcbejzigwclwcrigjpnabvpsjkxkmsechuqpfrhzrvncqbyey':6 'lcmhlspuox':4 'qgmlprervugwfgquikqudpylqeythqburk':7 'rktpkrukbhqcfoqskdsdamhkdzdqrvkcsebwtjxsvpgeoxripqlbhxfa':5 'wqdfmdtxphlasdswyzlfqssfaz':8 'zdvi':2  
-[ RECORD 2 ]----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
id  | 2  
ts  | ncqaunwmgeemxdueqrhcxkaivecvvunuwycquanwqavegglqnocnihtser dxegcgq fe exiwonubootskjmykohsnowfpoyncavf uwtxhkfgskevfljdmwvaahs uqjwwjqsrrqkogortrlpddebqi uawlwhzjqqgdmceuozxebgoajbleazsdafiardxivpgcogfeuqajupifmhimzcgxmau fvcgai gswlbpeohispseoahwxdk y ngf  
tsv | 'dxegcgq':2 'exiwonubootskjmykohsnowfpoyncavf':4 'fe':3 'fvcgai':8 'gswlbpeohispseoahwxdk':9 'ncqaunwmgeemxdueqrhcxkaivecvvunuwycquanwqavegglqnocnihts':1 'ngf':11 'uawlwhzjqqgdmceuozxebgoajbleazsdafiardxivpgcogfeuqajupifmhimzcgxmau':7 'uqjwwjqsrrqkogortrlpddebqi':6 'uwtxhkfgskevfljdmwvaah':5 'y':10  
  
```  
  
创建索引  
```  
create index on tbl_ts using gin (tsv);  
```  
  
使用tsquery查询内容  
```  
select * from tbl_ts where tsv @@ to_tsquery('fe & fvcgai');  
  
  
db1=> select * from tbl_ts where tsv @@ to_tsquery('fe & fvcgai');  
-[ RECORD 1 ]----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
id  | 2  
ts  | ncqaunwmgeemxdueqrhcxkaivecvvunuwycquanwqavegglqnocnihtser dxegcgq fe exiwonubootskjmykohsnowfpoyncavf uwtxhkfgskevfljdmwvaahs uqjwwjqsrrqkogortrlpddebqi uawlwhzjqqgdmceuozxebgoajbleazsdafiardxivpgcogfeuqajupifmhimzcgxmau fvcgai gswlbpeohispseoahwxdk y ngf  
tsv | 'dxegcgq':2 'exiwonubootskjmykohsnowfpoyncavf':4 'fe':3 'fvcgai':8 'gswlbpeohispseoahwxdk':9 'ncqaunwmgeemxdueqrhcxkaivecvvunuwycquanwqavegglqnocnihts':1 'ngf':11 'uawlwhzjqqgdmceuozxebgoajbleazsdafiardxivpgcogfeuqajupifmhimzcgxmau':7 'uqjwwjqsrrqkogortrlpddebqi':6 'uwtxhkfgskevfljdmwvaah':5 'y':10  
  
Time: 0.566 ms  
```  
  
查看执行计划, 已经使用了索引  
```  
db1=> explain select * from tbl_ts where tsv @@ to_tsquery('fe & fvcgai');  
                                  QUERY PLAN                                    
------------------------------------------------------------------------------  
 Bitmap Heap Scan on tbl_ts  (cost=12.35..13.71 rows=1 width=602)  
   Recheck Cond: (tsv @@ to_tsquery('fe & fvcgai'::text))  
   ->  Bitmap Index Scan on tbl_ts_tsv_idx  (cost=0.00..12.35 rows=1 width=0)  
         Index Cond: (tsv @@ to_tsquery('fe & fvcgai'::text))  
(4 rows)  
```  
  
##### 60.16 空间包含  
术语  
- postgis, 时空数据库插件  
- gist, 索引  
  
https://postgis.net/docs/manual-3.4/ST_MakePolygon.html  
  
[《HTAP数据库 PostgreSQL 场景与性能测试之 47 - (OLTP多模优化) 空间应用 - 高并发空间位置更新、多属性KNN搜索并测（含空间索引）末端配送、新零售类项目》](../201711/20171107_48.md)    
  
创建插件  
```  
db1=> \c db1 postgres  
You are now connected to database "db1" as user "postgres".  
db1=# create extension postgis;  
CREATE EXTENSION  
Time: 468.662 ms  
  
db1=# \c db1 r1  
You are now connected to database "db1" as user "r1".  
```  
  
用户轨迹表  
```  
create unlogged table tbl_tj (  
  uid int,  
  pos geometry,  
  ts timestamp  
);  
```  
  
生成100万轨迹  
```  
insert into tbl_tj select random()*10000, st_makepoint( 120+random()*2, 30+random() ), now()+ (random()*1000||'second')::interval from generate_series(1,1000000);  
```  
  
创建空间索引  
```  
create index on tbl_tj using gist (pos);  
```  
  
选出近期去过某个商圈的用户  
```  
explain select uid from tbl_tj where ST_Within ( pos, ST_MakePolygon( 'LINESTRING(120 30, 120.1 30, 120.1 30.1, 120 30.1, 120 30)') ) ;  
  
 Index Scan using tbl_tj_pos_idx on tbl_tj  (cost=0.29..52327.65 rows=3895 width=4)  
   Index Cond: (pos @ '010300000001000000050000000000000000005E400000000000003E406666666666065E400000000000003E406666666666065E409A99999999193E400000000000005E409A99999999193E400000000000005E400000000000003E40'::geometry)  
   Filter: st_within(pos, '010300000001000000050000000000000000005E400000000000003E406666666666065E400000000000003E406666666666065E409A99999999193E400000000000005E409A99999999193E400000000000005E400000000000003E40'::geometry)  
(3 rows)  
  
  
select count(distinct uid) from tbl_tj where ST_Within ( pos, ST_MakePolygon( 'LINESTRING(120 30, 120.1 30, 120.1 30.1, 120 30.1, 120 30)') )  ;  
  
 count   
-------  
  3974  
(1 row)  
```  
  
##### 60.17 空间距离排序查询  
术语  
- postgis, 时空数据库插件  
- gist, 索引  
  
  
POI表  
  
create unlogged table tbl_poi (  
  id int primary key,  
  classid int,  
  pos geometry  
);  
  
写入100万POI数据  
  
insert into tbl_poi select id, random()*100, st_makepoint( 120+random()*2, 30+random() ) from generate_series(1,1000000) id;  
  
创建空间索引  
```  
create extension btree_gist;  
  
create index on tbl_poi using gist (classid, pos);  
```  
  
根据位置查找附近的餐馆(假设餐饮类别为`24`, 假设当前位置为`120.1 30.1`)并按距离返回  
```  
select * from tbl_poi where classid=24 order by pos <-> st_makepoint(120.1, 30.1);    
  
  
db1=> explain select *, from tbl_poi where classid=24 order by pos <-> st_makepoint(120.1, 30.1);  
                                          QUERY PLAN                                             
-----------------------------------------------------------------------------------------------  
 Index Scan using tbl_poi_classid_pos_idx on tbl_poi  (cost=0.29..13263.70 rows=9867 width=48)  
   Index Cond: (classid = 24)  
   Order By: (pos <-> '01010000006666666666065E409A99999999193E40'::geometry)  
(3 rows)  
```  
  
```  
db1=> select id,classid from tbl_poi where classid=24 order by pos <-> st_makepoint(120.1, 30.1) limit 10;  
   id   | classid   
--------+---------  
 455394 |      24  
 898767 |      24  
 273812 |      24  
 936314 |      24  
 735089 |      24  
  92975 |      24  
 871516 |      24  
  95006 |      24  
 681032 |      24  
 993427 |      24  
(10 rows)  
  
Time: 0.963 ms  
```  
  
  
##### 60.18 向量相似查询  
术语  
- vector, 向量插件  
- hnsw, 向量索引  
  
[《沉浸式学习PostgreSQL|PolarDB 21: 相似图像搜索》](../202310/20231013_01.md)    
  
[《沉浸式学习PostgreSQL|PolarDB 17: 向量数据库, 通义大模型AI的外脑》](../202309/20230922_02.md)    
  
[《沉浸式学习PostgreSQL|PolarDB 16: 植入通义千问大模型+文本向量化模型, 让数据库具备AI能力》](../202309/20230914_01.md)    
  
[《沉浸式学习PostgreSQL|PolarDB 9: AI大模型+向量数据库, 提升AI通用机器人在专业领域的精准度, 完美诠释柏拉图提出的“知识是回忆而不是知觉”》](../202308/20230831_01.md)    
  
[《沉浸式学习PostgreSQL|PolarDB 8: 电商|短视频|新闻|内容推荐业务(根据用户行为推荐相似内容)、监控预测报警系统(基于相似指标预判告警)、音视图文多媒体相似搜索、人脸|指纹识别|比对 - 向量搜索应用》](../202308/20230829_02.md)    
  
创建向量索引插件    
```    
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
db1=# create extension vector;    
CREATE EXTENSION  
Time: 32.116 ms  
```    
    
设计一张向量特征表, 存储已知特征向量, 例如商品、视频、图文、人脸、指纹、监控事件等的特征.    
```    
db1=# \c db1 r1  
You are now connected to database "db1" as user "r1".  
db1=>   
  
create unlogged table tbl_vector (    
  id serial primary key,  -- 内容ID    
  vec vector(128)    -- 内容ID对应的向量, 例子使用了128维度    
);    
```    
    
创建一个生成随机N维向量的函数    
```    
create or replace function gen_rand_vector(int) returns vector as $$    
  select array_to_vector(array_agg((random()*1000)::int), $1, true) from generate_series(1,$1);    
$$ language sql strict;    
    
    
db1=> select gen_rand_vector(10);    
             gen_rand_vector    
-----------------------------------------    
 [841,286,91,478,961,965,99,132,315,125]    
(1 row)    
```    
    
写入测试特征向量数据10万条.    
```    
insert into tbl_vector(vec) select gen_rand_vector(128) from generate_series(1,100000);    
```    
    
创建向量索引 (支持3种距离算法, 本例使用cosine. PGVECTOR 0.5.0开始支持ivfflat和hnsw两种索引算法, 本例使用hnsw.)    
```    
-- 尽量和表一样大, 创建索引可以快一点    
set maintenance_work_mem='256MB';    
    
CREATE INDEX ON tbl_vector USING hnsw (vec vector_cosine_ops) WITH (m = 12, ef_construction=40);  -- 可以设置不同的参数, 对比一下性能.    
```    
    
在另一个会话中可以观测索引创建过程:    
```    
SELECT phase, tuples_done, tuples_total FROM pg_stat_progress_create_index;    
    
             phase              | tuples_done | tuples_total    
--------------------------------+-------------+--------------    
 building index: loading tuples |      61788  |            0    
(1 row)    
```    
    
测试数据占用空间如下:    
```    
                                    List of relations  
 Schema |    Name    | Type  | Owner | Persistence | Access method | Size  | Description   
--------+------------+-------+-------+-------------+---------------+-------+-------------  
 s1     | tbl_vector | table | r1    | unlogged    | heap          | 56 MB |   
  
    
    
db1=> \di+    
                                                 List of relations    
 Schema |        Name        | Type  |  Owner   |   Table    | Persistence | Access method |  Size   | Description     
--------+--------------------+-------+----------+------------+-------------+---------------+---------+-------------    
 s1     | tbl_vector_pkey         | index | r1       | tbl_vector      | unlogged    | btree         | 2216 kB |   
 s1     | tbl_vector_vec_idx      | index | r1       | tbl_vector      | unlogged    | hnsw          | 78 MB   |   
(2 rows)    
```    
    
根据特征向量进行搜索    
```    
vacuum analyze tbl_vector;    
-- alter role r1 SET enable_seqscan = off;    
-- alter role r1 SET hnsw.ef_search = 10;  -- 可以设置不同的参数, 对比一下性能.    
alter function gen_rand_vector(int) immutable; -- 为了测试索引的性能, immutable让这个函数产生常数, 强制使用vector索引.    
    
explain select id,vec <=> gen_rand_vector(128) from tbl_vector order by vec <=> gen_rand_vector(128) limit 1;    
    
 Limit  (cost=9.34..9.43 rows=1 width=12)  
   ->  Index Scan using tbl_vector_vec_idx on tbl_vector  (cost=9.34..9116.64 rows=100000 width=12)  
         Order By: (vec <=> '[31,886,785,244,168,193,756,265,860,54,262,663,246,558,275,130,112,105,194,461,845,682,766,760,790,765,368,353,753,722,173,172,529,626,246,983,636,755,819,931,860,590,157,535,204,668,995,762,236,106,916,698,288,431,172,668,132,770,761,533,559,376,549,181,200,373,321,433,59,120,873,590,927,228,112,375,482,387,129,54,516,413,936,80,137,327,991,535,711,624,439,562,815,889,667,398,138,469,989,740,400,409,88,331,294,380,981,481,875,874,218,970,710,782,680,449,551,246,656,233,973,824,673,635,755,827,565,931]'::vector)  
(3 rows)   
    
    
db1=> select id,vec <=> gen_rand_vector(128) from tbl_vector order by vec <=> gen_rand_vector(128) limit 1;    
   id   |      ?column?         
--------+---------------------  
 667676 | 0.16630337200308487  
(1 row)  
  
Time: 2.685 ms  
```    
  
##### 60.19 大数据量并行查询加速报表分析和复杂SQL  
建表  
```  
create unlogged table t_big (  
  id int,  
  info text,  
  c1 int,  
  c2 int,  
  ts timestamp  
);  
```  
  
写入1亿数据  
```  
insert into t_big select generate_series(1,100000000), md5(random()::text), random()*100, random()*10, clock_timestamp();  
  
db1=> \dt+ t_big  
                                  List of relations  
 Schema | Name  | Type  | Owner | Persistence | Access method |  Size   | Description   
--------+-------+-------+-------+-------------+---------------+---------+-------------  
 s1     | t_big | table | r1    | unlogged    | heap          | 8056 MB |   
(1 row)  
```  
  
强制并行度执行统计SQL  
```  
db1=> alter table t_big set (parallel_workers =4);  
ALTER TABLE  
  
db1=> set max_parallel_workers_per_gather =4;  
SET  
db1=> set max_parallel_workers=4;  
SET  
db1=> set min_parallel_index_scan_size =0;  
SET  
db1=> set min_parallel_table_scan_size =0;  
SET      
db1=> set parallel_leader_participation =off;  
SET  
db1=> set parallel_setup_cost =0;  
SET  
db1=> set parallel_tuple_cost =0;  
SET  
db1=> explain select c1,count(*) from t_big group by c1 ;  
                                            QUERY PLAN                                               
---------------------------------------------------------------------------------------------------  
 Finalize GroupAggregate  (cost=1405932.49..1405941.47 rows=101 width=12)  
   Group Key: c1  
   ->  Gather Merge  (cost=1405932.49..1405938.44 rows=404 width=12)  
         Workers Planned: 4  
         ->  Sort  (cost=1405932.43..1405932.68 rows=101 width=12)  
               Sort Key: c1  
               ->  Partial HashAggregate  (cost=1405928.06..1405929.07 rows=101 width=12)  
                     Group Key: c1  
                     ->  Parallel Seq Scan on t_big  (cost=0.00..1280928.04 rows=25000004 width=4)  
 JIT:  
   Functions: 6  
   Options: Inlining true, Optimization true, Expressions true, Deforming true  
(12 rows)  
  
  
db1=> explain analyze select c1,count(*) from t_big group by c1 ;  
                                                                      QUERY PLAN                                                                         
-------------------------------------------------------------------------------------------------------------------------------------------------------  
 Finalize GroupAggregate  (cost=1405932.49..1405941.47 rows=101 width=12) (actual time=8170.860..8171.041 rows=101 loops=1)  
   Group Key: c1  
   ->  Gather Merge  (cost=1405932.49..1405938.44 rows=404 width=12) (actual time=8098.056..8098.197 rows=404 loops=1)  
         Workers Planned: 4  
         Workers Launched: 4  
         ->  Sort  (cost=1405932.43..1405932.68 rows=101 width=12) (actual time=8057.777..8057.788 rows=101 loops=4)  
               Sort Key: c1  
               Worker 0:  Sort Method: quicksort  Memory: 29kB  
               Worker 1:  Sort Method: quicksort  Memory: 29kB  
               Worker 2:  Sort Method: quicksort  Memory: 29kB  
               Worker 3:  Sort Method: quicksort  Memory: 29kB  
               ->  Partial HashAggregate  (cost=1405928.06..1405929.07 rows=101 width=12) (actual time=8057.667..8057.678 rows=101 loops=4)  
                     Group Key: c1  
                     Worker 0:  Batches: 1  Memory Usage: 40kB  
                     Worker 1:  Batches: 1  Memory Usage: 40kB  
                     Worker 2:  Batches: 1  Memory Usage: 40kB  
                     Worker 3:  Batches: 1  Memory Usage: 40kB  
                     ->  Parallel Seq Scan on t_big  (cost=0.00..1280928.04 rows=25000004 width=4) (actual time=0.021..3627.108 rows=25000000 loops=4)  
 Planning Time: 0.073 ms  
 JIT:  
   Functions: 33  
   Options: Inlining true, Optimization true, Expressions true, Deforming true  
   Timing: Generation 4.747 ms, Inlining 236.900 ms, Optimization 144.771 ms, Emission 82.932 ms, Total 469.349 ms  
 Execution Time: 8172.490 ms  
(24 rows)  
```
  
##### 60.20 大对象和bytea的使用  
      
- [《使用 PostgreSQL 大对象和pgcrypto加解密文件》](../202212/20221215_01.md)        
- [《PostgreSQL 9.0 开始大对象的改进 - 增加 pg_largeobject_metadata 表用于查询大对象oid和对应的owner与权限》](../202105/20210507_03.md)        
- [《PostgreSQL 大对象使用》](../202012/20201205_01.md)        
- [《PostgreSQL psql的元素周期表 - 包括大对象操作》](../201906/20190607_04.md)        
- [《[转] 关于入侵PostgreSQL的那些事儿（文件读取写入、命令执行的办法）  -大对象》](../201802/20180201_03.md)        
- [《大对象 - 数据库common安全自动渗透测试与防范 - sqlmap》](../201702/20170213_01.md)        
- [《大对象攻击 - Hacking PostgreSQL》](../201610/20161018_02.md)        
- [《在java中正确使用PostgreSQL大对象和字节流(bytea)类型的姿势》](../201606/20160614_01.md)        
- [《PostgreSQL varlena field upto 1GB and large object upto 4TB(8KB block_size)(>=9.3) 2GB(<=9.2)》](../201307/20130726_01.md)        
- [《PostgreSQL 大对象或bytea存取pdf,jpg等文件 - PostgreSQL export regular file like pdf, word, text, doc stored in bytea type》](../201306/20130626_01.md)        
- [《大对象 - PostgreSQL 9.3 Add API for 64-bit large object access》](../201305/20130510_02.md)        
- [《大对象 - Use PostgreSQL server program import binary data into database bytea type》](../201303/20130306_01.md)        
- [《PostgreSQL large row|column performance tuning case - 包括大对象》](../201301/20130109_01.md)        
      
实验准备  
```  
-- 进入容器  
docker exec -ti pg bash  
  
-- 切换用户  
su - postgres  
  
-- 创建测试文件  
postgres@3501de034e72:~$ pwd  
/var/lib/postgresql  
postgres@3501de034e72:~$ echo "hello, i am digoal" >./test.txt  
```  
  
     
1、将数据库服务器上的文件导入数据库大对象      
```  
postgres=# SELECT lo_import('/var/lib/postgresql/test.txt');  
 lo_import   
-----------  
     41017  
(1 row)  
  
create table t (id int, info text, lo oid);  
insert into t values (1,'test.txt', 41017);  
```  
  
2、将数据库服务器上的文件导入数据库bytea      
```  
postgres=# select pg_read_binary_file('/var/lib/postgresql/test.txt');  
           pg_read_binary_file              
------------------------------------------  
 \x68656c6c6f2c206920616d206469676f616c0a  
(1 row)  
  
  
create table t1 (id int, info text, b bytea);  
insert into t1 values (1, 'test.txt', pg_read_binary_file('/var/lib/postgresql/test.txt'));  
```  
      
3、将客户端的文件导入数据库大对象      
```  
psql  
  
\?  
  以下采用客户端接口封装, 不需要超级用户. 但数据库服务端的接口需要超级用户权限.  就像copy和psql \copy一样.  
Large Objects  
  \lo_export LOBOID FILE  
  \lo_import FILE [COMMENT]  
  \lo_list  
  \lo_unlink LOBOID      large object operations  
  
  
postgres=# \lo_import /var/lib/postgresql/test.txt   
lo_import 41028  
  
postgres=# \lo_list  
         Large objects  
  ID   |  Owner   | Description   
-------+----------+-------------  
 41028 | postgres |   
(1 row)  
```  
  
4、将客户端的文件导入数据库bytea      
```  
postgres=# \df lo_*  
                                List of functions  
   Schema   |     Name      | Result data type |    Argument data types    | Type   
------------+---------------+------------------+---------------------------+------  
 pg_catalog | lo_close      | integer          | integer                   | func  
 pg_catalog | lo_creat      | oid              | integer                   | func  
 pg_catalog | lo_create     | oid              | oid                       | func  
 pg_catalog | lo_export     | integer          | oid, text                 | func  
 pg_catalog | lo_from_bytea | oid              | oid, bytea                | func  
 pg_catalog | lo_get        | bytea            | oid                       | func  
 pg_catalog | lo_get        | bytea            | oid, bigint, integer      | func  
 pg_catalog | lo_import     | oid              | text                      | func  
 pg_catalog | lo_import     | oid              | text, oid                 | func  
 pg_catalog | lo_lseek      | integer          | integer, integer, integer | func  
 pg_catalog | lo_lseek64    | bigint           | integer, bigint, integer  | func  
 pg_catalog | lo_open       | integer          | oid, integer              | func  
 pg_catalog | lo_put        | void             | oid, bigint, bytea        | func  
 pg_catalog | lo_tell       | integer          | integer                   | func  
 pg_catalog | lo_tell64     | bigint           | integer                   | func  
 pg_catalog | lo_truncate   | integer          | integer, integer          | func  
 pg_catalog | lo_truncate64 | integer          | integer, bigint           | func  
 pg_catalog | lo_unlink     | integer          | oid                       | func  
(18 rows)  
  
-- 先入大对象, 再转换为bytea  
  
postgres=# select lo_get(41028);  
                  lo_get                    
------------------------------------------  
 \x68656c6c6f2c206920616d206469676f616c0a  
(1 row)  
```  
  
5、将数据库大对象导出到数据库服务器上      
```  
postgres=# select lo_export(41028, '/var/lib/postgresql/test.txt.bak');  
 lo_export   
-----------  
         1  
(1 row)  
  
postgres=# \q  
postgres@3501de034e72:~$ cat /var/lib/postgresql/test.txt.bak  
hello, i am digoal  
```  
  
6、将数据库bytea导出到数据库服务器上      
```  
先把bytea转换为大对象, 再使用大对象接口导出  
  
postgres=# select lo_from_bytea(0, b) from t1 where id=1;  
 lo_from_bytea   
---------------  
         41029  
(1 row)  
  
postgres=# select lo_export(41029, '/var/lib/postgresql/test.txt.bak1');  
 lo_export   
-----------  
         1  
(1 row)  
  
  
  
postgres=# \q  
postgres@3501de034e72:~$ cat /var/lib/postgresql/test.txt.bak1  
hello, i am digoal  
```  
  
  
7、将数据库大对象导出到客户端     
```  
postgres=# \lo_export 41028 /var/lib/postgresql/test.txt.client  
lo_export  
  
postgres=# \q  
postgres@3501de034e72:~$ cat /var/lib/postgresql/test.txt.client  
hello, i am digoal  
```  
      
  
8、将数据库bytea导出到客户端      
```  
先把bytea转换为大对象, 再使用psql大对象接口导出  
  
  
postgres=# \lo_export 41029 /var/lib/postgresql/test.txt.client1  
lo_export  
  
postgres=# \q  
postgres@3501de034e72:~$ cat /var/lib/postgresql/test.txt.client1  
hello, i am digoal  
```  
      
9、读取大对象片段内容      
```  
lo_lseek  
lo_lseek64  
lo_get  
```  
  
10、删除大对象      
```  
postgres=# select lo_unlink(41017);  
 lo_unlink   
-----------  
         1  
(1 row)  
  
postgres=# select lo_unlink(41017);  
ERROR:  large object 41017 does not exist  
```  
      
11、检查未被引用的大对象      
```  
postgres@3501de034e72:~$ vacuumlo -nv postgres  
Connected to database "postgres"  
Test run: no large objects will be removed!  
Checking lo in public.t  
Would remove 2 large objects from database "postgres".  
```  
  
12、安全的清理未被引用的大对象      
```  
postgres@3501de034e72:~$ vacuumlo postgres  
postgres@3501de034e72:~$ psql  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
postgres=# \lo_list  
      Large objects  
 ID | Owner | Description   
----+-------+-------------  
(0 rows)  
```  
  
  
#### 61 将“远程数据库数据表/query结果”导出到“客户端本地文件”  
  
使用psql客户端 将“远程数据库数据表/query结果”导出到“客户端本地文件”  
```  
postgres@6f60081d4ace:~$ pwd  
/var/lib/postgresql  
postgres@6f60081d4ace:~$ psql  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
  
db1=> create table t_1 (id int, info text, ts timestamp);  
CREATE TABLE  
  
db1=> insert into t_1 select generate_series(1,10), md5(random()::text), now();  
INSERT 0 10  
  
db1=> \copy t_1 to '/var/lib/postgresql/t_1.csv' with (format csv);  
COPY 10  
  
db1=> \q  
postgres@6f60081d4ace:~$ cat t_1.csv   
1,9b924a12d5d6de3b28d1e0b33e13ec57,2023-11-11 05:16:03.577032  
2,4b6bc380cfd558dfa9f5928561a13272,2023-11-11 05:16:03.577032  
3,ca7c478b9e577d5b1f46e8294bf7dd92,2023-11-11 05:16:03.577032  
4,ca049d84a42858ef46bc12545c2202a6,2023-11-11 05:16:03.577032  
5,58730344f8c2c46b4410a83047050978,2023-11-11 05:16:03.577032  
6,5eeb084c6c88adcc878fba2fb6b16185,2023-11-11 05:16:03.577032  
7,222ac6a77aefab5c80ad2851b53cfedc,2023-11-11 05:16:03.577032  
8,6357795ae8684fe574ff2e015cec5999,2023-11-11 05:16:03.577032  
9,67ef87e1c126c864987e547d57f23c0f,2023-11-11 05:16:03.577032  
10,61821e0f94e7a95e6cd9d88bd0d881af,2023-11-11 05:16:03.577032  
```  
  
使用管道 将“远程数据库数据表/query结果”导出到“客户端本地文件”  
```  
postgres@6f60081d4ace:~$ psql -U r1 -d db1  -c "copy t_1 to stdout with (format csv);" > ./nt1.csv  
postgres@6f60081d4ace:~$ cat nt1.csv   
1,9b924a12d5d6de3b28d1e0b33e13ec57,2023-11-11 05:16:03.577032  
2,4b6bc380cfd558dfa9f5928561a13272,2023-11-11 05:16:03.577032  
3,ca7c478b9e577d5b1f46e8294bf7dd92,2023-11-11 05:16:03.577032  
4,ca049d84a42858ef46bc12545c2202a6,2023-11-11 05:16:03.577032  
5,58730344f8c2c46b4410a83047050978,2023-11-11 05:16:03.577032  
6,5eeb084c6c88adcc878fba2fb6b16185,2023-11-11 05:16:03.577032  
7,222ac6a77aefab5c80ad2851b53cfedc,2023-11-11 05:16:03.577032  
8,6357795ae8684fe574ff2e015cec5999,2023-11-11 05:16:03.577032  
9,67ef87e1c126c864987e547d57f23c0f,2023-11-11 05:16:03.577032  
10,61821e0f94e7a95e6cd9d88bd0d881af,2023-11-11 05:16:03.577032  
```  
  
#### 62 将“客户端本地文件”导入“远程数据库”  
  
使用psql客户端 将“客户端本地文件”导入“远程数据库”  
```  
postgres@6f60081d4ace:~$ psql -U r1 -d db1  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
db1=> select count(*) from t_1;  
 count   
-------  
    10  
(1 row)  
  
db1=> \copy t_1 from '/var/lib/postgresql/t_1.csv' with (format csv)  
COPY 10  
db1=> select count(*) from t_1;  
 count   
-------  
    20  
(1 row)  
```  
  
使用管道 将“客户端本地文件”导入“远程数据库”  
```  
postgres@6f60081d4ace:~$ cat nt1.csv|psql -U r1 -d db1 -c "copy t_1 from stdin with (format csv)" -f -  
COPY 10  
```  
  
#### 63 将“远程数据库数据表/query结果”导出到“远程数据库服务器上某文件”  
  
使用超级用户调用COPY命令 将“远程数据库数据表/query结果”导出到“远程数据库服务器上某文件”  
```  
postgres@6f60081d4ace:~$ psql -U postgres -d db1  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
db1=# copy s1.t_1 to '/tmp/t_1.csv' with (format csv);  
COPY 30  
  
db1=# copy (select * from s1.t_1 limit 10) to '/tmp/t_1.csv' with (format csv);  
COPY 10  
```  
  
#### 64 将“远程数据库服务器上某文件”导入“数据库”  
  
使用超级用户调用COPY命令 将“远程数据库服务器上某文件”导入“数据库”  
```  
postgres@6f60081d4ace:~$ psql -U postgres -d db1  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
db1=# copy s1.t_1 from '/tmp/t_1.csv' with (format csv);  
COPY 10  
```  
  
#### 65 通过系统表查看对象类型  
  
https://www.postgresql.org/docs/14/catalog-pg-class.html  
  
```  
r = ordinary table,   
i = index,   
S = sequence,   
t = TOAST table,   
v = view,   
m = materialized view,   
c = composite type,   
f = foreign table,   
p = partitioned table,   
I = partitioned index  
```  
  
  
```  
db1=> select distinct on (relkind) relkind,relname from pg_class;  
 relkind |         relname           
---------+-------------------------  
 f       | pglog  -- 函数  
 i       | pg_extension_name_index  -- 索引  
 r       | pg_ts_dict -- 表  
 t       | pg_toast_2618 -- toast切片表  
 v       | pg_matviews -- 视图  
(5 rows)  
```  
  
#### 66 查看数据类型  
数据类型:   
  
https://www.postgresql.org/docs/14/datatype.html  
  
类型转换  
```  
db1=# \c db1 r1  
You are now connected to database "db1" as user "r1".  
db1=> select cast('abc' as int);  
ERROR:  invalid input syntax for type integer: "abc"  
LINE 1: select cast('abc' as int);  
                    ^  
db1=> select cast('123' as int);  
 int4   
------  
  123  
(1 row)  
  
db1=> select cast('123.345' as numeric);  
 numeric   
---------  
 123.345  
(1 row)  
  
db1=> select cast('123.345' as text);  
  text     
---------  
 123.345  
(1 row)  
```  
  
```  
db1=> select '123.345'::int;  
ERROR:  invalid input syntax for type integer: "123.345"  
LINE 1: select '123.345'::int;  
               ^  
db1=> select '123.345'::numeric;  
 numeric   
---------  
 123.345  
(1 row)  
```  
  
https://www.postgresql.org/docs/14/typeconv.html  
  
支持的索引类型: [《PostgreSQL 9种索引的原理和应用场景》](../201706/20170627_01.md)    
```  
btree  
hash  
gin  
gist  
sp-gist  
brin  
bloom  
  
扩展索引  
hnsw  
...  
```  
  
https://www.postgresql.org/docs/14/indexes.html  
  
隐含列  
- ctid, 物理行号  
- xmin, 被插入时的事务号  
- xmax, 被删除时的事务号  
- cmin, 事务中第几条命令产生的记录   
- cmax, 事务中第几条命令产生的记录   
  
```  
db1=> create table t_hid (id int);  
CREATE TABLE  
db1=> insert into t_hid values (1);  
INSERT 0 1  
db1=> begin;  
BEGIN  
db1=*> insert into t_hid values (2);  
INSERT 0 1  
db1=*> insert into t_hid values (3);  
INSERT 0 1  
db1=*> insert into t_hid values (4);  
INSERT 0 1  
db1=*> end;  
COMMIT  
db1=> insert into t_hid values (5),(6),(7);  
INSERT 0 3  
db1=> select ctid,xmin,xmax,cmin,cmax,* from t_hid;  
 ctid  | xmin | xmax | cmin | cmax | id   
-------+------+------+------+------+----  
 (0,1) |  975 |    0 |    0 |    0 |  1  
 (0,2) |  976 |    0 |    0 |    0 |  2  
 (0,3) |  976 |    0 |    1 |    1 |  3  
 (0,4) |  976 |    0 |    2 |    2 |  4  
 (0,5) |  977 |    0 |    0 |    0 |  5  
 (0,6) |  977 |    0 |    0 |    0 |  6  
 (0,7) |  977 |    0 |    0 |    0 |  7  
(7 rows)  
```  
  
  
#### 67 查看数据类型支持的函数和操作符   
类型支持的函数和操作符:  
  
https://www.postgresql.org/docs/14/functions.html  
  
触发器  
- [《USE hstore store table's trace record》](../201206/20120625_01.md)    
  
创建需要被跟踪的测试表    
    
```    
drop table test;  
CREATE TABLE test (id int primary key, info text, crt_time timestamp(0));    
```    
    
创建hstore extension;    
    
```    
CREATE EXTENSION hstore;    
```    
    
创建通用的存储跟踪记录的记录表    
    
```    
CREATE TABLE table_change_rec (    
  id serial8 primary key,    
  relid oid,    
  table_schema text,    
  table_name text,    
  when_tg text,    
  level text,    
  op text,    
  old_rec hstore,    
  new_rec hstore,    
  crt_time timestamp without time zone DEFAULT now(),    
  username text,    
  client_addr inet,    
  client_port int    
);    
```    
    
创建通用的触发器函数    
    
```    
CREATE OR REPLACE FUNCTION dml_trace()    
RETURNS trigger    
LANGUAGE plpgsql    
AS $BODY$    
DECLARE    
v_new_rec hstore;    
v_old_rec hstore;    
v_username text := session_user;    
v_client_addr inet := inet_client_addr();    
v_client_port int := inet_client_port();    
BEGIN    
case TG_OP    
when 'DELETE' then     
  v_old_rec := hstore(OLD.*);    
  insert into table_change_rec (relid, table_schema, table_name, when_tg, level, op, old_rec, username, client_addr, client_port)    
    values (tg_relid, tg_table_schema, tg_table_name, tg_when, tg_level, tg_op, v_old_rec, v_username, v_client_addr, v_client_port);    
when 'INSERT' then     
  v_new_rec := hstore(NEW.*);    
  insert into table_change_rec (relid, table_schema, table_name, when_tg, level, op, new_rec, username, client_addr, client_port)    
    values (tg_relid, tg_table_schema, tg_table_name, tg_when, tg_level, tg_op, v_new_rec, v_username, v_client_addr, v_client_port);    
when 'UPDATE' then     
  v_old_rec := hstore(OLD.*);    
  v_new_rec := hstore(NEW.*);    
  insert into table_change_rec (relid, table_schema, table_name, when_tg, level, op, old_rec, new_rec, username, client_addr, client_port)    
    values (tg_relid, tg_table_schema, tg_table_name, tg_when, tg_level, tg_op, v_old_rec, v_new_rec, v_username, v_client_addr, v_client_port);    
else    
  return null;    
end case;    
  RETURN null;    
END;    
$BODY$ strict;    
```    
    
在测试表上分别创建插入, 更新, 删除的三个触发器.    
    
```    
CREATE TRIGGER tg AFTER DELETE or INSERT or UPDATE ON test FOR EACH ROW EXECUTE PROCEDURE dml_trace();    
```    
    
测试插入, 删除, 更新操作是否被跟踪.    
    
(已更新dml_trace, 以下例子未包含client_addr和client_port)    
    
```    
db1=> insert into test values (1, 'digoal', now());    
INSERT 0 1  
db1=> select * from test;    
 id |  info  |      crt_time         
----+--------+---------------------  
  1 | digoal | 2023-11-11 05:33:43  
(1 row)  
  
db1=> select * from table_change_rec;    
db1=> \x  
Expanded display is on.  
db1=> select * from table_change_rec;    
-[ RECORD 1 ]+---------------------------------------------------------------  
id           | 1  
relid        | 106648  
table_schema | s1  
table_name   | test  
when_tg      | AFTER  
level        | ROW  
op           | INSERT  
old_rec      |   
new_rec      | "id"=>"1", "info"=>"digoal", "crt_time"=>"2023-11-11 05:33:43"  
crt_time     | 2023-11-11 05:33:43.33753  
username     | r1  
client_addr  |   
client_port  |   
    
db1=> update test set info='DIGOAL' where id=1;    
UPDATE 1  
db1=> select * from test;    
-[ RECORD 1 ]-----------------  
id       | 1  
info     | DIGOAL  
crt_time | 2023-11-11 05:33:43  
  
db1=> select * from table_change_rec;    
-[ RECORD 1 ]+---------------------------------------------------------------  
id           | 1  
relid        | 106648  
table_schema | s1  
table_name   | test  
when_tg      | AFTER  
level        | ROW  
op           | INSERT  
old_rec      |   
new_rec      | "id"=>"1", "info"=>"digoal", "crt_time"=>"2023-11-11 05:33:43"  
crt_time     | 2023-11-11 05:33:43.33753  
username     | r1  
client_addr  |   
client_port  |   
-[ RECORD 2 ]+---------------------------------------------------------------  
id           | 2  
relid        | 106648  
table_schema | s1  
table_name   | test  
when_tg      | AFTER  
level        | ROW  
op           | UPDATE  
old_rec      | "id"=>"1", "info"=>"digoal", "crt_time"=>"2023-11-11 05:33:43"  
new_rec      | "id"=>"1", "info"=>"DIGOAL", "crt_time"=>"2023-11-11 05:33:43"  
crt_time     | 2023-11-11 05:34:09.639511  
username     | r1  
client_addr  |   
client_port  |   
  
    
db1=> delete from test where id=1;    
DELETE 1  
db1=> select * from test;    
(0 rows)  
  
db1=> select * from table_change_rec;    
-[ RECORD 1 ]+---------------------------------------------------------------  
id           | 1  
relid        | 106648  
table_schema | s1  
table_name   | test  
when_tg      | AFTER  
level        | ROW  
op           | INSERT  
old_rec      |   
new_rec      | "id"=>"1", "info"=>"digoal", "crt_time"=>"2023-11-11 05:33:43"  
crt_time     | 2023-11-11 05:33:43.33753  
username     | r1  
client_addr  |   
client_port  |   
-[ RECORD 2 ]+---------------------------------------------------------------  
id           | 2  
relid        | 106648  
table_schema | s1  
table_name   | test  
when_tg      | AFTER  
level        | ROW  
op           | UPDATE  
old_rec      | "id"=>"1", "info"=>"digoal", "crt_time"=>"2023-11-11 05:33:43"  
new_rec      | "id"=>"1", "info"=>"DIGOAL", "crt_time"=>"2023-11-11 05:33:43"  
crt_time     | 2023-11-11 05:34:09.639511  
username     | r1  
client_addr  |   
client_port  |   
-[ RECORD 3 ]+---------------------------------------------------------------  
id           | 3  
relid        | 106648  
table_schema | s1  
table_name   | test  
when_tg      | AFTER  
level        | ROW  
op           | DELETE  
old_rec      | "id"=>"1", "info"=>"DIGOAL", "crt_time"=>"2023-11-11 05:33:43"  
new_rec      |   
crt_time     | 2023-11-11 05:34:28.112658  
username     | r1  
client_addr  |   
client_port  |   
```    
    
使用each函数分解显示hstore存储的信息.    
    
```    
db1=> \x  
Expanded display is off.  
db1=> select id,(each(old_rec)).* from table_change_rec;    
 id |   key    |        value          
----+----------+---------------------  
  2 | id       | 1  
  2 | info     | digoal  
  2 | crt_time | 2023-11-11 05:33:43  
  3 | id       | 1  
  3 | info     | DIGOAL  
  3 | crt_time | 2023-11-11 05:33:43  
(6 rows)  
  
db1=> select id,(each(new_rec)).* from table_change_rec;    
 id |   key    |        value          
----+----------+---------------------  
  1 | id       | 1  
  1 | info     | digoal  
  1 | crt_time | 2023-11-11 05:33:43  
  2 | id       | 1  
  2 | info     | DIGOAL  
  2 | crt_time | 2023-11-11 05:33:43  
(6 rows)  
```    
  
事件触发器:  
- [《PostgreSQL Oracle 兼容性之 - 事件触发器实现类似Oracle的回收站功能》](../201504/20150429_01.md)    
- [《use event trigger function record user who alter table's SQL》](../201412/20141211_02.md)    
  
```  
db1=> create extension hstore;    
    
db1=> create or replace function ef_alter() returns event_trigger as $$    
declare    
  rec hstore;    
begin    
  select hstore(pg_stat_activity.*) into rec from pg_stat_activity where pid=pg_backend_pid();    
  insert into aud_alter (ctx) values (rec);    
end;    
$$ language plpgsql strict;    
CREATE FUNCTION    
    
\c db1 postgres  
  
db1=# create event trigger e_alter on ddl_command_end when tag in ('ALTER TABLE') execute procedure s1.ef_alter();    
CREATE EVENT TRIGGER    
    
db1=# \c db1 r1  
You are now connected to database "db1" as user "r1".  
  
db1=> create table aud_alter(id serial primary key, crt_time timestamp default now(), ctx hstore);    
CREATE TABLE  
  
db1=> drop table test;  
DROP TABLE  
  
db1=> create table test(id int);    
CREATE TABLE    
    
db1=> alter table test alter column id type int8;    
ALTER TABLE    
    
db1=> select * from aud_alter;    
-[ RECORD 1 ]---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
id       | 1  
crt_time | 2023-11-11 05:38:04.845588  
ctx      | "pid"=>"834", "datid"=>"16388", "query"=>"alter table test alter column id type int8;", "state"=>"active", "datname"=>"db1", "usename"=>"r1", "query_id"=>"-1466738775741965031", "usesysid"=>"16384", "leader_pid"=>NULL, "wait_event"=>NULL, "xact_start"=>"2023-11-11 05:38:04.845588+00", "backend_xid"=>"993", "client_addr"=>NULL, "client_port"=>"-1", "query_start"=>"2023-11-11 05:38:04.845588+00", "backend_type"=>"client backend", "backend_xmin"=>"993", "state_change"=>"2023-11-11 05:38:04.84559+00", "backend_start"=>"2023-11-11 05:37:50.215834+00", "client_hostname"=>NULL, "wait_event_type"=>NULL, "application_name"=>"psql"  
  
    
    
db1=> select each(ctx) from aud_alter where id=1;    
                         each                              
-------------------------------------------------------    
 (pid,48406)    
 (datid,12949)    
 (query,"alter table test alter column id type int8;")    
 (state,active)    
 (datname,postgres)    
 (usename,postgres)    
 (waiting,f)    
 (usesysid,10)    
 (xact_start,"2014-12-12 05:43:42.840327+08")    
 (client_addr,)    
 (client_port,-1)    
 (query_start,"2014-12-12 05:43:42.840327+08")    
 (state_change,"2014-12-12 05:43:42.840331+08")    
 (backend_start,"2014-12-12 05:38:37.084733+08")    
 (client_hostname,)    
 (application_name,psql)    
(16 rows)    
```    
  
视图:  
- [《PostgreSQL DBA最常用SQL》](../202005/20200509_02.md)    
```  
create view v_lock_chains as   
with recursive   
a as (select pid from pg_locks where not granted),  
tmp as (  
  select 1 as id, pid as blocked_pid, conflict_origin_own_lock_pid from (select pid, unnest(pg_blocking_pids(pid)) as conflict_origin_own_lock_pid from a) tt  
  union all  
  select id+1, conflict_origin_own_lock_pid as blocked_pid, unnest(pg_blocking_pids(conflict_origin_own_lock_pid)) as conflict_origin_own_lock_pid from tmp   
     -- where pg_blocking_pids(conflict_origin_own_lock_pid) <> '{}'::int[]   
)   
select tmp.id, pg_locks.pid, pg_locks.locktype, pg_locks.mode, pg_locks.granted, pg_stat_activity.query,   
  tmp.conflict_origin_own_lock_pid   
  from tmp, pg_locks, pg_stat_activity   
  where tmp.blocked_pid=pg_locks.pid   
      -- or tmp.conflict_origin_own_lock_pid=pg_locks.pid   
      and pg_locks.pid = pg_stat_activity.pid  
  order by id;   
```  
  
```  
db1=> select * from v_lock_chains;  
 id | pid | locktype | mode | granted | query | conflict_origin_own_lock_pid   
----+-----+----------+------+---------+-------+------------------------------  
(0 rows)  
  
db1=> select * from v_lock_chains;  
 id | pid |   locktype    |        mode         | granted |             query              | conflict_origin_own_lock_pid   
----+-----+---------------+---------------------+---------+--------------------------------+------------------------------  
  1 | 869 | relation      | RowExclusiveLock    | f       | insert into t_hint values (2); |                          860  
  1 | 869 | virtualxid    | ExclusiveLock       | t       | insert into t_hint values (2); |                          860  
  1 | 860 | relation      | AccessExclusiveLock | f       | truncate t_hint ;              |                          344  
  1 | 860 | transactionid | ExclusiveLock       | t       | truncate t_hint ;              |                          344  
  1 | 860 | virtualxid    | ExclusiveLock       | t       | truncate t_hint ;              |                          344  
  2 | 860 | relation      | AccessExclusiveLock | f       | truncate t_hint ;              |                          344  
  2 | 860 | transactionid | ExclusiveLock       | t       | truncate t_hint ;              |                          344  
  2 | 860 | virtualxid    | ExclusiveLock       | t       | truncate t_hint ;              |                          344  
(8 rows)  
```  
  
  
物化视图  
```  
create table t_mv (id int primary key, info text, ts timestamp, active boolean);  
insert into t_mv select generate_series(1,100000), md5(random()::Text), clock_timestamp(), true;  
insert into t_mv select generate_series(100001,200000), md5(random()::Text), clock_timestamp(), false;  
  
db1=> create materialized view mv_t_mv as select * from t_mv where active ;  
SELECT 100000  
```  
  
刷新物化视图  
```  
insert into t_mv select generate_series(200001,300000), md5(random()::Text), clock_timestamp(), true;  
update t_mv set active=false where id =2;  
update t_mv set active=true where id =100001;  
  
  
db1=> \h refresh  
Command:     REFRESH MATERIALIZED VIEW  
Description: replace the contents of a materialized view  
Syntax:  
REFRESH MATERIALIZED VIEW [ CONCURRENTLY ] name  
    [ WITH [ NO ] DATA ]  
  
URL: https://www.postgresql.org/docs/14/sql-refreshmaterializedview.html  
  
db1=> refresh materialized view CONCURRENTLY mv_t_mv with data;  
ERROR:  cannot refresh materialized view "s1.mv_t_mv" concurrently  
HINT:  Create a unique index with no WHERE clause on one or more columns of the materialized view.  
  
db1=> create unique index on mv_t_mv (id);  
CREATE INDEX  
db1=> refresh materialized view CONCURRENTLY mv_t_mv with data;  
REFRESH MATERIALIZED VIEW  
```  
  
#### 68 查看系统表  
  
https://www.postgresql.org/docs/14/catalogs.html  
  
```  
db1=> \dt pg_catalog.*  
                    List of relations  
   Schema   |          Name           | Type  |  Owner     
------------+-------------------------+-------+----------  
 pg_catalog | pg_aggregate            | table | postgres  
 pg_catalog | pg_am                   | table | postgres  
 pg_catalog | pg_amop                 | table | postgres  
 pg_catalog | pg_amproc               | table | postgres  
 pg_catalog | pg_attrdef              | table | postgres  
 pg_catalog | pg_attribute            | table | postgres  
 pg_catalog | pg_auth_members         | table | postgres  
 pg_catalog | pg_authid               | table | postgres  
 pg_catalog | pg_cast                 | table | postgres  
 pg_catalog | pg_class                | table | postgres  
 pg_catalog | pg_collation            | table | postgres  
 pg_catalog | pg_constraint           | table | postgres  
 pg_catalog | pg_conversion           | table | postgres  
 pg_catalog | pg_database             | table | postgres  
 pg_catalog | pg_db_role_setting      | table | postgres  
 pg_catalog | pg_default_acl          | table | postgres  
 pg_catalog | pg_depend               | table | postgres  
 pg_catalog | pg_description          | table | postgres  
 pg_catalog | pg_enum                 | table | postgres  
 pg_catalog | pg_event_trigger        | table | postgres  
 pg_catalog | pg_extension            | table | postgres  
 pg_catalog | pg_foreign_data_wrapper | table | postgres  
 pg_catalog | pg_foreign_server       | table | postgres  
 pg_catalog | pg_foreign_table        | table | postgres  
 pg_catalog | pg_index                | table | postgres  
 pg_catalog | pg_inherits             | table | postgres  
 pg_catalog | pg_init_privs           | table | postgres  
 pg_catalog | pg_language             | table | postgres  
 pg_catalog | pg_largeobject          | table | postgres  
 pg_catalog | pg_largeobject_metadata | table | postgres  
 pg_catalog | pg_namespace            | table | postgres  
 pg_catalog | pg_opclass              | table | postgres  
 pg_catalog | pg_operator             | table | postgres  
 pg_catalog | pg_opfamily             | table | postgres  
 pg_catalog | pg_partitioned_table    | table | postgres  
 pg_catalog | pg_policy               | table | postgres  
 pg_catalog | pg_proc                 | table | postgres  
 pg_catalog | pg_publication          | table | postgres  
 pg_catalog | pg_publication_rel      | table | postgres  
 pg_catalog | pg_range                | table | postgres  
 pg_catalog | pg_replication_origin   | table | postgres  
 pg_catalog | pg_rewrite              | table | postgres  
 pg_catalog | pg_seclabel             | table | postgres  
 pg_catalog | pg_sequence             | table | postgres  
 pg_catalog | pg_shdepend             | table | postgres  
 pg_catalog | pg_shdescription        | table | postgres  
 pg_catalog | pg_shseclabel           | table | postgres  
 pg_catalog | pg_statistic            | table | postgres  
 pg_catalog | pg_statistic_ext        | table | postgres  
 pg_catalog | pg_statistic_ext_data   | table | postgres  
 pg_catalog | pg_subscription         | table | postgres  
 pg_catalog | pg_subscription_rel     | table | postgres  
 pg_catalog | pg_tablespace           | table | postgres  
 pg_catalog | pg_transform            | table | postgres  
 pg_catalog | pg_trigger              | table | postgres  
 pg_catalog | pg_ts_config            | table | postgres  
 pg_catalog | pg_ts_config_map        | table | postgres  
 pg_catalog | pg_ts_dict              | table | postgres  
 pg_catalog | pg_ts_parser            | table | postgres  
 pg_catalog | pg_ts_template          | table | postgres  
 pg_catalog | pg_type                 | table | postgres  
 pg_catalog | pg_user_mapping         | table | postgres  
(62 rows)  
```  
  
#### 69 查看系统管理函数  
  
https://www.postgresql.org/docs/14/functions-info.html  
  
https://www.postgresql.org/docs/14/functions-admin.html  
  
```  
\df pg_catalog.*  
```  
  
#### 70 查看psql快捷命令  
```  
postgres@6f60081d4ace:~$ man psql  
```  
  
```  
postgres@6f60081d4ace:~$ psql  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
postgres=# \?  
  
  
General  
  \copyright             show PostgreSQL usage and distribution terms  
  \crosstabview [COLUMNS] execute query and display results in crosstab  
  \errverbose            show most recent error message at maximum verbosity  
  \g [(OPTIONS)] [FILE]  execute query (and send results to file or |pipe);  
                         \g with no arguments is equivalent to a semicolon  
  \gdesc                 describe result of query, without executing it  
  \gexec                 execute query, then execute each value in its result  
  \gset [PREFIX]         execute query and store results in psql variables  
  \gx [(OPTIONS)] [FILE] as \g, but forces expanded output mode  
  \q                     quit psql  
  \watch [SEC]           execute query every SEC seconds  
  
Help  
  \? [commands]          show help on backslash commands  
  \? options             show help on psql command-line options  
  \? variables           show help on special variables  
  \h [NAME]              help on syntax of SQL commands, * for all commands  
  
Query Buffer  
  \e [FILE] [LINE]       edit the query buffer (or file) with external editor  
  \ef [FUNCNAME [LINE]]  edit function definition with external editor  
  \ev [VIEWNAME [LINE]]  edit view definition with external editor  
  \p                     show the contents of the query buffer  
  \r                     reset (clear) the query buffer  
  \s [FILE]              display history or save it to file  
  \w FILE                write query buffer to file  
  
Input/Output  
  \copy ...              perform SQL COPY with data stream to the client host  
  \echo [-n] [STRING]    write string to standard output (-n for no newline)  
  \i FILE                execute commands from file  
  \ir FILE               as \i, but relative to location of current script  
  \o [FILE]              send all query results to file or |pipe  
  \qecho [-n] [STRING]   write string to \o output stream (-n for no newline)  
  \warn [-n] [STRING]    write string to standard error (-n for no newline)  
  
Conditional  
  \if EXPR               begin conditional block  
  \elif EXPR             alternative within current conditional block  
  \else                  final alternative within current conditional block  
  \endif                 end conditional block  
  
Informational  
  (options: S = show system objects, + = additional detail)  
  \d[S+]                 list tables, views, and sequences  
  \d[S+]  NAME           describe table, view, sequence, or index  
  \da[S]  [PATTERN]      list aggregates  
  \dA[+]  [PATTERN]      list access methods  
  \dAc[+] [AMPTRN [TYPEPTRN]]  list operator classes  
  \dAf[+] [AMPTRN [TYPEPTRN]]  list operator families  
  \dAo[+] [AMPTRN [OPFPTRN]]   list operators of operator families  
  \dAp[+] [AMPTRN [OPFPTRN]]   list support functions of operator families  
  \db[+]  [PATTERN]      list tablespaces  
  \dc[S+] [PATTERN]      list conversions  
  \dC[+]  [PATTERN]      list casts  
  \dd[S]  [PATTERN]      show object descriptions not displayed elsewhere  
  \dD[S+] [PATTERN]      list domains  
  \ddp    [PATTERN]      list default privileges  
  \dE[S+] [PATTERN]      list foreign tables  
  \des[+] [PATTERN]      list foreign servers  
  \det[+] [PATTERN]      list foreign tables  
  \deu[+] [PATTERN]      list user mappings  
  \dew[+] [PATTERN]      list foreign-data wrappers  
...  
  
  
Formatting  
  \a                     toggle between unaligned and aligned output mode  
  \C [STRING]            set table title, or unset if none  
  \f [STRING]            show or set field separator for unaligned query output  
  \H                     toggle HTML output mode (currently off)  
  \pset [NAME [VALUE]]   set table output option  
                         (border|columns|csv_fieldsep|expanded|fieldsep|  
                         fieldsep_zero|footer|format|linestyle|null|  
                         numericlocale|pager|pager_min_lines|recordsep|  
                         recordsep_zero|tableattr|title|tuples_only|  
                         unicode_border_linestyle|unicode_column_linestyle|  
                         unicode_header_linestyle)  
  \t [on|off]            show only rows (currently off)  
  \T [STRING]            set HTML <table> tag attributes, or unset if none  
  \x [on|off|auto]       toggle expanded output (currently off)  
  
Connection  
  \c[onnect] {[DBNAME|- USER|- HOST|- PORT|-] | conninfo}  
                         connect to new database (currently "postgres")  
  \conninfo              display information about current connection  
  \encoding [ENCODING]   show or set client encoding  
  \password [USERNAME]   securely change the password for a user  
  
Operating System  
  \cd [DIR]              change the current working directory  
  \setenv NAME [VALUE]   set or unset environment variable  
  \timing [on|off]       toggle timing of commands (currently off)  
  \! [COMMAND]           execute command in shell or start interactive shell  
  
Variables  
  \prompt [TEXT] NAME    prompt user to set internal variable  
  \set [NAME [VALUE]]    set internal variable, or list all if no parameters  
  \unset NAME            unset (delete) internal variable  
  
Large Objects  
  \lo_export LOBOID FILE  
  \lo_import FILE [COMMENT]  
  \lo_list  
  \lo_unlink LOBOID      large object operations  
```  
  
```  
postgres=# \h create role  
Command:     CREATE ROLE  
Description: define a new database role  
Syntax:  
CREATE ROLE name [ [ WITH ] option [ ... ] ]  
  
where option can be:  
  
      SUPERUSER | NOSUPERUSER  
    | CREATEDB | NOCREATEDB  
    | CREATEROLE | NOCREATEROLE  
    | INHERIT | NOINHERIT  
    | LOGIN | NOLOGIN  
    | REPLICATION | NOREPLICATION  
    | BYPASSRLS | NOBYPASSRLS  
    | CONNECTION LIMIT connlimit  
    | [ ENCRYPTED ] PASSWORD 'password' | PASSWORD NULL  
    | VALID UNTIL 'timestamp'  
    | IN ROLE role_name [, ...]  
    | IN GROUP role_name [, ...]  
    | ROLE role_name [, ...]  
    | ADMIN role_name [, ...]  
    | USER role_name [, ...]  
    | SYSID uid  
  
URL: https://www.postgresql.org/docs/14/sql-createrole.html  
```  
  
#### 71 psql快捷命令通配符  
  
```  
postgres=# \c db1 r1  
You are now connected to database "db1" as user "r1".  
db1=> \dt s1.*  
             List of relations  
 Schema |       Name       | Type  | Owner   
--------+------------------+-------+-------  
 s1     | aud_alter        | table | r1  
 s1     | new1             | table | r1  
 s1     | new2             | table | r1  
 s1     | new3             | table | r1  
 s1     | new4             | table | r1  
 s1     | nt               | table | r1  
 s1     | nt1              | table | r1  
 s1     | t                | table | r1  
 s1     | t2               | table | r1  
 s1     | t3               | table | r1  
 s1     | t4               | table | r1  
 s1     | t_1              | table | r1  
 s1     | t_big            | table | r1  
 s1     | t_cur            | table | r1  
 s1     | t_forupdate      | table | r1  
 s1     | t_hid            | table | r1  
 s1     | t_hint           | table | r1  
 s1     | t_lock           | table | r1  
 s1     | t_mv             | table | r1  
 s1     | t_off            | table | r1  
 s1     | t_off1           | table | r1  
 s1     | table_change_rec | table | r1  
 s1     | tbl              | table | r1  
 s1     | tbl_poi          | table | r1  
 s1     | tbl_tj           | table | r1  
 s1     | tbl_ts           | table | r1  
 s1     | tbl_vector       | table | r1  
 s1     | test             | table | r1  
 s1     | test1            | table | r1  
(29 rows)  
```  
  
#### 72 使用tab补齐SQL command  
```  
postgres@6f60081d4ace:~/14/pgdata$ psql  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
db1=> 按TAB键支持补齐  
ABORT                      COMMIT                     END                        LOCK                       REVOKE                     TRUNCATE  
ALTER                      COPY                       EXECUTE                    MOVE                       ROLLBACK                   UNLISTEN  
ANALYZE                    CREATE                     EXPLAIN                    NOTIFY                     SAVEPOINT                  UPDATE  
BEGIN                      DEALLOCATE                 FETCH                      PREPARE                    SECURITY LABEL             VACUUM  
CALL                       DECLARE                    GRANT                      REASSIGN                   SELECT                     VALUES  
CHECKPOINT                 DELETE FROM                IMPORT FOREIGN SCHEMA      REFRESH MATERIALIZED VIEW  SET                        WITH  
CLOSE                      DISCARD                    INSERT INTO                REINDEX                    SHOW                         
CLUSTER                    DO                         LISTEN                     RELEASE                    START                        
COMMENT                    DROP                       LOAD                       RESET                      TABLE          
```  
  
```  
postgres@6f60081d4ace:~/14/pgdata$ psql  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
db1=> create 按TAB键支持补齐  
ACCESS METHOD         DOMAIN                GROUP                 POLICY                SEQUENCE              TEMP                  UNIQUE  
AGGREGATE             EVENT TRIGGER         INDEX                 PROCEDURE             SERVER                TEMPORARY             UNLOGGED  
CAST                  EXTENSION             LANGUAGE              PUBLICATION           STATISTICS            TEXT SEARCH           USER  
COLLATION             FOREIGN DATA WRAPPER  MATERIALIZED VIEW     ROLE                  SUBSCRIPTION          TRANSFORM             USER MAPPING FOR  
CONVERSION            FOREIGN TABLE         OPERATOR              RULE                  TABLE                 TRIGGER               VIEW  
DATABASE              FUNCTION              OR REPLACE            SCHEMA                TABLESPACE            TYPE                 
```  
  
#### 73 查看SQL command man 手册  
  
```  
man CREATE_TABLE  
  
man INSERT  
  
man UPDATE  
  
man ALTER_TABLE  
  
man NOTIFY  
  
...  
```  
  
#### 74 修改数据库配置  
```  
配置参数:  
alter system set guc_parameter_name=value;  
  
OR  
  
vi $PGHOME/postgresql.auto.conf  
  
OR   
  
vi $PGHOME/postgresql.conf  
  
根据参数类型, reload或重启生效:  
  
pg_ctl reload  
  
OR  
  
pg_ctl restart -m fast  
```  
  
[《PostgreSQL 参数优先级讲解》](../201901/20190130_03.md)    
  
优先级由低到高:  
- 命令行: `pg_ctl/postgres -o ...`  
- 参数文件: `postgresql.conf`  
- 热配置参数: `postgresql.auto.conf`  
- `db`: alter database set x=xxx  
- `role`: alter role set x=xxx   
- `table/function...` 级别: `alter function set ...`    
  
#### 75 修改数据库防火墙配置  
`vi $PGDATA/pg_hba.conf`  
  
postgres超级用户只允许通过本地+密码访问  
  
普通用户本地连接不需要输入密码访问  
  
开放所有公网通过密码访问  
  
```  
# TYPE  DATABASE        USER            ADDRESS                 METHOD  
  
# "local" is for Unix domain socket connections only  
local all postgres scram-sha-256  
local   all             all                                     trust  
  
# IPv4 local connections:  
host all postgres 127.0.0.1/32 scram-sha-256  
host    all             all             127.0.0.1/32            trust  
  
# IPv6 local connections:  
host    all             postgres             ::1/128                 scram-sha-256  
host    all             all             ::1/128                 trust  
  
# Allow replication connections from localhost, by a user with the  
# replication privilege.  
local   replication     all                                     trust  
host    replication     all             127.0.0.1/32            trust  
host    replication     all             ::1/128                 trust  
  
host all all 0.0.0.0/0 scram-sha-256  
```  
  
```  
pg_ctl reload  
```  
  
试试效果  
```  
postgres@6f60081d4ace:~/14/pgdata$ psql  
Password for user postgres:   
psql: error: connection to server on socket "/var/lib/postgresql/14/pgdata/.s.PGSQL.1921" failed: FATAL:  password authentication failed for user "postgres"  
  
  
postgres@6f60081d4ace:~/14/pgdata$ psql db1 r1  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
db1=>   
```  
  
#### 76 创建插件  
  
```  
vi $PGDATA/postgresql.auto.conf  
  
shared_preload_libraries = 'pg_stat_statements'  
  
  
pg_ctl restart -m fast  
```  
  
#### 77 修改插件配置  
https://www.postgresql.org/docs/14/pgstatstatements.html   
  
```  
vi $PGDATA/postgresql.auto.conf  
  
shared_preload_libraries = 'pg_stat_statements'  
compute_query_id = on  
pg_stat_statements.max = 10000  
pg_stat_statements.track = all  
  
  
  
pg_ctl restart -m fast  
```  
  
```  
postgres@6f60081d4ace:~/14/pgdata$ psql  
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
postgres=# show pg_stat_statements.  
pg_stat_statements.max             pg_stat_statements.save            pg_stat_statements.track           pg_stat_statements.track_planning  pg_stat_statements.track_utility  
  
postgres=# show pg_stat_statements.track;  
 pg_stat_statements.track   
--------------------------  
 all  
(1 row)  
```  
  
#### 78 查看数据库报错, 分析数据库日志文件  
  
https://www.postgresql.org/docs/14/file-fdw.html  
  
  
```  
db1=> create extension file_fdw ;  
CREATE EXTENSION  
  
  
db1=> CREATE SERVER pglog FOREIGN DATA WRAPPER file_fdw;  
CREATE SERVER  
  
  
db1=> select pg_current_logfile();  
          pg_current_logfile            
--------------------------------------  
 log/postgresql-2023-11-10_163218.csv  
(1 row)  
  
  
CREATE FOREIGN TABLE pglog (  
  log_time timestamp(3) with time zone,  
  user_name text,  
  database_name text,  
  process_id integer,  
  connection_from text,  
  session_id text,  
  session_line_num bigint,  
  command_tag text,  
  session_start_time timestamp with time zone,  
  virtual_transaction_id text,  
  transaction_id bigint,  
  error_severity text,  
  sql_state_code text,  
  message text,  
  detail text,  
  hint text,  
  internal_query text,  
  internal_query_pos integer,  
  context text,  
  query text,  
  query_pos integer,  
  location text,  
  application_name text,  
  backend_type text,  
  leader_pid integer,  
  query_id bigint  
) SERVER pglog  
OPTIONS ( filename 'log/postgresql-2023-11-10_163218.csv', format 'csv' );  
  
  
db1=> \x  
Expanded display is on.  
db1=> select * from pglog limit 1;  
-[ RECORD 1 ]----------+-------------------------------------------------------  
log_time               | 2023-11-10 16:32:18.799+00  
user_name              |   
database_name          |   
process_id             | 753  
connection_from        |   
session_id             | 654e5b12.2f1  
session_line_num       | 1  
command_tag            |   
session_start_time     | 2023-11-10 16:32:18+00  
virtual_transaction_id |   
transaction_id         | 0  
error_severity         | LOG  
sql_state_code         | 00000  
message                | ending log output to stderr  
detail                 |   
hint                   | Future log output will go to log destination "csvlog".  
internal_query         |   
internal_query_pos     |   
context                |   
query                  |   
query_pos              |   
location               |   
application_name       |   
backend_type           | postmaster  
leader_pid             |   
query_id               | 0  
  
db1=> select distinct on (error_severity) * from pglog;  
-[ RECORD 1 ]----------+-------------------------------------------  
log_time               | 2023-11-10 16:35:05.8+00  
user_name              | postgres  
database_name          | postgres  
process_id             | 763  
connection_from        | [local]  
session_id             | 654e5b14.2fb  
session_line_num       | 1  
command_tag            | idle  
session_start_time     | 2023-11-10 16:32:20+00  
virtual_transaction_id | 3/12  
transaction_id         | 0  
error_severity         | ERROR  
sql_state_code         | 42601  
message                | syntax error at or near ";"  
detail                 |   
hint                   |   
internal_query         |   
internal_query_pos     |   
context                |   
query                  | show auto_explain.;  
query_pos              | 19  
location               |   
application_name       | psql  
backend_type           | client backend  
leader_pid             |   
query_id               | 0  
-[ RECORD 2 ]----------+-------------------------------------------  
log_time               | 2023-11-10 16:32:18.802+00  
user_name              |   
database_name          |   
process_id             | 753  
connection_from        |   
session_id             | 654e5b12.2f1  
session_line_num       | 4  
command_tag            |   
session_start_time     | 2023-11-10 16:32:18+00  
virtual_transaction_id |   
transaction_id         | 0  
error_severity         | LOG  
sql_state_code         | 00000  
message                | listening on Unix socket "./.s.PGSQL.1921"  
detail                 |   
hint                   |   
internal_query         |   
internal_query_pos     |   
context                |   
query                  |   
query_pos              |   
location               |   
application_name       |   
backend_type           | postmaster  
leader_pid             |   
query_id               | 0  
```  
  
  
  
#### 79 查看报错所属代码  
```  
db1=> \set VERBOSITY verbose  
  
  
db1=> select a;  
ERROR:  42703: column "a" does not exist  
LINE 1: select a;  
               ^  
LOCATION:  errorMissingColumn, parse_relation.c:3638  
```  
  
  
#### 80 查看数据库报错编码说明  
https://www.postgresql.org/docs/14/errcodes-appendix.html  
  
  
```  
ERROR:  42703  
```  
  
```  
undefined_column  
```  
#### 81 查看数据库编译配置  
```  
postgres@6f60081d4ace:~/14/pgdata$ pg_config  
  
BINDIR = /usr/lib/postgresql/14/bin  
DOCDIR = /usr/share/doc/postgresql-doc-14  
HTMLDIR = /usr/share/doc/postgresql-doc-14  
INCLUDEDIR = /usr/include/postgresql  
PKGINCLUDEDIR = /usr/include/postgresql  
INCLUDEDIR-SERVER = /usr/include/postgresql/14/server  
LIBDIR = /usr/lib/x86_64-linux-gnu  
PKGLIBDIR = /usr/lib/postgresql/14/lib  
LOCALEDIR = /usr/share/locale  
MANDIR = /usr/share/postgresql/14/man  
SHAREDIR = /usr/share/postgresql/14  
SYSCONFDIR = /etc/postgresql-common  
PGXS = /usr/lib/postgresql/14/lib/pgxs/src/makefiles/pgxs.mk  
CONFIGURE =  '--build=x86_64-linux-gnu' '--prefix=/usr' '--includedir=${prefix}/include' '--mandir=${prefix}/share/man' '--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--disable-option-checking' '--disable-silent-rules' '--libdir=${prefix}/lib/x86_64-linux-gnu' '--runstatedir=/run' '--disable-maintainer-mode' '--disable-dependency-tracking' '--with-tcl' '--with-perl' '--with-python' '--with-pam' '--with-openssl' '--with-libxml' '--with-libxslt' '--mandir=/usr/share/postgresql/14/man' '--docdir=/usr/share/doc/postgresql-doc-14' '--sysconfdir=/etc/postgresql-common' '--datarootdir=/usr/share/' '--datadir=/usr/share/postgresql/14' '--bindir=/usr/lib/postgresql/14/bin' '--libdir=/usr/lib/x86_64-linux-gnu/' '--libexecdir=/usr/lib/postgresql/' '--includedir=/usr/include/postgresql/' '--with-extra-version= (Debian 14.9-1.pgdg110+1)' '--enable-nls' '--enable-thread-safety' '--enable-debug' '--enable-dtrace' '--disable-rpath' '--with-uuid=e2fs' '--with-gnu-ld' '--with-gssapi' '--with-ldap' '--with-pgport=5432' '--with-system-tzdata=/usr/share/zoneinfo' 'AWK=mawk' 'MKDIR_P=/bin/mkdir -p' 'PROVE=/usr/bin/prove' 'PYTHON=/usr/bin/python3' 'TAR=/bin/tar' 'XSLTPROC=xsltproc --nonet' 'CFLAGS=-g -O2 -fstack-protector-strong -Wformat -Werror=format-security -fno-omit-frame-pointer' 'LDFLAGS=-Wl,-z,relro -Wl,-z,now' '--enable-tap-tests' '--with-icu' '--with-llvm' 'LLVM_CONFIG=/usr/bin/llvm-config-11' 'CLANG=/usr/bin/clang-11' '--with-lz4' '--with-systemd' '--with-selinux' 'build_alias=x86_64-linux-gnu' 'CPPFLAGS=-Wdate-time -D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fstack-protector-strong -Wformat -Werror=format-security'  
CC = gcc  
CPPFLAGS = -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2  
CFLAGS = -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -fno-omit-frame-pointer  
CFLAGS_SL = -fPIC  
LDFLAGS = -Wl,-z,relro -Wl,-z,now -L/usr/lib/llvm-11/lib -Wl,--as-needed  
LDFLAGS_EX =   
LDFLAGS_SL =   
LIBS = -lpgcommon -lpgport -lselinux -llz4 -lxslt -lxml2 -lpam -lssl -lcrypto -lgssapi_krb5 -lz -lreadline -lpthread -lrt -ldl -lm   
VERSION = PostgreSQL 14.9 (Debian 14.9-1.pgdg110+1)  
```  
  
#### 82 查看数据库控制文件内容  
  
```  
postgres@6f60081d4ace:~/14/pgdata$ pg_controldata   
pg_control version number:            1300  
Catalog version number:               202107181  
Database system identifier:           7290978703664750627  
Database cluster state:               in production  
pg_control last modified:             Sat 11 Nov 2023 06:06:50 AM UTC  
Latest checkpoint location:           0/404EFA98  
Latest checkpoint's REDO location:    0/404EFA98  
Latest checkpoint's REDO WAL file:    000000010000000000000040  
Latest checkpoint's TimeLineID:       1  
Latest checkpoint's PrevTimeLineID:   1  
Latest checkpoint's full_page_writes: on  
Latest checkpoint's NextXID:          0:1019  
Latest checkpoint's NextOID:          106737  
Latest checkpoint's NextMultiXactId:  1  
Latest checkpoint's NextMultiOffset:  0  
Latest checkpoint's oldestXID:        726  
Latest checkpoint's oldestXID's DB:   1  
Latest checkpoint's oldestActiveXID:  0  
Latest checkpoint's oldestMultiXid:   1  
Latest checkpoint's oldestMulti's DB: 1  
Latest checkpoint's oldestCommitTsXid:0  
Latest checkpoint's newestCommitTsXid:0  
Time of latest checkpoint:            Sat 11 Nov 2023 06:06:49 AM UTC  
Fake LSN counter for unlogged rels:   0/12D33  
Minimum recovery ending location:     0/0  
Min recovery ending loc's timeline:   0  
Backup start location:                0/0  
Backup end location:                  0/0  
End-of-backup record required:        no  
wal_level setting:                    replica  
wal_log_hints setting:                off  
max_connections setting:              2000  
max_worker_processes setting:         8  
max_wal_senders setting:              10  
max_prepared_xacts setting:           0  
max_locks_per_xact setting:           64  
track_commit_timestamp setting:       off  
Maximum data alignment:               8  
Database block size:                  8192  
Blocks per segment of large relation: 131072  
WAL block size:                       8192  
Bytes per WAL segment:                16777216  
Maximum length of identifiers:        64  
Maximum columns in an index:          32  
Maximum size of a TOAST chunk:        1996  
Size of a large-object chunk:         2048  
Date/time type storage:               64-bit integers  
Float8 argument passing:              by value  
Data page checksum version:           0  
Mock authentication nonce:            2f174bd82d73e525c4095000cc1a2df1ecced8ffa6f36fd70d20851d01a619b3  
```  
  
#### 83 跟踪数据库进程调用栈  
```  
pstack  
```  
  
OR  
  
[《debian 使用gdb实现rhel / centos pstack功能》](../202310/20231008_03.md)    
  
```  
db1=> select pg_backend_pid();  
 pg_backend_pid   
----------------  
           1039  
(1 row)  
  
  
  
root@6f60081d4ace:~# gdb -p 1039 --batch -ex "thread apply all bt"    
[Thread debugging using libthread_db enabled]  
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".  
0x00007fe723fc8d16 in epoll_wait (epfd=4, events=0x55610a6a3190, maxevents=1, timeout=-1) at ../sysdeps/unix/sysv/linux/epoll_wait.c:30  
30	../sysdeps/unix/sysv/linux/epoll_wait.c: No such file or directory.  
  
Thread 1 (Thread 0x7fe7217a4a40 (LWP 1039) "postgres"):  
#0  0x00007fe723fc8d16 in epoll_wait (epfd=4, events=0x55610a6a3190, maxevents=1, timeout=-1) at ../sysdeps/unix/sysv/linux/epoll_wait.c:30  
#1  0x000055610854eb7b in WaitEventSetWait ()  
#2  0x0000556108440140 in secure_read ()  
#3  0x0000556108447e97 in ?? ()  
#4  0x0000556108448b65 in pq_getbyte ()  
#5  0x0000556108573949 in PostgresMain ()  
#6  0x00005561084f13b8 in ?? ()  
#7  0x00005561084f2224 in PostmasterMain ()  
#8  0x0000556108268809 in main ()  
[Inferior 1 (process 1039) detached]  
```  
  
#### 84 判断锁等待事件和堵塞状态  
  
[《PostgreSQL 谁堵塞了谁（锁等待检测）- pg_blocking_pids》](../201903/20190304_01.md)    
  
[《PostgreSQL 谁堵塞了谁（锁等待检测）- pg_blocking_pids, pg_safe_snapshot_blocking_pids》](../201902/20190201_02.md)    
  
[《PostgreSQL 锁等待排查实践 - 珍藏级 - process xxx1 acquired RowExclusiveLock on relation xxx2 of database xxx3 after xxx4 ms at xxx》](../201806/20180622_02.md)    
  
[《PostgreSQL 锁等待监控 珍藏级SQL - 谁堵塞了谁》](../201705/20170521_01.md)    
  
pg_blocking_pids(被堵塞PID)  
  
```  
create table t_lock (id int primary key, info text, ts timestamp);  
insert into t_lock values (1,'test',now());  
```  
  
session 1  
```  
db1=> begin isolation level repeatable read ;  
BEGIN  
db1=*> select * from t_lock;  
 id | info |             ts               
----+------+----------------------------  
  1 | test | 2023-11-11 02:42:58.803888  
(1 row)  
```  
  
session 2  
```  
db1=> begin;  
BEGIN  
db1=*> truncate table t_lock;  
```  
  
session 3   
```  
db1=> select pg_backend_pid();  
 pg_backend_pid   
----------------  
            367  
(1 row)  
  
  
db1=> select * from t_lock;  
```  
  
session 4   
```  
with recursive tmp as (  
  select 1 as id, 367 as blocked_pid, conflict_origin_own_lock_pid from unnest(pg_blocking_pids(367)) as conflict_origin_own_lock_pid  
  union all  
  select id+1, conflict_origin_own_lock_pid as blocked_pid, unnest(pg_blocking_pids(conflict_origin_own_lock_pid)) as conflict_origin_own_lock_pid from tmp   
     -- where pg_blocking_pids(conflict_origin_own_lock_pid) <> '{}'::int[]   
)   
select tmp.id, pg_locks.pid, pg_locks.locktype, pg_locks.mode, pg_locks.granted, pg_stat_activity.query,   
  tmp.conflict_origin_own_lock_pid   
  from tmp, pg_locks, pg_stat_activity   
  where tmp.blocked_pid=pg_locks.pid   
      -- or tmp.conflict_origin_own_lock_pid=pg_locks.pid   
      and pg_locks.pid = pg_stat_activity.pid  
  order by id;   
  
  
 id | pid |   locktype    |        mode         | granted |         query          | conflict_origin_own_lock_pid   
----+-----+---------------+---------------------+---------+------------------------+------------------------------  
  1 | 367 | virtualxid    | ExclusiveLock       | t       | select * from t_lock;  |                          358  
  1 | 367 | relation      | AccessShareLock     | f       | select * from t_lock;  |                          358  
  2 | 358 | relation      | AccessExclusiveLock | f       | truncate table t_lock; |                          344  
  2 | 358 | virtualxid    | ExclusiveLock       | t       | truncate table t_lock; |                          344  
  2 | 358 | transactionid | ExclusiveLock       | t       | truncate table t_lock; |                          344  
(5 rows)  
```  
  
找到了源头是344, 最后查一下这条在干什么?   
  
```  
select pg_locks.pid, pg_locks.locktype, pg_locks.mode, pg_locks.granted, pg_stat_activity.query  
from pg_locks, pg_stat_activity   
where pg_locks.pid = pg_stat_activity.pid  
and pg_locks.pid=344;   
  
  
 pid |  locktype  |      mode       | granted |         query           
-----+------------+-----------------+---------+-----------------------  
 344 | relation   | AccessShareLock | t       | select * from t_lock;  
 344 | virtualxid | ExclusiveLock   | t       | select * from t_lock;  
 344 | relation   | AccessShareLock | t       | select * from t_lock;  
(3 rows)  
```  
  
创建一个试图, 方便排查锁等待链条    
```  
create view v_lock_chains as   
with recursive   
a as (select pid from pg_locks where not granted),  
tmp as (  
  select 1 as id, pid as blocked_pid, conflict_origin_own_lock_pid from (select pid, unnest(pg_blocking_pids(pid)) as conflict_origin_own_lock_pid from a) tt  
  union all  
  select id+1, conflict_origin_own_lock_pid as blocked_pid, unnest(pg_blocking_pids(conflict_origin_own_lock_pid)) as conflict_origin_own_lock_pid from tmp   
     -- where pg_blocking_pids(conflict_origin_own_lock_pid) <> '{}'::int[]   
)   
select tmp.id, pg_locks.pid, pg_locks.locktype, pg_locks.mode, pg_locks.granted, pg_stat_activity.query,   
  tmp.conflict_origin_own_lock_pid   
  from tmp, pg_locks, pg_stat_activity   
  where tmp.blocked_pid=pg_locks.pid   
      -- or tmp.conflict_origin_own_lock_pid=pg_locks.pid   
      and pg_locks.pid = pg_stat_activity.pid  
  order by id;   
```  
  
#### 85 RR隔离级别  
后续的SQL可见性判断都使用同一个事务快照, 也就是事务开始时创建的快照.  快照后提交的数据是看不到的, 因为被判断为不可见.  
```  
create table t_rr (id int);  
insert into t_rr values (1);  
```  
  
session 2:  
```  
begin;  
insert into t_rr values (2);  
INSERT 0 1  
```  
  
session 1:  
```  
db1=> begin isolation level repeatable read ;  
BEGIN  
  
db1=*> select * from t_rr;  
 id   
----  
  1  
(1 row)  
```  
  
session 2:  
```  
db1=*> commit;  
COMMIT  
```  
  
session 1:  
```  
db1=*> select * from t_rr;  
 id   
----  
  1  
(1 row)  
```  
  
#### 86 导出事务快照   
[《PostgreSQL 共享事务快照功能 - PostgreSQL 9.2 can share snapshot between multi transactions》](../201205/20120516_01.md)    
  
[《PostgreSQL 事务快照功能 - Parallel Export consistent data or Parallel Query use snapshot transaction feature》](../201303/20130306_02.md)    
  
[《PostgreSQL 9.5 new feature - pg_dump use --snapshot taken by another session (exp. slot, pg_export_snapshot())》](../201506/20150616_02.md)    
  
让多个会话使用同一个快照判断tuple可见性. 在 并行逻辑备份, 并行逻辑复制 的场景中, 使用共享事务快照解决多个并行进程快照不一致的问题. 也可以用来分享rc事务不同快照给不同的协作会话.   
  
```  
create table t_snap (id int);  
insert into t_snap values (1);  
```  
  
session 1:  
```  
begin TRANSACTION ISOLATION LEVEL repeatable read;    
SELECT pg_export_snapshot();    
  
 pg_export_snapshot    
---------------------  
 00000005-00000008-1  
(1 row)  
```  
  
  
#### 87 导入事务快照  
  
session 2:  
```  
db1=> begin TRANSACTION ISOLATION LEVEL repeatable read;    
BEGIN  
db1=*>   
db1=*> SET TRANSACTION SNAPSHOT '00000005-00000008-1';   
SET  
```  
  
#### 88 串行隔离级别(SSI)  
用于模拟串行处理 开启了SSI隔离级别的多个会话, 按事务结束顺序的串行, 如果相互不冲突, 则可以成功结束事务.    
  
采用了一些优化手段来通知被冲突但是未结束的事务, 用于加速报错, 避免到事务结束时再报错.    
  
```  
db1=> begin isolation level serializable ;  
BEGIN  
```  
  
#### 89 使用pgbench压测数据库  
  
- [《HTAP数据库 PostgreSQL 场景与性能测试之 3.1 - (OLAP) 大表JOIN统计查询-10亿 join 1亿 agg》](../201711/20171107_49.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 47 - (OLTP多模优化) 空间应用 - 高并发空间位置更新、多属性KNN搜索并测（含空间索引）末端配送、新零售类项目》](../201711/20171107_48.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 46 - (OLTP) 大json字段的高并发更新》](../201711/20171107_47.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 45 - (OLTP) 数据量与性能的线性关系(10亿+无衰减), 暨单表多大需要分区》](../201711/20171107_46.md)    
- [《[未完待续] HTAP数据库 PostgreSQL 场景与性能测试之 44 - (OLTP) 空间应用 - 空间包含查询(输入多边形 包含 表内空间对象)》](../201711/20171107_45.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 43 - (OLTP+OLAP) unlogged table 含索引多表批量写入》](../201711/20171107_44.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 42 - (OLTP+OLAP) unlogged table 不含索引多表批量写入》](../201711/20171107_43.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 41 - (OLTP+OLAP) 含索引多表批量写入》](../201711/20171107_42.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 40 - (OLTP+OLAP) 不含索引多表批量写入》](../201711/20171107_41.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 39 - (OLTP+OLAP) logged & unlogged table 含索引多表单点写入》](../201711/20171107_40.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 38 - (OLTP+OLAP) logged & unlogged table 不含索引多表单点写入》](../201711/20171107_39.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 37 - (OLTP+OLAP) 含索引单表批量写入》](../201711/20171107_38.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 36 - (OLTP+OLAP) 不含索引单表批量写入》](../201711/20171107_37.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 35 - (OLTP+OLAP) 含索引单表单点写入》](../201711/20171107_36.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 34 - (OLTP+OLAP) 不含索引单表单点写入》](../201711/20171107_35.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 33 - (OLAP) 物联网 - 线性字段区间实时统计》](../201711/20171107_34.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 32 - (OLTP) 高吞吐数据进出(堆存、行扫、无需索引) - 阅后即焚(JSON + 函数流式计算)》](../201711/20171107_33.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 31 - (OLTP) 高吞吐数据进出(堆存、行扫、无需索引) - 阅后即焚(读写大吞吐并测)》](../201711/20171107_32.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 30 - (OLTP) 秒杀 - 高并发单点更新》](../201711/20171107_31.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 29 - (OLTP) 空间应用 - 高并发空间位置更新（含空间索引）》](../201711/20171107_30.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 28 - (OLTP) 高并发点更新》](../201711/20171107_29.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 27 - (OLTP) 物联网 - FEED日志, 流式处理 与 阅后即焚 (CTE)》](../201711/20171107_28.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 26 - (OLTP) NOT IN、NOT EXISTS 查询》](../201711/20171107_27.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 25 - (OLTP) IN , EXISTS 查询》](../201711/20171107_26.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 24 - (OLTP) 物联网 - 时序数据并发写入(含时序索引BRIN)》](../201711/20171107_25.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 23 - (OLAP) 并行计算》](../201711/20171107_24.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 22 - (OLTP) merge insert|upsert|insert on conflict|合并写入》](../201711/20171107_23.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 21 - (OLTP+OLAP) 排序、建索引》](../201711/20171107_22.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 20 - (OLAP) 用户画像圈人场景 - 多个字段任意组合条件筛选与透视》](../201711/20171107_21.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 19 - (OLAP) 用户画像圈人场景 - 数组相交查询与聚合》](../201711/20171107_20.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 18 - (OLAP) 用户画像圈人场景 - 数组包含查询与聚合》](../201711/20171107_19.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 17 - (OLTP) 数组相似查询》](../201711/20171107_18.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 16 - (OLTP) 文本特征向量 - 相似特征(海明...)查询》](../201711/20171107_17.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 15 - (OLTP) 物联网 - 查询一个时序区间的数据》](../201711/20171107_16.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 14 - (OLTP) 字符串搜索 - 全文检索》](../201711/20171107_15.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 13 - (OLTP) 字符串搜索 - 相似查询》](../201711/20171107_14.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 12 - (OLTP) 字符串搜索 - 前后模糊查询》](../201711/20171107_13.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 11 - (OLTP) 字符串搜索 - 后缀查询》](../201711/20171107_12.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 10 - (OLTP) 字符串搜索 - 前缀查询》](../201711/20171107_11.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 9 - (OLTP) 字符串模糊查询 - 含索引实时写入》](../201711/20171107_10.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 8 - (OLTP) 多值类型(数组)含索引实时写入》](../201711/20171107_09.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 7 - (OLTP) 全文检索 - 含索引实时写入》](../201711/20171107_08.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 6 - (OLTP) 空间应用 - KNN查询（搜索附近对象，由近到远排序输出）》](../201711/20171107_07.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 5 - (OLTP) 空间应用 - 空间包含查询(表内多边形 包含 输入空间对象)》](../201711/20171107_06.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 4 - (OLAP) 大表OUTER JOIN统计查询》](../201711/20171107_05.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 3 - (OLAP) 大表JOIN统计查询》](../201711/20171107_04.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 2 - (OLTP) 多表JOIN》](../201711/20171107_03.md)    
- [《HTAP数据库 PostgreSQL 场景与性能测试之 1 - (OLTP) 点查》](../201711/20171107_02.md)    
- [《沉浸式学习PostgreSQL|PolarDB 12: 如何快速构建 海量 逼真 测试数据》](../202309/20230906_02.md)    
- [《PostgreSQL 如何快速构建 海量 逼真 测试数据》](../201711/20171121_01.md)    
  
man pgbench  
  
tpc-b  
```  
postgres@6f60081d4ace:~$ pgbench -i -s 10  
dropping old tables...  
NOTICE:  table "pgbench_accounts" does not exist, skipping  
NOTICE:  table "pgbench_branches" does not exist, skipping  
NOTICE:  table "pgbench_history" does not exist, skipping  
NOTICE:  table "pgbench_tellers" does not exist, skipping  
creating tables...  
generating data (client-side)...  
1000000 of 1000000 tuples (100%) done (elapsed 0.75 s, remaining 0.00 s)  
vacuuming...  
creating primary keys...  
done in 1.96 s (drop tables 0.00 s, create tables 0.02 s, client-side generate 0.78 s, vacuum 0.28 s, primary keys 0.88 s).  
  
  
postgres@6f60081d4ace:~$ pgbench -M prepared -n -r -P 1 -c 4 -j 4 -T 10 -S  
pgbench (14.9 (Debian 14.9-1.pgdg110+1))  
progress: 1.0 s, 30933.3 tps, lat 0.128 ms stddev 0.043  
progress: 2.0 s, 33331.9 tps, lat 0.120 ms stddev 0.037  
progress: 3.0 s, 32953.7 tps, lat 0.121 ms stddev 0.036  
progress: 4.0 s, 33335.1 tps, lat 0.120 ms stddev 0.034  
progress: 5.0 s, 31687.2 tps, lat 0.126 ms stddev 0.044  
progress: 6.0 s, 32090.9 tps, lat 0.124 ms stddev 0.042  
progress: 7.0 s, 33384.9 tps, lat 0.120 ms stddev 0.038  
progress: 8.0 s, 32202.6 tps, lat 0.124 ms stddev 0.040  
progress: 9.0 s, 31151.3 tps, lat 0.128 ms stddev 0.041  
transaction type: <builtin: select only>  
scaling factor: 10  
query mode: prepared  
number of clients: 4  
number of threads: 4  
duration: 10 s  
number of transactions actually processed: 320073  
latency average = 0.125 ms  
latency stddev = 0.041 ms  
initial connection time = 4.823 ms  
tps = 32020.662222 (without initial connection time)  
statement latencies in milliseconds:  
         0.001  \set aid random(1, 100000 * :scale)  
         0.124  SELECT abalance FROM pgbench_accounts WHERE aid = :aid;  
```  
  
自定义测试脚本:  
```  
create unlogged table t_bench(id serial primary key, gid int, info text, ts timestamp);  
  
  
vi t.sql  
\set gid random(1,1000)  
insert into t_bench(gid,info,ts) values (:gid, random()::text, now());  
  
  
pgbench -M prepared -n -r -P 1 -f ./t.sql -c 4 -j 4 -T 10  
  
  
postgres@6f60081d4ace:~$ pgbench -M prepared -n -r -P 1 -f ./t.sql -c 4 -j 4 -T 10  
pgbench (14.9 (Debian 14.9-1.pgdg110+1))  
progress: 1.0 s, 27538.6 tps, lat 0.144 ms stddev 0.061  
progress: 2.0 s, 27973.0 tps, lat 0.143 ms stddev 0.041  
progress: 3.0 s, 27437.5 tps, lat 0.145 ms stddev 0.043  
progress: 4.0 s, 27998.6 tps, lat 0.143 ms stddev 0.042  
progress: 5.0 s, 28008.2 tps, lat 0.142 ms stddev 0.045  
progress: 6.0 s, 28242.1 tps, lat 0.141 ms stddev 0.062  
progress: 7.0 s, 28113.7 tps, lat 0.142 ms stddev 0.067  
progress: 8.0 s, 28360.3 tps, lat 0.141 ms stddev 0.040  
progress: 9.0 s, 27479.7 tps, lat 0.145 ms stddev 0.046  
transaction type: ./t.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 4  
number of threads: 4  
duration: 10 s  
number of transactions actually processed: 276617  
latency average = 0.144 ms  
latency stddev = 0.051 ms  
initial connection time = 4.494 ms  
tps = 27673.170529 (without initial connection time)  
statement latencies in milliseconds:  
         0.000  \set gid random(1,1000)  
         0.144  insert into t_bench(gid,info,ts) values (:gid, random()::text, now());  
```  
  
#### 90 查看活跃会话  
[《PostgreSQL DBA最常用SQL》](../202005/20200509_02.md)    
  
[《PostgreSQL Oracle 兼容性之 - performance insight - AWS performance insight 理念与实现解读 - 珍藏级》](../201901/20190125_02.md)    
  
```  
postgres=# select now(),state,datname,usename,wait_event_type,wait_event,query from pg_stat_activity where state in ('active', 'fastpath function call');      
-[ RECORD 1 ]---+-----------------------------------------------------------------------------------------------------------------------------------------------  
now             | 2023-11-11 06:36:28.51324+00  
state           | active  
datname         | postgres  
usename         | postgres  
wait_event_type |   
wait_event      |   
query           | select now(),state,datname,usename,wait_event_type,wait_event,query from pg_stat_activity where state in ('active', 'fastpath function call');  
```  
  
#### 91 查看TOP SQL  
[《PostgreSQL 如何查找TOP SQL (例如IO消耗最高的SQL) (包含SQL优化内容) - 珍藏级 - 数据库慢、卡死、连接爆增、慢查询多、OOM、crash、in recovery、崩溃等怎么办?怎么优化?怎么诊断?》](../201704/20170424_06.md)    
  
最耗时 SQL. 依赖pg_stat_statements插件   
      
单次调用最耗时 SQL TOP 5      
      
```      
select userid::regrole, dbid, query from pg_stat_statements order by mean_exec_time desc limit 5;      
```    
  
```  
 userid | dbid  |                                                       query                                                         
--------+-------+-------------------------------------------------------------------------------------------------------------------  
 r1     | 16388 | truncate table t_lock  
 r1     | 16388 | create index on tbl using gin (gid, c1 gin_trgm_ops, c2 gin_trgm_ops, c3 gin_trgm_ops)  
 r1     | 16388 | insert into tbl_ts select id,ts,to_tsvector(ts) from (select generate_series($1,$2) id, gen_rand_text($3) ts) t  
 r1     | 16388 | insert into t_big select generate_series($1,$2), md5(random()::text), random()*$3, random()*$4, clock_timestamp()  
 r1     | 16388 | insert into tbl (gid,c1,c2,c3,ts)                                                                                +  
        |       | select random()*$1, gen_hanzi($2), gen_hanzi($3), gen_hanzi($4), clock_timestamp()                               +  
        |       | from generate_series($5,$6)  
(5 rows)  
```    
      
**总最耗时 SQL TOP 5(最需要关注的是这个)**      
      
```      
select userid::regrole, dbid, query from pg_stat_statements order by total_exec_time desc limit 5;      
```    
  
```  
 userid | dbid  |                                                       query                                                         
--------+-------+-------------------------------------------------------------------------------------------------------------------  
 r1     | 16388 | truncate table t_lock  
 r1     | 16388 | insert into tbl (gid,c1,c2,c3,ts)                                                                                +  
        |       | select random()*$1, gen_hanzi($2), gen_hanzi($3), gen_hanzi($4), clock_timestamp()                               +  
        |       | from generate_series($5,$6)  
 r1     | 16388 | create index on tbl using gin (gid, c1 gin_trgm_ops, c2 gin_trgm_ops, c3 gin_trgm_ops)  
 r1     | 16388 | insert into tbl_ts select id,ts,to_tsvector(ts) from (select generate_series($1,$2) id, gen_rand_text($3) ts) t  
 r1     | 16388 | insert into t_big select generate_series($1,$2), md5(random()::text), random()*$3, random()*$4, clock_timestamp()  
(5 rows)  
```    
      
响应时间抖动最严重 SQL      
      
```      
select userid::regrole, dbid, query from pg_stat_statements order by stddev_exec_time desc limit 5;      
```        
      
最耗临时空间 SQL      
      
```      
select userid::regrole, dbid, query from pg_stat_statements order by temp_blks_written desc limit 5;      
```     
  
```  
  userid  | dbid  |                                              query                                                 
----------+-------+--------------------------------------------------------------------------------------------------  
 r1       | 16388 | explain analyze select * from t_off1 where c=1 order by id limit 10 offset 8000000  
 r1       | 16388 | insert into t_off1 (info,c,ts) select md5(random()::text), $1, now() from generate_series($2,$3)  
 r1       | 16388 | refresh materialized view CONCURRENTLY mv_t_mv with data  
 r1       | 16388 | insert into tbl (gid,c1,c2,c3,ts)                                                               +  
          |       | select random()*$1, gen_hanzi($2), gen_hanzi($3), gen_hanzi($4), clock_timestamp()              +  
          |       | from generate_series($5,$6)  
 postgres | 13757 | alter table pgbench_accounts add primary key (aid)  
(5 rows)  
```  
  
#### 92 配置慢查询日志  
```  
vi $PGDATA/postgresql.auto.conf  
  
log_min_duration_statement = '1s'  
  
OR  
  
postgres=# alter system set log_min_duration_statement = '1s';  
ALTER SYSTEM  
```  
  
```  
pg_ctl reload  
  
OR  
  
postgres=# select pg_reload_conf();  
 pg_reload_conf   
----------------  
 t  
(1 row)  
  
postgres=# show log_min_duration_statement;  
 log_min_duration_statement   
----------------------------  
 1s  
(1 row)  
```  
  
```  
postgres=# select pg_sleep(1.1);  
 pg_sleep   
----------  
   
(1 row)  
```  
  
```  
cd $PGDATA  
  
postgres@6f60081d4ace:~/14/pgdata$ cat current_logfiles   
csvlog log/postgresql-2023-11-11_060650.csv  
  
postgres@6f60081d4ace:~/14/pgdata$ less log/postgresql-2023-11-11_060650.csv  
  
  
  
2023-11-11 06:43:01.303 UTC,"postgres","postgres",1160,"[local]",654f2270.488,1,"SELECT",2023-11-11 06:42:56 UTC,4/0,0,LOG,00000,"duration: 1104.114 ms  statement: select pg_sleep(1.1);",,,,,,,,,"psql","client backend",,2920803561901199087  
```  
  
#### 93 配置过往慢查询跟踪  
https://www.postgresql.org/docs/14/auto-explain.html  
  
```  
vi $PGDATA/postgresql.auto.conf  
  
track_io_timing = on  
track_wal_io_timing = on  
shared_preload_libraries = 'auto_explain, pg_stat_statements'  
auto_explain.log_min_duration = '1s'  
auto_explain.log_analyze = true  
auto_explain.log_buffers = true  
auto_explain.log_wal = true  
auto_explain.log_timing = true   
auto_explain.log_verbose = true  
auto_explain.log_settings = true  
auto_explain.log_nested_statements = true  
  
  
  
pg_ctl restart -m fast  
```  
  
```  
postgres=# \c db1 r1  
You are now connected to database "db1" as user "r1".  
db1=> \dt+  
                                           List of relations  
 Schema |       Name       | Type  |  Owner   | Persistence | Access method |    Size    | Description   
--------+------------------+-------+----------+-------------+---------------+------------+-------------  
 public | spatial_ref_sys  | table | postgres | permanent   | heap          | 6936 kB    |   
 s1     | aud_alter        | table | r1       | permanent   | heap          | 16 kB      |   
 s1     | new1             | table | r1       | permanent   | heap          | 8192 bytes |   
 s1     | new2             | table | r1       | permanent   | heap          | 8192 bytes |   
 s1     | new3             | table | r1       | unlogged    | heap          | 16 kB      |   
 s1     | new4             | table | r1       | permanent   | heap          | 498 MB     |   
 s1     | nt               | table | r1       | permanent   | heap          | 8192 bytes |   
 s1     | nt1              | table | r1       | permanent   | heap          | 0 bytes    |   
 s1     | t                | table | r1       | permanent   | heap          | 16 kB      |   
 s1     | t2               | table | r1       | permanent   | heap          | 16 kB      |   
 s1     | t3               | table | r1       | permanent   | heap          | 16 kB      |   
 s1     | t4               | table | r1       | permanent   | heap          | 0 bytes    |   
 s1     | t_1              | table | r1       | permanent   | heap          | 16 kB      |   
 s1     | t_big            | table | r1       | unlogged    | heap          | 8056 MB    |   
 s1     | t_cur            | table | r1       | permanent   | heap          | 792 kB     |   
 s1     | t_forupdate      | table | r1       | permanent   | heap          | 16 kB      |   
 s1     | t_hid            | table | r1       | permanent   | heap          | 8192 bytes |   
 s1     | t_hint           | table | r1       | permanent   | heap          | 8192 bytes |   
 s1     | t_lock           | table | r1       | permanent   | heap          | 16 kB      |   
 s1     | t_mv             | table | r1       | permanent   | heap          | 24 MB      |   
 s1     | t_off            | table | r1       | permanent   | heap          | 376 kB     |   
 s1     | t_off1           | table | r1       | unlogged    | heap          | 806 MB     |   
 s1     | t_rr             | table | r1       | permanent   | heap          | 8192 bytes |   
 s1     | table_change_rec | table | r1       | permanent   | heap          | 16 kB      |   
 s1     | tbl              | table | r1       | unlogged    | heap          | 120 MB     |   
 s1     | tbl_poi          | table | r1       | unlogged    | heap          | 65 MB      |   
 s1     | tbl_tj           | table | r1       | unlogged    | heap          | 78 MB      |   
 s1     | tbl_ts           | table | r1       | unlogged    | heap          | 639 MB     |   
 s1     | tbl_vector       | table | r1       | unlogged    | heap          | 56 MB      |   
 s1     | test             | table | r1       | permanent   | heap          | 0 bytes    |   
 s1     | test1            | table | r1       | permanent   | heap          | 16 kB      |   
(31 rows)  
  
db1=> select count(*) from t_off1  
db1-> ;  
  count     
----------  
 10000000  
(1 row)  
  
db1=> \timing  
Timing is on.  
db1=> select count(*) from t_big;  
   count     
-----------  
 100000000  
(1 row)  
  
Time: 16360.549 ms (00:16.361)  
db1=> select pg_sleep(1.5);  
 pg_sleep   
----------  
   
(1 row)  
  
Time: 1503.326 ms (00:01.503)  
db1=>   
```  
  
```  
postgres@6f60081d4ace:~/14/pgdata$ cd $PGDATA  
postgres@6f60081d4ace:~/14/pgdata$ cat current_logfiles   
csvlog log/postgresql-2023-11-11_064543.csv  
  
  
  
  
2023-11-11 06:46:15.404 UTC,"r1","db1",1201,"[local]",654f232a.4b1,1,"SELECT",2023-11-11 06:46:02 UTC,4/3,0,LOG,00000,"duration: 1437.490 ms  plan:  
Query Text: select count(*) from t_off1  
;  
Aggregate  (cost=183711.54..183711.55 rows=1 width=8) (actual time=1437.480..1437.481 rows=1 loops=1)  
  Output: count(*)  
  Buffers: shared read=7874  
  I/O Timings: read=82.202  
  ->  Index Only Scan using t_off1_c_ts_idx on s1.t_off1  (cost=0.43..158711.67 rows=9999949 width=0) (actual time=3.104..803.399 rows=10000000 loops=1)  
        Output: c, ts  
        Heap Fetches: 0  
        Buffers: shared read=7874  
        I/O Timings: read=82.202  
Settings: max_parallel_workers_per_gather = '0', random_page_cost = '1.1', search_path = '""$user"", s1, public'  
JIT:  
  Functions: 2  
  Options: Inlining false, Optimization false, Expressions true, Deforming true  
  Timing: Generation 0.245 ms, Inlining 0.000 ms, Optimization 0.208 ms, Emission 2.311 ms, Total 2.765 ms",,,,,,,,,"psql","client backend",,8133783971837376411  
2023-11-11 06:46:15.404 UTC,"r1","db1",1201,"[local]",654f232a.4b1,2,"SELECT",2023-11-11 06:46:02 UTC,4/0,0,LOG,00000,"duration: 1472.583 ms  statement: select count(*) from t_off1  
;",,,,,,,,,"psql","client backend",,8133783971837376411  
2023-11-11 06:46:39.911 UTC,"r1","db1",1201,"[local]",654f232a.4b1,3,"SELECT",2023-11-11 06:46:02 UTC,4/4,0,LOG,00000,"duration: 16359.165 ms  plan:  
Query Text: select count(*) from t_big;  
Aggregate  (cost=2280928.20..2280928.21 rows=1 width=8) (actual time=16359.155..16359.156 rows=1 loops=1)  
  Output: count(*)  
  Buffers: shared read=1030928  
  I/O Timings: read=4232.276  
  ->  Seq Scan on s1.t_big  (cost=0.00..2030928.16 rows=100000016 width=0) (actual time=0.457..10531.855 rows=100000000 loops=1)  
        Output: id, info, c1, c2, ts  
        Buffers: shared read=1030928  
        I/O Timings: read=4232.276  
Settings: max_parallel_workers_per_gather = '0', random_page_cost = '1.1', search_path = '""$user"", s1, public'  
JIT:  
  Functions: 2  
  Options: Inlining true, Optimization true, Expressions true, Deforming true  
  Timing: Generation 0.360 ms, Inlining 53.314 ms, Optimization 5.399 ms, Emission 4.499 ms, Total 63.572 ms",,,,,,,,,"psql","client backend",,930403565133997478  
2023-11-11 06:46:39.911 UTC,"r1","db1",1201,"[local]",654f232a.4b1,4,"SELECT",2023-11-11 06:46:02 UTC,4/0,0,LOG,00000,"duration: 16371.929 ms  statement: select count(*) from t_big;",,,,,,,,,"psql","client backend",,930403565133997478  
2023-11-11 06:46:51.538 UTC,"r1","db1",1201,"[local]",654f232a.4b1,5,"SELECT",2023-11-11 06:46:02 UTC,4/5,0,LOG,00000,"duration: 1501.982 ms  plan:  
Query Text: select pg_sleep(1.5);  
Result  (cost=0.00..0.01 rows=1 width=4) (actual time=1501.966..1501.967 rows=1 loops=1)  
  Output: pg_sleep('1.5'::double precision)  
Settings: max_parallel_workers_per_gather = '0', random_page_cost = '1.1', search_path = '""$user"", s1, public'",,,,,,,,,"psql","client backend",,2920803561901199087  
2023-11-11 06:46:51.538 UTC,"r1","db1",1201,"[local]",654f232a.4b1,6,"SELECT",2023-11-11 06:46:02 UTC,4/0,0,LOG,00000,"duration: 1502.873 ms  statement: select pg_sleep(1.5);",,,,,,,,,"psql","client backend",,2920803561901199087  
```  
  
#### 94 配置连接池   
https://www.pgbouncer.org/usage.html  
  
- [《pgbouncer 1.21 开始支持 prepared statement in 事务模式》](../202310/20231026_02.md)    
- [《Use pgbouncer connect to GreenPlum's segment node》](../201201/20120113_03.md)    
- [《PostgreSQL 连接池 pgbouncer 使用》](../201005/20100511_03.md)    
  
```  
su - postgres  
cd ~  
  
postgres@6f60081d4ace:~$ pwd  
/var/lib/postgresql  
  
mkdir ~/.pgb  
  
vi ~/.pgb/pgb.ini  
  
[databases]  
db1 = host=localhost port=1921 dbname=db1  
  
[pgbouncer]  
listen_port = 1922  
listen_addr = localhost  
auth_type = md5  
auth_file = /var/lib/postgresql/.pgb/userlist.txt  
logfile = /var/lib/postgresql/.pgb/pgbouncer.log  
pidfile = /var/lib/postgresql/.pgb/pgbouncer.pid  
admin_users = ad  
  
  
vi ~/.pgb/userlist.txt  
"ad" "pwd"  
  
chmod 600 ~/.pgb/userlist.txt  
  
/usr/sbin/pgbouncer -d ~/.pgb/pgb.ini  
  
psql -h 127.0.0.1 -p 1922 -U r1 -d db1  
  
  
psql -h 127.0.0.1 -p 1922 -U r1 -d db1  
Password for user r1:   
psql (14.9 (Debian 14.9-1.pgdg110+1))  
Type "help" for help.  
  
db1=>   
db1=>   
```  
  
  
#### 95 reload配置文件, 关闭/启动/重启数据库实例  
  
```  
-- 进入容器后, 进入postgres用户  
su - postgres  
  
-- reload配置文件  
pg_ctl reload  
  
-- 关闭数据库实例, 回退未完成会话, 刷出buffer内存中的脏数据, 一致性关闭数据库. 再次启动时无需自动恢复.   
pg_ctl stop -m fast  
  
-- 最快速度关闭数据库实例, 不管未完成会话, 不刷出buffer内存中的脏数据, 非一致性关闭数据库. 再次启动时需要自动恢复.   
pg_ctl stop -m immediate  
  
-- 启动数据库实例  
pg_ctl start  
  
-- 重启数据库实例  
pg_ctl restart -m fast  
  
-- 关闭容器  
docker stop pg  
  
-- 启动容器  
docker start pg  
  
-- 进入容器  
docker exec -ti pg bash  
  
-- 删除本章测试数据  
psql  
\c db1 r1  
drop schema s1 cascade;  
create schema s1;  
```  
  
  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 云原生分布式开源数据库](https://github.com/ApsaraDB "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、内核开发公开课、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  

## 下载和使用马斯克开源的 Grok-1 大语言模型     
                                                                                  
### 作者                                                                                  
digoal                                                                                  
                                                                                  
### 日期                                                                                  
2024-03-23                                                                           
                                                                                  
### 标签                                                                                  
PostgreSQL , PolarDB , DuckDB , Grok-1 , llama , Mac Studio                    
                                                                                  
----                                                                                  
                                                                                  
## 背景      
1、准备一台mac studio m2 ultra 192GB 8T 24 76 32 顶配. 官方翻新机售价约5万.      
  
[《好消息, Mac Studio 可以跑马斯克开源的 Grok-1 开源大语言模型》](../202403/20240323_01.md)    
  
[《想减少一些ssd磁盘写入来提高寿命? 禁用 MacOS 的 Swap 分区, 开启内存压缩 - 实测有效》](../202212/20221207_01.md)  
  
2、下载grok-1代码   
```
git clone --depth 1 https://github.com/xai-org/grok-1.git  
```
  
3、下载模型文件, 占用空间318GB     
  
下面给出了3种下载方法, 国内用迅雷就可以下载magnet link.      
  
3\.1、BT种子文件  
```  
Torrent: https://academictorrents.com/details/5f96d43576e3d386c9ba65b883210a393b68210e  
```  
  
3\.2、魔力链接, 拷贝下面内容到迅雷即可下载.    
```  
Magnet Link:  
magnet:?xt=urn:btih:5f96d43576e3d386c9ba65b883210a393b68210e&tr=https%3A%2F%2Facademictorrents.com%2Fannounce.php&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce  
```  
  
3\.3、从Hugging face下载`ckpt-0`.  
  
Hugging Face: https://huggingface.co/xai-org/grok-1 / https://huggingface.co/xai-org/grok-1/tree/main/ckpt-0  
  
首先要安装 huggingface-cli    
  
https://github.com/huggingface/huggingface_hub/blob/main/docs/source/en/guides/cli.md  
  
```  
pip install -U "huggingface_hub[cli]"  
  
huggingface-cli --help  
usage: huggingface-cli <command> [<args>]  
  
positional arguments:  
  {env,login,whoami,logout,repo,upload,download,lfs-enable-largefiles,lfs-multipart-upload,scan-cache,delete-cache}  
                        huggingface-cli command helpers  
    env                 Print information about the environment.  
    login               Log in using a token from huggingface.co/settings/tokens  
    whoami              Find out which huggingface.co account you are logged in as.  
    logout              Log out  
    repo                {create} Commands to interact with your huggingface.co repos.  
    upload              Upload a file or a folder to a repo on the Hub  
    download            Download files from the Hub  
    lfs-enable-largefiles  
                        Configure your repository to enable upload of files > 5GB.  
    scan-cache          Scan cache directory.  
    delete-cache        Delete revisions from the cache directory.  
  
options:  
  -h, --help            show this help message and exit  
```  
  
  
使用huggingface-cli从huggingface下载ckpt-0  
```  
huggingface-cli download xai-org/grok-1 --repo-type model --include ckpt-0/* --local-dir checkpoints --local-dir-use-symlinks False  
```  
  
If you get errors on zsh, then add quotes to ckpt-0/* to prevent shell from interpreting * as wildcard:  
```  
huggingface-cli download xai-org/grok-1 --repo-type model --include 'ckpt-0/*' --local-dir checkpoints --local-dir-use-symlinks False  
```  
  
  
4、将下载的ckpt-0目录放到grok-1代码 checkpoints目录中.  
```  
mv ckpt-0 grok-1/checkpoints/    
```  
  
5、测试grok 
```  
cd grok-1   
pip install -r requirements.txt  
python run.py   
```  
   
6、llama.cpp添加了grok-1的支持, 有兴趣可以继续阅读: https://github.com/ggerganov/llama.cpp/pull/6204   
  
## 参考  
https://github.com/xai-org/grok-1/discussions/129  
  
https://huggingface.co/xai-org/grok-1  
  
https://github.com/ggerganov/llama.cpp/pull/6204   
  
使用 MacBook Pro M1 16G 运行 Llama 2 7B (Apple Silicon 通用方法)  
- https://zhuanlan.zhihu.com/p/665094660
- https://www.cyberlight.xyz/passage/llama2-apple
   
仅需6行代码就能在Mac 本地上跑LLaMa2 模型  
- https://zhuanlan.zhihu.com/p/645908853
  
  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
